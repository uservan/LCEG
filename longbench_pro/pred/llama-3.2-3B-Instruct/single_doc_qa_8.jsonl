{"pred": " English-German dataset.", "answers": ["the English-German dataset"], "length": 6772}
{"pred": " The bigger the receptive field size, the more complete shapes can be reconstructed.", "answers": ["Bigger receptive field size leads to more successful shape completion."], "length": 6247}
{"pred": " Doc Brown \n Emmett Lathrop Brown \n Doc Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett Lathrop Brown \n Emmett L", "answers": "Doctor Emmett Lathrop `` Doc '' Brown", "length": 6477}
{"pred": " Claudia Wells", "answers": "Claudia Wells", "length": 6479}
{"pred": " Lea Thompson.", "answers": "Lea Thompson", "length": 6477}
{"pred": " Marlene McFly was played by Michael J. Fox.", "answers": "Wendie Jo Sperber", "length": 6478}
{"pred": " $m \\sim t^{1/2}$ and $O \\sim t^{\\alpha} L_\\parallel^{-1/2}$.", "answers": ["It is well described by the Gaussian theory."], "length": 6401}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7619}
{"pred": " 22,880.", "answers": ["22,880 users", "20,000"], "length": 7034}
{"pred": " 2013–14.", "answers": ["In the 2013-2014 season."], "length": 6983}
{"pred": " FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "length": 7140}
{"pred": " Yes.", "answers": ["Yes", "Yes"], "length": 7156}
{"pred": " No.", "answers": "Yes", "length": 6949}
{"pred": " No.", "answers": "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate", "length": 6949}
{"pred": " Tweets containing offensive words and slurs which are not hate or offensive in all cases and writers of them used this type of language in their daily communications.", "answers": "Waseem-dataset, Davidson-dataset,", "length": 6959}
{"pred": " Waseem and Hovey, and Davidson et al. \n\nQuestion: Which machine learning-based approaches are used?\nAnswer: Supervised machine learning-based approaches.\n\nQuestion: What is the main difference between the driven lattice gas models and the equilibrium lattice gas?\nAnswer: The driven lattice gas models (IDLG and RDLG) distinguish between the alternative order parameter O, while the equilibrium lattice gas (LG) does not.\n\nQuestion: What is the prediction of the Gaussian theory for the exponent α?\nAnswer: α = 1/8.\n\nQuestion: What is the prediction of the Gaussian theory for the exponent α when the system is", "answers": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "length": 6947}
{"pred": " Waseem and Hovy, Davidson et al., and Waseem et al.", "answers": "BERT based fine-tuning, Insert nonlinear layers, Insert Bi-LSTM layer, Insert CNN layer", "length": 6945}
{"pred": " Four different fine-tuning approaches are implemented that exploit pre-trained BERTbase transformer encoders for the classification task. \n\nQuestion: What is the effect of using the pre-trained BERT model and fine-tuning it on the downstream task?\nAnswer: The pre-trained BERT model and fine-tuning it on the downstream task outperforms previous works in terms of precision, recall, and F1-score.\n\nQuestion: What is the main reason for the high misclassifications of hate samples as offensive?\nAnswer: The pre-trained BERT model can differentiate hate and offensive samples accurately by leveraging knowledge-aware language understanding that it has, and the", "answers": "sampling tweets from specific keywords create systematic and substancial racial biases in datasets", "length": 6949}
{"pred": " Data collection biases and annotation biases. \n\nQuestion: What is the effect of biases in the data?\nAnswer: The model can differentiate hate and offensive samples accurately by leveraging knowledge-aware language understanding that it has. \n\nQuestion: What is the main reason for high misclassifications of hate samples as offensive?\nAnswer: The pre-trained BERT model has learned general knowledge from normal textual data without any purposely hateful or offensive language. \n\nQuestion: What is the value of the exponent α for the Ising universality class?\nAnswer: 1/10. \n\nQuestion: What is the value of the exponent α for the IDLG and RDL", "answers": "Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters", "length": 6946}
{"pred": " biases from data collection and rules of annotation.", "answers": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "length": 6947}
{"pred": " McPherson. \n\nQuestion: What is the population of McPherson County as of the 2020 census?\nAnswer: 30,223.\n\nQuestion: What is the name of the county in Kansas that is named after Civil War General James B. McPherson?\nAnswer: McPherson County.\n\nQuestion: What is the name of the largest city in McPherson County?\nAnswer: McPherson.\n\nQuestion: What is the name of the county established in 1860 by the passage of a bill by S. N. Wood?\nAnswer: Peketon County.\n\nQuestion: What is the name of the county that", "answers": ["McPherson."], "length": 6447}
{"pred": " Yes.", "answers": ["Yes", "Yes"], "length": 7022}
{"pred": " Ternary Trans-CNN model. \n\nQuestion: What is the previous work's accuracy?\nAnswer: 83.9%. \n\nQuestion: What is the previous work's dataset?\nAnswer: 3189 rows of text messages. \n\nQuestion: What is the previous work's model architecture?\nAnswer: 3 layers of Convolution 1D having filter sizes of 15, 12 and 10 and kernel size of 3 followed by 2 dense fully connected layer of size 64 and 3. \n\nQuestion: What is the previous work's activation function?\nAnswer: ReLU activation. \n\nQuestion: What is the", "answers": "Ternary Trans-CNN", "length": 6072}
{"pred": " HEOT \n\nQuestion: What is the name of the language blend?\nAnswer: Hinglish \n\nQuestion: What is the approximate number of people who speak Hinglish?\nAnswer: 350 million \n\nQuestion: What is the name of the model architecture used?\nAnswer: Ternary Trans-CNN \n\nQuestion: What is the accuracy of the Ternary Trans-CNN model?\nAnswer: 83.90 \n\nQuestion: What is the name of the dataset used for training the model?\nAnswer: HEOT \n\nQuestion: What is the number of rows in the dataset?\nAnswer: 3189 \n\nQuestion: What is the", "answers": "HEOT , A labelled dataset for a corresponding english tweets", "length": 6069}
{"pred": " 3189 rows of text messages.", "answers": "3189 rows of text messages", "length": 6070}
{"pred": " 3189 rows of text messages.", "answers": "Resulting dataset was 7934 messages for train and 700 messages for test.", "length": 6070}
{"pred": " The dataset was obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from Twitter for the conversations happening in the Indian subcontinent. A labelled dataset for a corresponding English tweets were also obtained from a study conducted by Davidson et al. \n\nQuestion: What is the main challenge in abusive language detection?\nAnswer: The major reason of the failure in abusive language detection comes from its subjectivity and context-dependent characteristics.\n\nQuestion: What is the name of the model that achieved the highest accuracy for hate speech detection?\nAnswer: Bidirectional LSTM with 32 units.\n\nQuestion: What is the name", "answers": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "length": 6070}
{"pred": " No.", "answers": "No", "length": 6072}
{"pred": " Naïve Bayes, Support Vector Machine (SVM), Logistic Regression (LR), Random Forests (RF), Gradient Boosted Trees (GBT), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), HybridCNN.", "answers": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "length": 6071}
{"pred": " No.", "answers": "No", "length": 6075}
{"pred": " ROUGE, Human evaluation.", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "length": 6253}
{"pred": " Renormalization.", "answers": ["Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets."], "length": 7506}
{"pred": " They use a bilingual dictionary to translate each word in the source language into English.", "answers": ["Unanswerable", "CFILT-preorder system"], "length": 6817}
{"pred": " The algorithm was offered 10 models and selected 5 of them for the final ensemble. The single models were selected using the following algorithm: starting with the best performing model according to validation performance, then trying to add the best performing model that had not been previously tried, keeping it in the ensemble if it improved its validation performance and discarding it otherwise. This way they gradually tried each model once. They used the BookTest validation dataset for this procedure.", "answers": ["simply averaging the predictions from the constituent single models"], "length": 6732}
{"pred": " Bi-directional and uni-directional models.", "answers": ["uni-directional model to augment the decoder", "bi-directional language model to augment the sequence to sequence encoder ,  uni-directional model to augment the decoder"], "length": 6433}
{"pred": " December 11, 1928.", "answers": ["Goodwin became a Naval aviator in January 1929."], "length": 5893}
{"pred": " Yes.", "answers": ["Yes", "Yes"], "length": 7335}
{"pred": " $m \\sim t^{1/2}$ and $O \\sim t^{\\alpha} L_\\parallel^{-1/2}$.", "answers": ["It is well described by the Gaussian theory."], "length": 7200}
{"pred": " Yes.", "answers": ["Yes", "Yes"], "length": 7305}
{"pred": " more than 120.", "answers": ["Margaret Way wrote more than 120 novels."], "length": 6070}
{"pred": " Kannada, Hindi, Telugu, Malayalam, Bengali, English, and another language.", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "length": 6247}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 5998}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6691}
{"pred": " Romance novels and women's fiction.", "answers": ["Romance novels and women's fiction."], "length": 6393}
{"pred": " Environmental fluctuation and uncertainty, and the details of the task the artificial organisms are aiming to solve.", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6580}
{"pred": " No. \n\nQuestion: Is hate speech defined in legal literature?\nAnswer: Yes. \n\nQuestion: Is hate speech detected in multimodal publications?\nAnswer: Yes. \n\nQuestion: Is hate speech detected in textual publications?\nAnswer: Yes. \n\nQuestion: Is hate speech detected in images?\nAnswer: No. \n\nQuestion: Is hate speech detected in multimodal publications?\nAnswer: Yes. \n\nQuestion: Is hate speech detected in multimodal publications using CNN and RNN?\nAnswer: Yes. \n\nQuestion: Is hate speech detected in multimodal publications using CNN and RNN with multimodal architectures?\nAnswer: Yes. \n\nQuestion: Is", "answers": "Unanswerable", "length": 6580}
{"pred": " $150,000$ tweets.", "answers": " $150,000$ tweets", "length": 6580}
{"pred": " The proposed multimodal models do not outperform the textual models.", "answers": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "length": 6588}
{"pred": " Noisy data, complexity and diversity of multimodal relations, and small set of multimodal examples.", "answers": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "length": 6593}
{"pred": " F-score, Area Under the ROC Curve (AUC), and mean accuracy (ACC).", "answers": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "length": 6583}
{"pred": " Twitter API. \n\nQuestion: What is the goal of the proposed model?\nAnswer: To detect hate speech publications based on the context given by both data modalities.\n\nQuestion: What is the dataset used in the proposed model?\nAnswer: MMHS150K.\n\nQuestion: What is the main challenge of the proposed task?\nAnswer: Noisy data, complexity and diversity of multimodal relations, and small set of multimodal examples.\n\nQuestion: What is the performance of the proposed model?\nAnswer: The proposed multimodal models do not outperform the textual models.\n\nQuestion: What is the main limitation of the proposed multimodal models?\nAnswer:", "answers": "Twitter API", "length": 6585}
{"pred": " 150000. \n\nQuestion: What is the goal of this work?\nAnswer: The goal is to distinguish between publications using the same key offensive words that constitute or not an attack to a community (hate speech).\n\nQuestion: What is the main challenge of the proposed task and dataset?\nAnswer: Noisy data, complexity and diversity of multimodal relations, and small set of multimodal examples.\n\nQuestion: What is the performance of the proposed multimodal models compared to the textual models?\nAnswer: The proposed multimodal models do not outperform the textual models.\n\nQuestion: What is the main contribution of this work?\nAnswer: The creation", "answers": "$150,000$ tweets", "length": 6589}
{"pred": " LSTM, Davison method, random scores.", "answers": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "length": 6583}
{"pred": " Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6584}
{"pred": " 3 different workers. \n\nQuestion: What is the total number of tweets in the dataset?\nAnswer: 150,000.\n\nQuestion: What is the total number of hate tweets in the dataset?\nAnswer: 36,978.\n\nQuestion: What is the total number of not hate tweets in the dataset?\nAnswer: 112,845.\n\nQuestion: What is the number of hate sub-categories in the dataset?\nAnswer: 6.\n\nQuestion: What is the number of hate sub-categories in the dataset?\nAnswer: 5.\n\nQuestion: What is the number of hate sub-categories in the dataset?\nAnswer: 4.\n\nQuestion:", "answers": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "length": 6591}
{"pred": " No.", "answers": ["No"], "length": 7152}
{"pred": " Linear SVM, Bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN) models.", "answers": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "length": 6901}
{"pred": " The dataset is different from pre-existing ones in that it includes annotation of type and target of offensive language, which is not present in other datasets.", "answers": "no prior work has explored the target of the offensive language", "length": 6905}
{"pred": " English. \n\nQuestion: What is the main strategy to tackle the problem of offensive content in social media?\nAnswer: Train systems capable of recognizing offensive content, which then can be deleted or set aside for human moderation. \n\nQuestion: What is the main focus of the proposed hierarchical three-level annotation model?\nAnswer: To distinguish between whether language is offensive or not, and type (B) and target (C) of the offensive language. \n\nQuestion: What is the name of the dataset created in the passage?\nAnswer: OLID (OffensEval dataset). \n\nQuestion: What is the main goal of the proposed framework?\nAnswer: To", "answers": "English", "length": 6900}
{"pred": " 14,100. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment?\nAnswer: 395. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the IND class?\nAnswer: 2,407. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the GRP class?\nAnswer: 1,075. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the OTH class?\nAnswer: 395. \n\nQuestion: What is the size of the", "answers": "14,100 tweets", "length": 6902}
{"pred": " 14,100. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment?\nAnswer: 395. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the IND class?\nAnswer: 2,407. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the GRP class?\nAnswer: 1,075. \n\nQuestion: What is the size of the new dataset for the offensive language target identification experiment for the OTH class?\nAnswer: 395. \n\nQuestion: What is the size of the", "answers": "Dataset contains total of 14100 annotations.", "length": 6902}
{"pred": " Abusive language, cyber-aggression, cyber-bullying, toxic comments, hate speech, and offensive language.", "answers": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "length": 6901}
{"pred": " CNN. \n\nQuestion: What is the main goal of the proposed hierarchical three-level annotation model?\nAnswer: To distinguish between whether language is offensive or not, and type and target of the offensive language. \n\nQuestion: What is the main task of the proposed framework?\nAnswer: To identify the interpretable latent dynamics of a system. \n\nQuestion: What is the main difference between the proposed framework and other frameworks?\nAnswer: The proposed framework only needs the value of the observables, and not their derivatives, as training data. \n\nQuestion: What is the main application of the proposed framework?\nAnswer: To model high-fidelity simulations of critical", "answers": "CNN ", "length": 6900}
{"pred": " Six. \n\nQuestion: What is the name of the dataset created in the passage?\nAnswer: OLID.\n\nQuestion: What is the main goal of the proposed hierarchical three-level annotation model?\nAnswer: To capture the similarities among prior work and differentiate between whether the (abusive) language is directed towards a specific individual or entity or towards a generalized group and whether the abusive content is explicit or implicit.\n\nQuestion: What is the name of the task that the authors participated in?\nAnswer: SemEval 2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).\n\nQuestion: What is the name", "answers": "five annotators", "length": 6899}
{"pred": " Posts that do not contain offense or profanity; Offensive (OFF): We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.", "answers": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "length": 6901}
{"pred": " Level A, Level B, Level C.", "answers": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "length": 6903}
{"pred": " 50% of the dataset comes from political keywords and 50% come from non-political keywords.", "answers": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "length": 6904}
{"pred": " ROUGE, Human evaluation.", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "length": 6253}
{"pred": " Translations with a score that was too low were manually inspected and sent back to the translators when needed. Perplexity of the translations using a language model trained on a large amount of clean monolingual data. The ratio of English characters in the translations. VizSeq BIBREF16 to calculate similarity scores between transcripts and translations based on LASER cross-lingual sentence embeddings BIBREF17. Samples with low scores were manually inspected and sent back for translation when needed. Overlaps of train, development and test sets in terms of transcripts and voice clips (via MD5 file hashing), and confirm they are totally disjoint.", "answers": ["Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "computed sentence-level BLEU, We manually inspected examples where the source transcript was identical to the translation, measured the perplexity of the translations, computed the ratio of English characters in the translations, calculate similarity scores between transcripts and translations"], "length": 6684}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7215}
{"pred": " No.", "answers": ["No"], "length": 6501}
{"pred": " 33.16% of speakers are women, but only 22.57% of total speech time is occupied by women.", "answers": ["Women represent 33.16% of the speakers"], "length": 6759}
{"pred": " No. \n\nQuestion: Does the paper discuss the difficulty of Information Extraction tasks in the biomedical domain?\nAnswer: Yes. \n\nQuestion: What is the main problem in BioIE?\nAnswer: Similar to those in Information Extraction. \n\nQuestion: What is the main problem in BioIE according to Passage 1?\nAnswer: Similar to those in Information Extraction tasks. \n\nQuestion: What are the main problems in BioIE according to Passage 1?\nAnswer: Similar to those in Information Extraction tasks. \n\nQuestion: What are the main problems in BioIE according to Passage 1?\nAnswer: Similar to those in Information Extraction tasks. \n\nQuestion", "answers": ["Yes"], "length": 6907}
{"pred": " Nuclear power.", "answers": "anti-nuclear-power", "length": 7167}
{"pred": " 3.", "answers": "eight layers", "length": 7166}
{"pred": " abortion, gay rights, Obama, and marijuana.", "answers": "abortion, gay rights, Obama, marijuana", "length": 7165}
{"pred": " abortion, gay rights, Obama, and marijuana.", "answers": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "length": 7165}
{"pred": " 505,412. \n\nQuestion: What is the size of the English data?\nAnswer: 977. \n\nQuestion: What is the size of the development set?\nAnswer: Randomly selected from what was left. \n\nQuestion: What is the size of the testing set?\nAnswer: Randomly selected from what was left. \n\nQuestion: What is the number of posts for each stance in the FBFans dataset?\nAnswer: About twenty percent of the posts were labeled with a stance, and the number of supportive (Sup) posts was much larger than that of the unsupportive (Uns) ones. \n\nQuestion: What", "answers": "32,595", "length": 7165}
{"pred": " Yes.", "answers": "No", "length": 7163}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, 7) UTCNN without the LDA model, 8) UTCNN without comments.", "answers": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "length": 7162}
{"pred": " Conditional random fields (CRF), word sense knowledge, bidirectional RNN classifier, Google n-gram and word2vec, hidden Markov model and a cyclic dependency network, supervised approach, weakly supervised approach, rule-based system, UWAV system.", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "length": 6867}
{"pred": " various approaches have been proposed for modelling urban regions, identifying points-of-interest, and itineraries.", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "length": 6118}
{"pred": " Wikipedia and Reddit CMV.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "length": 6538}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7055}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 7147}
{"pred": " English-German dataset.", "answers": ["the English-German dataset"], "length": 7037}
{"pred": " Multinomial Naive Bayes classifier.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "length": 6743}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7168}
{"pred": " They conducted a survey among engineers and identified a spectrum of three typical personas. They also analyzed the NLP jobs submitted to a commercial centralized GPU cluster, which showed that about 87.5% NLP related jobs belong to a few common tasks, and more than 90% of the networks were composed of several common components.", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 6687}
{"pred": " Several methods are considered to find examples of biases and unwarranted inferences, including manually detecting stereotypes, biases, and odd phrases, tagging all descriptions with part-of-speech information, leveraging the structure of Flickr30K Entities, and applying Louvain clustering to the coreference graph.", "answers": ["spot patterns by just looking at a collection of images, tag all descriptions with part-of-speech information, I applied Louvain clustering", "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging"], "length": 6836}
{"pred": " LSTMs.", "answers": ["Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM"], "length": 7140}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 6786}
{"pred": " Medicare requires an adjustment to your monthly Medicare Part B medical insurance and Medicare prescription drug coverage premiums. This affects less than five percent of people with Medicare. Most people don t pay higher premiums. If you have higher income, you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage.", "answers": "The law requires an adjustment to your monthly Medicare Part B medical insurance and Medicare prescription drug coverage premiums . This affects less than five percent of people with Medicare . Most people don t pay higher premiums", "length": 6606}
{"pred": " Social Security uses the most recent federal tax return the IRS provides to us. If you must pay higher premiums, we use a sliding scale to calculate the adjustments, based on your modified adjusted gross income MAGI. Your MAGI is your total adjusted gross income and tax - exempt interest income.", "answers": "Social Security uses the most recent federal tax return the IRS provides to us . you must pay higher premiums", "length": 6597}
{"pred": " No", "answers": "we use a sliding scale to calculate the adjustments , based on your modified adjusted gross income MAGI . Your MAGI is your total adjusted gross income and tax - exempt interest income .", "length": 6589}
{"pred": " You can find your local SHIP contact information in the back of your Medicare & You 2020 Handbook online, or you can request it when you call.", "answers": "You can find your local SHIP contact information in the back of your Medicare & You 2020 Handbook online", "length": 6611}
{"pred": " You ll pay monthly premiums plus an additional amount, which is based on what you report to the IRS.", "answers": "you ll pay monthly premiums plus an additional amount , which is based on what you report to the IRS . Because individual plan premiums vary , the law specifies that the amount is determined using a base premium .", "length": 6614}
{"pred": " this law does not apply to you.", "answers": " this law does not apply to you ", "length": 6599}
{"pred": "  You ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage.", "answers": "you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage . We call the additional amount the income - related monthly adjustment amount ", "length": 6594}
{"pred": " Yes.", "answers": ["Yes", "Yes"], "length": 6388}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6771}
{"pred": " \nTo open a driving school, you will need to meet DMV s requirements below for your place of business a qualified, experienced instructor see below to meet DMV s requirements for records receipts, etc. and record-keeping authority to operate a business in New York State and this location \n\nRequirements \nYou must receive approval from DMV for the use of the name for your driving school see also Request for Approval of Driving School Name [2] before you submit an application. be at least 50 square feet, which is accessible by your customers be in a suitable building see Part 76.2 for details be at least 1,", "answers": "Sure. If you're interested into opening a driving school, you must know that is necessary to get a DMV's approval for the use of its name in your school.", "length": 6254}
{"pred": " Yes, you must also have a classroom that meets DMV's requirements.", "answers": "Good. If you're planning to do that, then you must have adequate facilities and an experienced instructor that holds a valid instructor's card, with at least 1,000 hours of experience. In any case, you must request a premises check.", "length": 6256}
{"pred": " Submit the Request for Approval of Driving School Name [2] form MV-299.3 that shows your Driving School name was approved by the DMV, a completed Driving School License Application [5] form MV-521, a completed Personal History [6] form MV-521.1 for each owner, partner, corporate officer, agent, employee and major stockholder 20% or more of stock listed on your Driving School Application MV-521, and pay the application fee of $50.00 non-refundable.", "answers": "LLCs have to submit a copy of their Filing Receipt from the Department of State.", "length": 6260}
{"pred": " submit all required items to NYS DMV Bureau of Consumer & Facility Services Application Unit P.O. Box 2700 Albany, NY 12220 - 0700.", "answers": "Instructions to file can be found on the NY State Department of State website.", "length": 6234}
{"pred": " You may apply by visiting the NY State DTF website.", "answers": "The Certificate of Authority and Sales Tax ID number are issued by the New York State Department of Taxation and Finance.  You can apply by visiting the NY State DTF website.", "length": 6238}
{"pred": " No, DMV does not provide Surety Bonds, you must contact a surety insurance company and have them fill out Dealer Bond Under NY State Vehicle and Traffic Law Section 415 6-B pdf [5] VS-3.", "answers": "The DMV does not provide Surety Bonds. You will have to contact a surety insurance company and have them fill out the Dealer Bond Under NY State Vehicle and Traffic Law Section 415.", "length": 6238}
{"pred": " at least 3 feet wide by 2 feet tall.", "answers": "The sign must measure at least 3 feet wide by 2 feet tall, and it needs to be a red background with white lettering.", "length": 6244}
{"pred": " various approaches have been proposed for modelling urban regions, identifying points-of-interest, and itineraries.", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "length": 6118}
{"pred": " Apply Online The easiest and quickest way to apply for retirement, spouse's, ex - spouse's, or Medicare benefits is to apply online. Apply By Phone Call us at If you are deaf or hard of hearing, you can call us at TTY Apply In Person Visit your local Social Security office. Call first to make an appointment.", "answers": "Is this for benefits for your family?", "length": 6408}
{"pred": " Yes.", "answers": "If any of your qualified family members apply for benefits with you ,we will ask you for their Social Security numbers and their birth certificates .", "length": 6410}
{"pred": " Yes", "answers": "Use the PBGC's Find an Unclaimed Pension tool to find out if you have unclaimed benefits", "length": 6416}
{"pred": " You must be at least 61 years and 9 months old to apply for retirement benefits. If you are already age 62, you may be able to start your benefits in the month you apply.", "answers": "Yes, If any of the qualified family members apply for benefits with you ,we will ask you for their Social Security numbers and their birth certificates .", "length": 6425}
{"pred": " The amount needed for a work credit changes from year to year.", "answers": "The amount needed for a work credit changes from year to year. In 2019, for example, you earn one credit for every $ 1,360 in wages or self-employment income.", "length": 6431}
{"pred": " 1.7K bilingual ancient-modern Chinese articles from the internet.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "length": 6916}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6952}
{"pred": " By conducting a survey among engineers.", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 6420}
{"pred": " John F. Kennedy Profiles in Courage Award.", "answers": ["In 2009, Brooksley Born received the John F. Kennedy Profiles in Courage Award."], "length": 6612}
{"pred": " Fuller's Ranch.", "answers": ["The first white settlement in McPherson County was Fuller's Ranch, established by Charles O. Fuller."], "length": 6148}
{"pred": " $m \\sim t^{1/2}$ and the Binder cumulant $g$ of the lowest transverse mode is zero in this regime. The alternative order parameter $O,$ however, distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases.", "answers": ["It is well described by the Gaussian theory."], "length": 7784}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7168}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6841}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 7477}
{"pred": " English. \n\nQuestion: What is the main goal of the paper?\nAnswer: The paper presents OLID, a new dataset with annotation of type and target of offensive language.\n\nQuestion: What is the main difference between the driven lattice gas models and the equilibrium lattice gas?\nAnswer: The driven lattice gas models (IDLG and RDLG) have a different dynamical behaviour of the order parameter O compared to the equilibrium lattice gas (LG).\n\nQuestion: What is the prediction of the Gaussian theory for the exponent α?\nAnswer: α = 1/8.\n\nQuestion: What is the prediction of the Gaussian theory for the exponent α when", "answers": ["English", "English ", "English"], "length": 6538}
{"pred": " It is a characteristic of layer-hybridized electronic states and has a band geometric origin in the momentum space curl of interlayer BCP.", "answers": ["The momentum space curl of the interlayer Berry connection polarizability generates the crossed nonlinear dynamical Hall effect."], "length": 6860}
{"pred": " You ll be covered for services and supplies when we determine they are medically necessary and were received from an authorized provider. Covered services include : Ambulance service Ambulatory surgery Durable medical equipment DME Family planning and maternity Hospice Inpatient services Mental health services Outpatient services Pharmacy prescription medicines Skilled nursing care Transplants When you re signed up for CHAMPVA, you ll get a copy of the CHAMPVA Program Guide. This guide will tell you more about covered and non - covered services and supplies.", "answers": "Are you the spouse or surviving spouse of or a child of a Veteran with disabilities or a Veteran who has died ?", "length": 7235}
{"pred": " no", "answers": "If you don t qualify for TRICARE the Department of Defense s health care program for active - duty and retired service members and their families", "length": 7232}
{"pred": " You may be able to get health insurance through the Civilian Health and Medical Program of the Department of Veterans Affairs CHAMPVA.", "answers": "you may be able to get health insurance through the Civilian Health and Medical Program of the Department of Veterans Affairs CHAMPVA .", "length": 7240}
{"pred": " Yes, you can call our caregiver support line at 855 - 260 - 3274.", "answers": "Yes, you can contact the caregiver support line at 855-260-3274", "length": 7255}
{"pred": " You ll need to apply for these benefits. To apply, fill out an Application for the Program of Comprehensive Assistance for Family Caregivers VA Form 10 - 10CG. You ll need identification and health coverage information for both you and your Veteran and you ll both need to sign and date the form.", "answers": "You will qualify for this program based on your Veteran’s qualifications. You may be eligible if the Veteran you’re caring for meets both of the requirements  ", "length": 7242}
{"pred": " yes", "answers": "Okay. Does the veteran you are caring for have a serious injury including traumatic brain injury, psychological trauma, or other mental disorder that was caused or made worse by their active-duty service on or after September 11, 2001?", "length": 7237}
{"pred": " no", "answers": "If that is true then you are not eligible for this benefit.", "length": 7237}
{"pred": " English-German dataset.", "answers": ["the English-German dataset"], "length": 7094}
{"pred": " Our system (MIC-CIS) is ranked 3rd (out of 12 participants) and 4th (out of 25 participants) in FLC and SLC tasks, respectively.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "length": 6568}
{"pred": " We use those dimensions as high-level categories of a qualitative annotation schema for annotating question, expected answer and the corresponding context. We further enrich the qualitative annotations by a metric based on lexical cues in order to approximate a lower bound for the complexity of the reading comprehension task.", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "length": 6516}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7113}
{"pred": " No.", "answers": ["No"], "length": 6661}
{"pred": " a context-agnostic MT system.", "answers": [" MT system on the data released by BIBREF11", "Transformer base, two-pass CADec model"], "length": 6924}
{"pred": " Nuclear power.", "answers": "anti-nuclear-power", "length": 7167}
{"pred": " 3.", "answers": "eight layers", "length": 7166}
{"pred": " abortion, gay rights, Obama, and marijuana.", "answers": "abortion, gay rights, Obama, marijuana", "length": 7165}
{"pred": " abortion, gay rights, Obama, and marijuana.", "answers": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "length": 7165}
{"pred": " 505,412. \n\nQuestion: What is the size of the English data?\nAnswer: 977. \n\nQuestion: What is the size of the development set?\nAnswer: Randomly selected from what was left. \n\nQuestion: What is the size of the testing set?\nAnswer: Randomly selected from what was left. \n\nQuestion: What is the number of posts for each stance in the FBFans dataset?\nAnswer: About twenty percent of the posts were labeled with a stance, and the number of supportive (Sup) posts was much larger than that of the unsupportive (Uns) ones. \n\nQuestion: What", "answers": "32,595", "length": 7165}
{"pred": " Yes.", "answers": "No", "length": 7163}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, 7) UTCNN without the LDA model, 8) UTCNN without comments.", "answers": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "length": 7162}
{"pred": " Yes.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "length": 7250}
{"pred": " No.", "answers": ["Yes", "Unanswerable"], "length": 7109}
{"pred": " 3.", "answers": ["eight layers"], "length": 7166}
{"pred": " BIBREF0, PubMed, PMC, CORD-19, SQuAD, BC5CDR, and Deepset-AI Covid-QA.", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "length": 7331}
{"pred": " Sentence corpus (S) from aristo2016:combining.", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 6751}
{"pred": " 61.4% and 56.7% for TupleInf and TableILP respectively.", "answers": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "length": 6748}
{"pred": " Yes.", "answers": "No", "length": 6746}
{"pred": " No.", "answers": "No", "length": 6748}
{"pred": " ElasticSearch query.", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 6751}
{"pred": " No.", "answers": "Yes", "length": 6747}
{"pred": " S (Sentence corpus) and also web pages.", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 6751}
{"pred": " Open IE v4.", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 6751}
{"pred": " No.", "answers": "Yes", "length": 6748}
{"pred": " 335,698. \n\nQuestion: What is the size of the dataset in terms of entities?\nAnswer: 4,600,465. \n\nQuestion: What is the size of the dataset in terms of entities in the U.S.?\nAnswer: 197,527. \n\nQuestion: What is the size of the dataset in terms of entities in the U.S. in terms of users?\nAnswer: 153,209. \n\nQuestion: What is the size of the dataset in terms of entities in the U.S. in terms of male users?\nAnswer: 52,725. \n\nQuestion: What is the size of the", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "length": 6078}
{"pred": " By analyzing the distribution of words related to people's core values, such as Religion and Hard Work, and using the Meaning Extraction Method (MEM).", "answers": ["using the Meaning Extraction Method", "Unanswerable"], "length": 6502}
{"pred": " 14 million words. \n\nQuestion: What is the size of the dataset?\nAnswer: 16225 unique words. \n\nQuestion: What is the size of the dataset?\nAnswer: 72782 unique words. \n\nQuestion: What is the size of the dataset?\nAnswer: 6946 sentences. \n\nQuestion: What is the size of the dataset?\nAnswer: 32 x 32. \n\nQuestion: What is the size of the dataset?\nAnswer: 10. \n\nQuestion: What is the size of the dataset?\nAnswer: 3,600. \n\nQuestion: What is the size of the dataset?\nAnswer: ", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "length": 7004}
{"pred": " https://python.quectel.com/doc/doc/Advanced_development/zh/QuecCloud.html", "answers": ["Online documentation, QuecPython community, online support: QQ group 445121768."], "length": 4701}
{"pred": " Closing of the sale of the Amplifier and Micro-Optics businesses to II-VI, reduction of the company's headcount from approximately 3,000 to around 2,200 by January 1, 2014, and reduction of executive pay by approximately 15%.", "answers": "Oclaro has been implementing a significant restructuring plan, which includes closing our second major asset sale and initiating a company-wide reorganization to strengthen our market focus. We've also refined our manufacturing strategy and started the process of resizing the company by implementing global headcount reductions. The company is downsizing from approximately 3,000 employees to about 1,500 by July 1, 2014, and the executive team and Board of Directors will reduce our pay by 15%. Oclaro has also taken steps to simplify its global footprint by reducing the number of global sites from about 20 to 10 by the end of June 2014. This restructuring is expected to result in a $10 million to $12 million reduction in quarterly spending.", "length": 6776}
{"pred": " Leverage its core competencies and strong customer relationships to effectively and profitably compete in high growth markets.", "answers": "Oclaro plans to compete in high growth markets by leveraging its core competencies and strong customer relationships. Our strategy includes the utilization of technology leadership in indium phosphide and lithium niobate materials, devices and photonic integration to offer differentiated products at both the component and module level for high-speed transmission in client and line side applications. The company has been reorganized into two business divisions, one for the client side (optical connectivity) and one for the line side (integrated photonics), with each division responsible for its own operations and contributing about half of the company's revenues.", "length": 6765}
{"pred": " Strong demand for 100 gigabit CFP product lines, 10 gigabit tunable products, and transceivers used in wireless backhaul applications, and robust demand in both the telecom and datacom market segments despite some uncertainty about the exact timing of large scale 100G deployments in China.", "answers": "Oclaro has seen robust demand in both the telecom and datacom market segments, with strong demand for our 100 gigabit CFP product lines, 10 gigabit tunable products, and transceivers used in wireless backhaul applications. We have also experienced a significant spike in demand for our 40 gigabit line side product lines. Despite these promising developments, the company has faced challenges due to delays in transferring products from Shenzhen to our contract manufacturers, which have impacted customer deliveries and constrained revenue output. However, with changes in our manufacturing strategy, Oclaro expects to improve our customer deliveries and mitigate risks in manufacturing transitions.", "length": 6765}
{"pred": " The proceeds were used to repay debt and to restructure the company.", "answers": "Some of the proceeds from the $185 million generated by product line sales were used to repay Oclaro's debt. The remaining resources are being applied to restructure the company, complete its manufacturing transfers, and fund its operating losses to breakeven.", "length": 6770}
{"pred": " $20 million to $25 million.", "answers": "Oclaro expects to spend between $20 million and $25 million to restructure the company and lower its burn rate. With the completion of the restructuring, we estimate debt on revenues of approximately $110 million per quarter, non-GAAP gross margins of 20%, and operating expenses of 25% of sales would help them achieve adjusted EBITDA breakeven. The company aims to achieve this breakeven objective in one year.", "length": 6769}
{"pred": " We did not report bookings in the September quarter. We reported revenue. Our revenue was $96.6 million, which was up 1% from the prior quarter. The revenue was not very linear, however, as the 40G and 100G transmission products grew over 20% from the prior quarter, while the 10G and lower bit rate products declined 11%.", "answers": "Well, I can’t really speak to the linearity and the order patterns, but I would say that, right now, we are not specifically reporting on bookings. But I would say that on a qualitative basis, we had a good month for bookings. It was actually a strong month for bookings.", "length": 6794}
{"pred": " Yes.", "answers": "Yes, I think you should use the guidance we gave for the December quarter in combination with the EBITDA model and fill in the next year around those parameters.", "length": 6809}
{"pred": " We have seen robust demand in both the telecom and datacom market segments despite some uncertainty about the exact timing of large scale 100G deployments in China. We have enjoyed strong demand for 100 gigabit CFP product lines, our 10 gigabit tunable products as well as transceivers used in wireless backhaul applications. We have also seen very large spike in demand for our 40 gigabit line side product lines, which are used in deployments in North America.", "answers": "I think that we broke out the percent revenue. The delay in the 100G China Telecom that has been moving target I think since the summer. But it looks good and we feel we are pretty well positioned there. We noted that Huawei was no longer a 10% customer. And I just wanted to ratchet up the reason for that. In the past, our largest 980 pump customer was Huawei and of course that business traveled with them. But we are continuing to view Huawei as a very good, very important customer and we are very well positioned there going forward. Probably the biggest notable trend Rob is in North America with the 40G business, it’s really on the line side, it has really picked up for us last quarter, this quarter. And we are expecting to see residual next quarter well beyond with I think we would have been expecting six months, nine months ago.", "length": 6805}
{"pred": " No.", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 7275}
{"pred": " No", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 7266}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing.", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 7292}
{"pred": " After your VA claim exam, we ll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating.", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 7289}
{"pred": " Yes. The VA offers a range of assistance programs, including disability compensation, vocational rehabilitation, and education benefits.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 7286}
{"pred": " Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 7288}
{"pred": " Information about VA disability compensation, VA claim exam, VA claim process, VA benefits and services, and VA disability ratings.", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 7266}
{"pred": " The staff at your local VA medical center or a local doctor's office that we partner with will contact you. They will either send you a letter by mail with the date and time of your exam, or call you to find a time that works for you. Make sure both the VA regional office and the VA medical center nearest you have your up-to-date address, phone number, and email address so you get your exam notice in time. Call the number provided right away to confirm the time and location of your exam.", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 7270}
{"pred": " Linear SVM, Bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN).", "answers": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "length": 6910}
{"pred": " The dataset distinguishes between the type and target of the offensive language, whereas prior work focuses on different aspects of offensive language.", "answers": "no prior work has explored the target of the offensive language", "length": 6914}
{"pred": " English. \n\nQuestion: What is the name of the dataset created in Passage 1?\nAnswer: OLID.\n\nQuestion: What is the main strategy to tackle the problem of offensive content in social media?\nAnswer: Train systems capable of recognizing offensive content.\n\nQuestion: What is the main difference between the driven lattice gas models (IDLG and RDLG) and the equilibrium lattice gas (LG)?\nAnswer: The driven lattice gas models (IDLG and RDLG) have a non-Gaussian nature of higher fluctuating modes, while the equilibrium lattice gas (LG) has a Gaussian nature of higher fluctuating modes.\n\nQuestion: What", "answers": "English", "length": 6909}
{"pred": " 14,100. \n\nQuestion: What is the size of the dataset for answer retrieval?\nAnswer: 128.7M. \n\nQuestion: What is the size of the dataset for answer triggering?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer selection?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer extraction?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer triggering and selection?\nAnswer: 5 times larger than the answer selection dataset. \n\nQuestion: What is the size of the dataset for answer extraction and triggering?\n", "answers": "14,100 tweets", "length": 6911}
{"pred": " 14,100. \n\nQuestion: What is the size of the dataset for answer retrieval?\nAnswer: 128.7M. \n\nQuestion: What is the size of the dataset for answer triggering?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer selection?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer extraction?\nAnswer: Not mentioned. \n\nQuestion: What is the size of the dataset for answer triggering and selection?\nAnswer: 5 times larger than the answer selection dataset. \n\nQuestion: What is the size of the dataset for answer extraction and triggering?\n", "answers": "Dataset contains total of 14100 annotations.", "length": 6911}
{"pred": " Abusive language, cyber-aggression, cyber-bullying, toxic comments, hate speech, and offensive language.", "answers": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "length": 6910}
{"pred": " A CNN-based sentence classifier achieved the best results in all three sub-tasks.", "answers": "CNN ", "length": 6909}
{"pred": " 5. \n\nQuestion: What is the name of the dataset created in Passage 1?\nAnswer: OLID.\n\nQuestion: What is the name of the annotation model proposed in Passage 1?\nAnswer: Hierarchical three-level annotation model.\n\nQuestion: What is the name of the task that the authors are participating in?\nAnswer: SemEval 2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).\n\nQuestion: What is the name of the API used to collect the data?\nAnswer: Twitter API.\n\nQuestion: What is the percentage of the dataset that is offensive?\nAnswer: ", "answers": "five annotators", "length": 6908}
{"pred": " Level A discriminates between offensive (OFF) and non-offensive (NOT) tweets. Not Offensive (NOT): Posts that do not contain offense or profanity; Offensive (OFF): We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.", "answers": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "length": 6910}
{"pred": " Level A, Level B, Level C.", "answers": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "length": 6912}
{"pred": " 395, 107, 30%.", "answers": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "length": 6913}
{"pred": " The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7167}
{"pred": " The models are evaluated by the retention rate of tokens and the accuracy of a scheme, which is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence.", "answers": ["by training an autocomplete system on 500K randomly sampled sentences from Yelp reviews", "efficiency of a communication scheme $(q_{\\alpha },p_{\\beta })$ by the retention rate of tokens, which is measured as the fraction of tokens that are kept in the keywords, accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence"], "length": 6681}
{"pred": " February 15, 2010.", "answers": ["KSTP switched to a sports radio format on February 15, 2010."], "length": 6803}
{"pred": " Ternary Trans-CNN model. \n\nQuestion: What is the previous work's accuracy?\nAnswer: 83.9%. \n\nQuestion: What is the previous work's dataset?\nAnswer: 3189 rows of text messages. \n\nQuestion: What is the previous work's model architecture?\nAnswer: 3 layers of Convolution 1D having filter sizes of 15, 12 and 10 and kernel size of 3 followed by 2 dense fully connected layer of size 64 and 3. \n\nQuestion: What is the previous work's activation function?\nAnswer: ReLU activation. \n\nQuestion: What is the", "answers": "Ternary Trans-CNN", "length": 6072}
{"pred": " HEOT \n\nQuestion: What is the name of the language blend?\nAnswer: Hinglish \n\nQuestion: What is the approximate number of people who speak Hinglish?\nAnswer: 350 million \n\nQuestion: What is the name of the model architecture used?\nAnswer: Ternary Trans-CNN \n\nQuestion: What is the accuracy of the Ternary Trans-CNN model?\nAnswer: 83.90 \n\nQuestion: What is the name of the dataset used for training the model?\nAnswer: HEOT \n\nQuestion: What is the number of rows in the dataset?\nAnswer: 3189 \n\nQuestion: What is the", "answers": "HEOT , A labelled dataset for a corresponding english tweets", "length": 6069}
{"pred": " 3189 rows of text messages.", "answers": "3189 rows of text messages", "length": 6070}
{"pred": " 3189 rows of text messages.", "answers": "Resulting dataset was 7934 messages for train and 700 messages for test.", "length": 6070}
{"pred": " The dataset was obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from Twitter for the conversations happening in the Indian subcontinent. A labelled dataset for a corresponding English tweets were also obtained from a study conducted by Davidson et al. \n\nQuestion: What is the main challenge in abusive language detection?\nAnswer: The major reason of the failure in abusive language detection comes from its subjectivity and context-dependent characteristics.\n\nQuestion: What is the name of the model that achieved the highest accuracy for hate speech detection?\nAnswer: Bidirectional LSTM with 32 units.\n\nQuestion: What is the name", "answers": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "length": 6070}
{"pred": " No.", "answers": "No", "length": 6072}
{"pred": " Naïve Bayes, Support Vector Machine (SVM), Logistic Regression (LR), Random Forests (RF), Gradient Boosted Trees (GBT), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), HybridCNN.", "answers": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "length": 6071}
{"pred": " No.", "answers": "No", "length": 6075}
{"pred": " 38 hours.", "answers": ["Unanswerable", "Unanswerable"], "length": 6191}
{"pred": " BIBREF0, BIBREF1, BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6, BIBREF7, BIBREF8, BIBREF9, BIBREF10, BIBREF11, BIBREF12, BIBREF13, BIBREF14, BIBREF15, BIBREF16, BIBREF17, BIBREF18, BIBREF19, BIBREF20, BIBREF21, BIBREF22, BIBREF23, BIBREF24, BIBREF", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "length": 7038}
{"pred": " 2013–2014.", "answers": ["In the 2013-2014 season."], "length": 7059}
{"pred": " No.", "answers": ["No"], "length": 7139}
{"pred": " 23 September 2017. \n\nQuestion: When did English become Prime Minister?\nAnswer: 12 December 2016.\n\nQuestion: Who became Prime Minister after English?\nAnswer: Jacinda Ardern.\n\nQuestion: What was the result of the 2017 general election for the National Party?\nAnswer: National won the largest share of the party vote (44.4%) and the largest number of seats (56).\n\nQuestion: Who became the leader of the National Party after English?\nAnswer: Simon Bridges.\n\nQuestion: What was the result of the 2017 general election for the Labour Party?\nAnswer: The parties holding the balance", "answers": ["23 September."], "length": 6566}
{"pred": " racism, sexism, personal attack.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "length": 6789}
{"pred": " The bigger the receptive field size, the more complete shapes can be reconstructed.", "answers": ["Bigger receptive field size leads to more successful shape completion."], "length": 6247}
{"pred": " No.", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 7141}
{"pred": " No", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 7132}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing.", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 7158}
{"pred": " After your VA claim exam, we ll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating.", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 7155}
{"pred": " Yes. VA disability compensation pay offers a monthly tax-free payment to Veterans who got sick or injured while serving in the military and to Veterans whose service made an existing condition worse. You may qualify for VA disability benefits for physical conditions like a chronic illness or injury and mental health conditions like PTSD that developed before, during, or after service.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 7152}
{"pred": " You can contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 7154}
{"pred": " Information about VA disability compensation, claim process, and other VA benefits and services.", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 7132}
{"pred": " Call 800 - 827 - 1000, or Go to your nearest VA regional benefit office. Find a VA regional benefit office near you.", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 7136}
{"pred": " The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7103}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6942}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, 7) UTCNN without the LDA model, 8) UTCNN without comments.", "answers": ["SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, ecurrent Convolutional Neural Networks, SVM and deep learning models with comment information", "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information"], "length": 7162}
{"pred": " 1000. \n\nQuestion: What is the optimal ratio of expert to crowd annotations for specialized tasks?\nAnswer: The optimal ratio depends on the cost and availability of domain experts.\n\nQuestion: What is the Pearson's correlation coefficient for the LSTM-CRF-Pattern model trained on the reannotated difficult subset and the random subset?\nAnswer: Not mentioned in the passage.\n\nQuestion: What is the F1 score achieved after re-annotating the 600 most-difficult articles?\nAnswer: 68.1%.\n\nQuestion: What is the F1 score achieved by the LSTM-CRF-Pattern model trained on the reannotated difficult", "answers": ["57,505 sentences", "57,505 sentences"], "length": 7167}
{"pred": " No.", "answers": ["No", "No"], "length": 6964}
{"pred": " Environmental fluctuation and uncertainty, and the details of the task the artificial organisms are aiming to solve.", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " He loses his job and the family is forced to move.", "answers": ["After attacking Jacobo at a workers' strike, Ngotho loses his job and Njoroge's family is forced to move."], "length": 6268}
{"pred": " South West Ultras.", "answers": ["South West Ultras fan club."], "length": 6847}
{"pred": " Flickr, structured environmental datasets.", "answers": [" the same datasets as BIBREF7", "same datasets as BIBREF7"], "length": 6120}
{"pred": " General Forbearance, Mandatory Forbearance, or Parent PLUS Borrower Deferment.", "answers": "The two main types are general forbearance and mandatory forbearance.", "length": 6984}
{"pred": " Parent PLUS Borrower Deferment.", "answers": "It would be teacher loan forgiveness if you are performing a teaching service that would qualify you", "length": 6987}
{"pred": " No payments are required during the post-deferment grace period.", "answers": "Income-driven repayment plans base your monthly payments on your income and family size, meaning that in some cases, you payment under this plan could become as low as $0 per month. ", "length": 6989}
{"pred": " Yes, you are eligible for an in-school deferment if you are enrolled at least half-time at an eligible college or career school. If you are a graduate or professional student who received a Direct PLUS Loan, you qualify for an additional six months of deferment after you cease to be enrolled at least half-time.", "answers": "With that option, in most cases your loan will be placed into a deferment automatically based on enrollment information reported by your school, and your loan servicer will notify you that the deferment has been granted. ", "length": 6991}
{"pred": " Yes, you may be eligible for a Military Service and Post-Active Duty Student Deferment.", "answers": "You may be eligible for this deferment if you are on active duty military service in connection with a war, military operation, or national emergency. ", "length": 6990}
{"pred": " Yes.", "answers": "You may be eligible for this deferment. ", "length": 6987}
{"pred": " You may qualify for this deferment if you are enrolled in an approved graduate fellowship program.", "answers": "You could complete the Graduate Fellowship Deferment Request if you are enrolled in an approved graduate fellowship program, which is generally a program that provides financial support to graduate students to pursue graduate studies and research. ", "length": 6979}
{"pred": " They built a dataset of Twitter accounts based on two lists annotated in previous works. \n\nQuestion: What is the main orientation in the previous works?\nAnswer: The main orientation in the previous works is to verify the textual claims/tweets but not their sources.\n\nQuestion: What is the approach proposed in the work?\nAnswer: An approach to detect non-factual Twitter accounts by treating post streams as a sequence of tweets' chunks.\n\nQuestion: What is the main obstacle for detecting suspicious Twitter accounts?\nAnswer: The behavior of mixing some real news with the misleading ones.\n\nQuestion: What is the hypothesis of the authors?\nAnswer: Suspicious accounts have", "answers": "public resources where suspicious Twitter accounts were annotated, list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy", "length": 6554}
{"pred": " $relu$, $selu$, $tanh$", "answers": "relu, selu, tanh", "length": 6557}
{"pred": " LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level) and Top-$k$ replies, likes, or re-tweets.", "answers": "Top-$k$ replies, likes, or re-tweets, FacTweet (tweet-level), LR + All Features (chunk-level), LR + All Features (tweet-level), Tweet2vec, LR + Bag-of-words", "length": 6555}
{"pred": " A sorted sequence of tweets labeled by the label of its corresponding account.", "answers": "Chunks is group of tweets from single account that  is consecutive in time - idea is that this group can show secret intention of malicious accounts.", "length": 6552}
{"pred": " sentiment, emotion, morality, style, words embeddings. \n\nQuestion: What is the approach proposed?\nAnswer: a recurrent neural model using long short-term memory (LSTM) to model the sequential flow of the chunks' tweets. \n\nQuestion: What is the main orientation in the previous works?\nAnswer: verifying the textual claims/tweets but not their sources. \n\nQuestion: What is the dataset used?\nAnswer: a large dataset of tweets using a list of propaganda, hoax and clickbait accounts. \n\nQuestion: What is the baseline used?\nAnswer: logistic regression (LR) classifier. \n\nQuestion: What is the macro-F1", "answers": "Sentiment, Morality, Style, Words embeddings", "length": 6552}
{"pred": " No.", "answers": "Yes", "length": 6561}
{"pred": " words embeddings, style, and morality features.", "answers": "words embeddings, style, and morality features", "length": 6565}
{"pred": " 180 Twitter accounts.", "answers": "Total dataset size: 171 account (522967 tweets)", "length": 6557}
{"pred": " A chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. Each chunk consists of a sorted sequence of tweets. Each tweet in ck_i is represented by a vector v ∈ ℝd, where v is the concatenation of a set of features' vectors, that is v = 〈f1, …, fn 〉. Each feature vector f_i is built by counting the presence of tweet's words in a set of lexical lists. The final representation of the tweet is built by averaging the single word vectors.", "answers": "chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account", "length": 6560}
{"pred": " LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets.", "answers": "LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets", "length": 6556}
{"pred": " 3.", "answers": ["eight layers"], "length": 7166}
{"pred": " Iraq. \n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the main topic of the text?\nAnswer: Iraq.\n\nQuestion: What is the", "answers": ["The main topic of the text is Iraq's politics and current situation."], "length": 7052}
{"pred": " 635hrs of audio data for 7 Indian languages.", "answers": ["Unanswerable", " Paraphrase Database (PPDB) ,  book corpus", "Unanswerable"], "length": 7009}
{"pred": " The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7103}
{"pred": " English.", "answers": ["English", "Simple English"], "length": 6181}
{"pred": " Competitive or even state-of-the-art results for some of the emotion labels on existing, standard evaluation datasets.", "answers": ["Answer with content missing: (Table 3) Best author's model B-M average micro f-score is 0.409, 0.459, 0.411 on Affective, Fairy Tales and ISEAR datasets respectively. "], "length": 7274}
{"pred": " 5.", "answers": ["5."], "length": 6999}
{"pred": " Carnegie Mellon Pronouncing Dictionary, multilingual pronunciation corpus collected by deri2016grapheme.", "answers": ["the Carnegie Mellon Pronouncing Dictionary BIBREF12, the multilingual pronunciation corpus collected by deri2016grapheme , ranscriptions extracted from Wiktionary", "multilingual pronunciation corpus collected by deri2016grapheme"], "length": 6428}
{"pred": " Two-step relation detection.", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "length": 6735}
{"pred": " Bowman, K. and Sarkar, R. and Raut, S. and Leong, K. W., Gene transfer to hemophilia A mice via oral delivery of FVIII-chitosan nanoparticles, Journal of Controlled Release, vol. 132 no. 3 (2008), pp. 252-259.", "answers": ["Sustained viral gene delivery through core-shell fibers and Gene transfer to hemophilia A mice via oral delivery of FVIII-chitosan nanoparticles."], "length": 6709}
{"pred": " December 11, 1928.", "answers": ["Goodwin became a Naval aviator in January 1929."], "length": 7114}
{"pred": " Permanent yellow spot damage on the screen.", "answers": ["Exposure to sunlight or strong light may cause permanent yellow spot damage on the screen."], "length": 5324}
{"pred": " MEDDOCAN and NUBes-PHI.", "answers": ["MEDDOCAN, NUBes-PHI", "MEDDOCAN, NUBes "], "length": 6104}
{"pred": " 1.7K bilingual ancient-modern Chinese articles from the internet.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "length": 6843}
{"pred": " Nuclear liquid-gas transition.", "answers": ["Nuclear liquid-gas transition in lattice QCD."], "length": 7196}
{"pred": " \n\\begin{eqnarray}\nO (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).\\quad\n\\label{eq:Oscalingass}\n\\end{eqnarray}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7774}
{"pred": " No.", "answers": ["No"], "length": 7027}
{"pred": " No.", "answers": ["No"], "length": 6856}
{"pred": " $m \\sim t^{1/2}$ and the Binder cumulant $g$ of the lowest transverse mode is zero in this regime.", "answers": ["It is well described by the Gaussian theory."], "length": 6858}
{"pred": " We use those dimensions as high-level categories of a qualitative annotation schema for annotating question, expected answer and the corresponding context. We further enrich the qualitative annotations by a metric based on lexical cues in order to approximate a lower bound for the complexity of the reading comprehension task.", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "length": 6516}
{"pred": " CRF, UWAV.", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "length": 7426}
{"pred": " A group of 50 native people who were well-versed in both English and Tamil languages acted as annotators for the evaluation.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "length": 6890}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 7166}
{"pred": " English, Spanish, Finnish.", "answers": ["English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish", "English, Spanish, Finnish"], "length": 6791}
{"pred": " 30.", "answers": "48,705", "length": 6931}
{"pred": " The combination of the two best performing similarity-based approaches INLINEFORM2 and INLINEFORM3 does not yield better accuracy. The negative impact of using a lower-performing approach such as INLINEFORM4 within a hybrid combination can also be observed in INLINEFORM5 for lower values of INLINEFORM6. Overall, this confirms our initial intuition that combining the best performing popularity-based approach with the best similarity-based approach should result in the highest accuracy.", "answers": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "length": 6930}
{"pred": " average dissimilarity of all pairs of tags in the list of recommended tags.", "answers": " the average dissimilarity of all pairs of tags in the list of recommended tags", "length": 6928}
{"pred": " 30% of the Amazon search terms contain parts of the e-book titles. \n\nQuestion: what is the goal of the authors?\nAnswer: to support editors in the e-book annotation process with tag recommendations.\n\nQuestion: what is the main task of the authors?\nAnswer: to improve the performance of tag recommender systems for e-books.\n\nQuestion: what is the approach of the authors?\nAnswer: hybrid tag recommendation approach.\n\nQuestion: what is the evaluation metric used by the authors?\nAnswer: Normalized Discounted Cumulative Gain (nDCG) and semantic similarity.\n\nQuestion: what is the dataset used by the authors?\nAnswer:", "answers": "33,663", "length": 6929}
{"pred": " NCHLT text corpora, DSL 2015, DSL 2017, Amazon search terms, editor tags, Amazon review keywords.", "answers": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "length": 6928}
{"pred": " 19 different algorithms, including popularity-based, similarity-based, and hybrid approaches.", "answers": "popularity-based, similarity-based, hybrid", "length": 6929}
{"pred": " Find out what happens after you request a decision review You don t need to do anything while you wait unless VA sends you a letter asking for more information. If VA schedules exams for you, be sure not to miss them. Track the status of your appeal.", "answers": "We can help you find out what happens after you request a decision review Did the VA schedule an exam for you?", "length": 6787}
{"pred": " You can view the details of your claim, including where your claim is in the review process, and when we think we will complete our review, as well as any evidence to support your initial claim, any additional evidence, your claim type, what you have claimed, and your representative for VA claims.", "answers": "You can view the details that you filed online, including any evidence that supports your initial claim.", "length": 6789}
{"pred": " https://www.va.gov/decisions/decisions-review-appeal-process.asp", "answers": "We have a page for frequently asked questions about decision reviews. I can give you the link", "length": 6803}
{"pred": " Yes, your representative, if you have one, may help you at the hearing.", "answers": "Your representative ,  if you have one ,  may help you at the hearing .", "length": 6781}
{"pred": " No.", "answers": "A Veterans Service Organization, or VA-accredited attorney or agent can help you request a decision review. I can send you to the page where you can get more information on this", "length": 6801}
{"pred": " You can download VA Form 10182 PDF or fill out the Decision Review Request: Board Appeal VA Form 10182. By mail Send the completed form and any supporting documents to this address : Board of Veterans AppealsPO Box 27063Washington, D.C. 20038 In person Bring your completed form to a regional benefit office. Find a regional benefit office near you By fax Fax your completed form to 844 - 678 - 8979. You can also ask a regional benefit office for a copy of this form to fill out. Or you can call the VA toll-free hotline at 800 - 827 - 100", "answers": "You can ask a regional office for a copy of this form or you can call the VA toll-free hotline at 800-827-1000, Monday through Friday, 8:00 a.m. - 9:00 p.m. ET, to request a form. ", "length": 6791}
{"pred": " Direct Review.", "answers": "If you want a Veterans Law Judge to review your case as quickly as possible, choose a Direct Review.", "length": 6797}
{"pred": " The US Department of Veterans Affairs (VA) provides free, confidential private counseling and treatment to male and female Veterans for both mental and physical health problems linked to military sexual trauma (MST).", "answers": "Are you a veteran?", "length": 6978}
{"pred": " Yes. You can download our military sexual trauma brochure for Veterans, access more fact sheets, articles, and resources, and learn more about our programs and services. You can also visit the Department of Defense DoD Military OneSource website, our mental health site for transitioning service members, or the Make the Connection website to hear stories from Veterans about their own experiences with the effects of MST, and find more resources and support.", "answers": "You can download our military sexual trauma brochure for Veterans : In English PDF ,or En espanol PDF", "length": 6983}
{"pred": " Visit Make the Connection website.", "answers": "You can download our military sexual trauma brochure for Veterans : In English PDF ,or En espanol PDF", "length": 6979}
{"pred": " No. If you don't qualify for VA health care, you may still be able to get certain health care services, like care for needs linked to military sexual trauma. Call our general VA hotline at 800 - 827 - 1000 to find out what your care options may be.", "answers": "you can remain anonymous. You can get 1-on-1 advice , support , and information 24/7 by phone , text , or online chat .You can also connect with a sexual assault response coordinator near your base or installation .", "length": 6990}
{"pred": " Call 1800 - 662-HELP (800 - 662 - 4357) or text 43578.", "answers": "Yes, simply call 1800-662-HELP 800-662-4357.", "length": 6994}
{"pred": " Yes.", "answers": "you may be able to get MST - related care even if you don't qualify for other VA services . You also don't need to have reported the MST or have other proof that it happened .", "length": 6984}
{"pred": " No.", "answers": "Not the traumatic event itself, but you may be able to get disability compensation for conditions resulting from MST like PTSD the most common mental health condition linked to MST.  We can help you find out if you can get disability benefits for PTSD", "length": 6975}
{"pred": " You can access VA services by calling 800 - 827 - 1000, Monday through Friday, 8:00 a.m. to 9:00 p.m. ET, or by visiting your nearest VA medical center or Vet Center. You can also get free mental health care for a year after separation, regardless of your discharge status, service history, or eligibility for VA health care.", "answers": "If you have a VA primary care provider talk to that professional about what you have been through . Your provider will offer treatment and support as needed .", "length": 6976}
{"pred": " All personalized models outperform baseline in BPE perplexity, with Prior Name performing the best. While our models exhibit comparable performance to baseline in BLEU-1/4 and ROUGE-L, we generate more diverse and acceptable recipes. BLEU and ROUGE are not the most appropriate metrics for generation quality. A `correct' recipe can be written in many ways with the same main entities (ingredients). As BLEU-1/4 capture structural information via n-gram matching, they are not correlated with subjective recipe quality. This mirrors observations from BIBREF31, BIBREF8.", "answers": ["average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time"], "length": 6851}
{"pred": " A tweet went viral if it was retweeted more than 1000 times.", "answers": ["Viral tweets are the ones that are retweeted more than 1000 times", "those that contain a high number of retweets"], "length": 7165}
{"pred": " June 1, 1999.", "answers": ["June 1, 1999."], "length": 7128}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6950}
{"pred": " 33.16% of speakers are women, but only 22.57% of the total speech time is attributed to women.", "answers": ["Women represent 33.16% of the speakers"], "length": 6564}
{"pred": " South West Ultras.", "answers": ["South West Ultras fan club."], "length": 6174}
{"pred": " Statistical machine learning models.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "length": 6631}
{"pred": " Romance and women's fiction.", "answers": ["Romance novels and women's fiction."], "length": 6377}
{"pred": " 1964.", "answers": ["Weep Not, Child was first published in 1964."], "length": 7240}
{"pred": " No.", "answers": ["No"], "length": 7124}
{"pred": " S.", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 7242}
{"pred": " 61.4%", "answers": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "length": 7239}
{"pred": " Yes.", "answers": "No", "length": 7237}
{"pred": " No.", "answers": "No", "length": 7239}
{"pred": " Open IE v4.", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 7242}
{"pred": " No.", "answers": "Yes", "length": 7238}
{"pred": " Wikipedia articles.", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 7242}
{"pred": " Open IE v4.", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 7242}
{"pred": " No.", "answers": "Yes", "length": 7239}
{"pred": " NLTK, Stanford CoreNLP, TwitterNLP, spaCy, CogComp-NLP, Stanford NLP, Rosette Text Analytics, Google Cloud, TensiStrength.", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "length": 5889}
{"pred": " $m \\sim t^{1/2}$ and $O \\sim t^{\\alpha} L_\\parallel^{-1/2}$.", "answers": ["It is well described by the Gaussian theory."], "length": 7123}
{"pred": " English.", "answers": ["English", "Simple English"], "length": 6318}
{"pred": " by employing a propagator in the latent space to capture the reduced-order dynamics of the system.", "answers": ["By using a propagator in the latent space."], "length": 6626}
{"pred": " SMT models.", "answers": ["RNN-based NMT model, Transformer-NMT"], "length": 7017}
{"pred": " $m \\sim t^{1/2}$ and the Binder cumulant $g$ of the lowest transverse mode is zero in this regime.", "answers": ["It is well described by the Gaussian theory."], "length": 7123}
{"pred": " DTA corpus BIBREF11.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "length": 6915}
{"pred": " Four years. \n\nQuestion: What is the name of the radio station that KSTP switched to in 2010?\nAnswer: Sports Radio.\n\nQuestion: What is the name of the radio station that KSTP was the flagship for the Minnesota Twins baseball team?\nAnswer: KSTP-AM.\n\nQuestion: What is the name of the radio station that KSTP was the flagship for the Minnesota United FC?\nAnswer: KSTP.\n\nQuestion: What is the name of the radio station that KSTP was the flagship for the University of Minnesota Golden Gophers men's and women's basketball and men's ice hockey", "answers": ["Four years."], "length": 6810}
{"pred": " Sumy algorithms.", "answers": ["LSA, TextRank, LexRank and ILP-based summary.", "LSA, TextRank, LexRank"], "length": 6918}
{"pred": " $O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).$", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7511}
{"pred": " 1964.", "answers": ["Weep Not, Child was first published in 1964."], "length": 7087}
{"pred": " No.", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 6600}
{"pred": " No.", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 6591}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing.", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 6617}
{"pred": " After your VA claim exam, we'll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating.", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 6614}
{"pred": " No.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 6611}
{"pred": " Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 6613}
{"pred": " Information about VA claim exam, VA disability compensation, VA claim process, VA benefits and services, and more.", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 6591}
{"pred": " The staff at your local VA medical center or a local doctor's office that we partner with will contact you. They will either send you a letter by mail with the date and time of your exam, or call you to find a time that works for you.", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 6595}
{"pred": " 1964.", "answers": ["Weep Not, Child was first published in 1964."], "length": 7320}
{"pred": " Yes.", "answers": "You might be able to repayment it under an income-driven repayment plan but it depends on what type of loan you have. Do you have a FFEL Program Loan or a Federal Perkins Loan?", "length": 6743}
{"pred": " No.", "answers": "You might be able to get a Direct Consolidation Loan and then you could repay under the REPAYE plan.", "length": 6728}
{"pred": " Yes.", "answers": "You may be eligible for the Public Service Loan Forgiveness Program. Read on to see if you can qualify.", "length": 6747}
{"pred": " You must submit an application called the Income-Driven Repayment Plan Request. You can submit the application online or on a paper form, which you can get from your loan servicer.", "answers": "To apply for an Income-Driven Repayment Plan you will have to complete the paper application and provide a paper copy of your most recently filed federal income tax return or IRS tax return transcript.", "length": 6742}
{"pred": " Borrowers currently on an IDR Plan who need to re-certify or make changes to their repayment plan.", "answers": "Borrowers currently on an IDR Plan who need to recertify or make changes to their repayment plan.", "length": 6747}
{"pred": " Generally, your payment amount under an income-driven repayment plan is a percentage of your discretionary income. The percentage is different depending on the plan. The chart below shows how payment amounts are determined under each income-driven plan. Depending on your income and family size, you may have no monthly payment at all.", "answers": "Your payment is always based on your income and family size, regardless of any changes in your income.", "length": 6757}
{"pred": " Yes.", "answers": "You can browse our Income-Driven Plans question and answers page for more information.", "length": 6735}
{"pred": " Browse our Income - Driven Plans Questions and Answers page.", "answers": "On our website.", "length": 6731}
{"pred": " Environmental fluctuation and uncertainty, and the details of the task the artificial organisms are aiming to solve.", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " Kannada, Hindi, Telugu, Malayalam, Bengali, and English.", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "length": 6714}
{"pred": " extended middle context.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "length": 7121}
{"pred": " 2013–2014.", "answers": ["In the 2013-2014 season."], "length": 7011}
{"pred": " Romance novels and women's fiction.", "answers": ["Romance novels and women's fiction."], "length": 5603}
{"pred": " No.", "answers": ["Yes", "No"], "length": 7133}
{"pred": " FC Banants.", "answers": ["FC Banants."], "length": 6520}
{"pred": " $m \\sim t^{1/2}$ and the Binder cumulant $g$ of the lowest transverse mode is zero in this regime.", "answers": ["It is well described by the Gaussian theory."], "length": 7178}
{"pred": " By conducting a survey among engineers and analyzing the NLP jobs submitted to a commercial centralized GPU cluster.", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 7109}
{"pred": " 2-5 times smaller.", "answers": ["Infall rate is 2-5 times smaller and gas density is 2-5 times smaller."], "length": 7287}
{"pred": " V +, V 0, V −.", "answers": ["The three subsets are V+, V0, and V-, determined by the Kullback-Leibler information distance."], "length": 6987}
{"pred": " Fuller's Ranch.", "answers": ["The first white settlement in McPherson County was Fuller's Ranch, established by Charles O. Fuller."], "length": 6552}
{"pred": " The belief entropy over the goal distribution decreases more steadily, allowing for it to leverage the human's latest observations and reach the goal successfully.", "answers": ["The belief entropy decreases more steadily."], "length": 7007}
{"pred": " 1964.", "answers": ["Weep Not, Child was first published in 1964."], "length": 7124}
{"pred": " previous work. \n\nQuestion: What is the main difference between traditional and neural network models?\nAnswer: the way to represent input sentences. \n\nQuestion: What is the purpose of the Gaussian-masked directional multi-head attention?\nAnswer: to capture the representation of different directions to improve the ability of capturing the localness information and position information for the importance of adjacent characters. \n\nQuestion: What is the purpose of the bi-affinal attention scorer?\nAnswer: to label the gap. \n\nQuestion: What is the purpose of the encoder in the proposed model?\nAnswer: to generate the representation of input which makes the model encode sentences at once without feeding", "answers": ["Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019"], "length": 7141}
{"pred": " word2vec. \n\nQuestion: What is the main contribution of the paper?\nAnswer: creating original and effective word vectors that capture syntactic, semantic, and sentimental characteristics of words.\n\nQuestion: What is the name of the Turkish Language Institution used in the dictionary-based approach?\nAnswer: TDK.\n\nQuestion: What is the name of the library used in the English corpora evaluation?\nAnswer: SentiWordNet.\n\nQuestion: What is the name of the tool used for normalizing Turkish characters?\nAnswer: Zemberek.\n\nQuestion: What is the name of the tool used for morphological parsing and disambiguation?\nAnswer:", "answers": "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach", "length": 6920}
{"pred": " The Twitter corpus is formed of tweets about Turkish mobile network operators, with 1,716 tweets, 973 of them are negative and 743 of them are positive, and the Cohen's Kappa inter-annotator agreement score is 0.82. Disagreements on the polarity of a tweet are removed.", "answers": "one of the Twitter datasets is about Turkish mobile network operators, there are positive, neutral and negative labels and provide the total amount plus the distribution of labels", "length": 6923}
{"pred": " The dataset consists of 20,244 movie reviews, with an average of 39 words per review, and star-rating scores between 0.5 and 5, with a threshold of 2.5 for negative reviews and 4 for positive reviews. The dataset is used to evaluate the proposed approaches for sentiment analysis in Turkish.", "answers": "there are 20,244 reviews divided into positive and negative with an average 39 words per review, each one having a star-rating score", "length": 6924}
{"pred": " minimum, mean, and maximum polarity scores.", "answers": "polarity scores, which are minimum, mean, and maximum polarity scores, from each review", "length": 6926}
{"pred": " word vectors, dictionary-based approach, word2vec embeddings, hand-crafted features, supervised scores, unsupervised dictionary algorithm, SVD method, cosine similarity metric, fuzzy c-means clustering algorithm, principal component analysis (PCA) method, singular value decomposition (SVD) method, fuzzy c-means clustering algorithm, cosine similarity metric, fuzzy c-means clustering algorithm, principal component analysis (PCA) method, singular value decomposition (SVD) method, fuzzy c-means clustering algorithm, cosine similarity metric, fuzzy c-means clustering algorithm, principal component analysis (PCA) method, singular value decomposition (SVD) method,", "answers": "generate word embeddings specific to a domain, TDK (Türk Dil Kurumu - “Turkish Language Institution”) dictionary to obtain word polarities", "length": 6924}
{"pred": " The supervised polarity score per word is calculated as in (DISPLAY_FORM4), where $ w_{t}$ denotes the sentiment score of word $t$, $N_{t}$ is the number of documents (reviews or tweets) in which $t$ occurs in the dataset of positive polarity, $N$ is the number of all the words in the corpus of positive polarity. $N^{\\prime }$ denotes the corpus of negative polarity. $N^{\\prime }_{t}$ and $N^{\\prime }$ denote similar values for the negative polarity corpus. Normalisation is performed to prevent the imbalance problem and a small number", "answers": "(+1 or -1), words of opposite polarities (e.g. “happy\" and “unhappy\") get far away from each other", "length": 6924}
{"pred": " 85.61%", "answers": ["85.61%."], "length": 7048}
{"pred": " small.", "answers": ["small BERT", "small BERT"], "length": 6169}
{"pred": " personal attack, racism, and sexism.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "length": 6460}
{"pred": " No.", "answers": ["Yes"], "length": 6631}
{"pred": " Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6872}
{"pred": " No.", "answers": "Unanswerable", "length": 6872}
{"pred": " $150,000$ tweets.", "answers": " $150,000$ tweets", "length": 6872}
{"pred": " The proposed multimodal models do not outperform the textual models.", "answers": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "length": 6880}
{"pred": " Noisy data, complexity and diversity of multimodal relations, and small set of multimodal examples.", "answers": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "length": 6885}
{"pred": " F-score, Area Under the ROC Curve (AUC), and mean accuracy (ACC).", "answers": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "length": 6875}
{"pred": " Twitter API.", "answers": "Twitter API", "length": 6877}
{"pred": " 150000", "answers": "$150,000$ tweets", "length": 6881}
{"pred": " LSTM, CNN.", "answers": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "length": 6875}
{"pred": " Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6876}
{"pred": " 6 categories: No attacks to any community, racist, sexist, homophobic, religion based attacks or attacks to other communities.", "answers": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "length": 6883}
{"pred": " Helps you pay for school or job training.", "answers": "The GI Bill Post-9/11 helps you pay for school or job training. have you served the active army after September 10, 2001?", "length": 6132}
{"pred": " You served at least 90 days on active duty either all at once or with breaks in service on or after September 11, 2001, or Received a Purple Heart on or after September 11, 2001, and were honorably discharged after any amount of service.", "answers": "one of the primary requirements is to have served at least 90 days on active duty, all at once or with interruptions in service as of September 11, 2001,", "length": 6151}
{"pred": " Yes\n\nQuestion: What is the maximum benefit amount for Post-9/11 GI Bill (Chapter 33) benefits?\nAnswer: $22,000\n\nQuestion: What is the purpose of the GI Bill Comparison Tool?\nAnswer: To find out if the VA has approved your program for VA educational benefits.\n\nQuestion: What is the purpose of the GI Bill Statement of Benefits?\nAnswer: To show you how much of your benefits you have used and how much you have left to use.\n\nQuestion: What is the purpose of the Yellow Ribbon Program?\nAnswer: To help pay for higher private-school or out-of-state tuition.\n\nQuestion: What", "answers": "Did you receive a Purple Heart on or after September 11, 2001?", "length": 6140}
{"pred": " No.", "answers": "have you served for at least 30 continuous days at a time, without a break in service as of September 11, 2001?", "length": 6131}
{"pred": " Yes, you qualify for Post-9/11 GI Bill (Chapter 33) benefits.", "answers": "Are you a dependent child using the benefits transferred by a veteran or qualified service member?", "length": 6137}
{"pred": " Yes, you are eligible for Post-9/11 GI Bill (Chapter 33) benefits if you are a dependent child using benefits transferred by a qualifying Veteran or service member.", "answers": "Based on the information provided by you, I inform you that you are not eligible for benefits.", "length": 6142}
{"pred": " You can verify your enrollment online through our Web Automated Verification system called \" WAVE \" or by phone by calling 877 - 823 - 2378.", "answers": "Before you enroll you need to contact the school or use the GI Bill Comparison Tool to find out if we have approved your program for VA educational benefits ", "length": 6143}
{"pred": " Tuition and fees. Housing. Books and supplies. \n\nQuestion: What is the maximum benefit amount for Post-9/11 GI Bill (Chapter 33) benefits?\nAnswer: Up to 36 months of benefits. \n\nQuestion: What is the benefit amount for Post-9/11 GI Bill (Chapter 33) benefits for a student who had 90 days of active service since September 10, 2001?\nAnswer: 40% of the maximum amount. \n\nQuestion: What is the benefit amount for Post-9/11 GI Bill (Chapter 33) benefits for a student who had 3 years of", "answers": "I can help you learn that too. You may be able to get financial help.", "length": 6139}
{"pred": " Second, second, fourth and fifth.", "answers": ["column Ens Test in Table TABREF19"], "length": 7051}
{"pred": " 2013–2014.", "answers": ["In the 2013-2014 season."], "length": 6990}
{"pred": " Baseline assigns a semantic role to a constituent based on its syntactic function, i.e. the dependency relation to its head.", "answers": "same baseline as used by lang2011unsupervised", "length": 7260}
{"pred": " Crosslingual latent variables.", "answers": "CLV as a parent of the two corresponding role variables", "length": 7264}
{"pred": " Crosslingual latent variables.", "answers": "crosslingual latent variables", "length": 7264}
{"pred": " Europarl corpus.", "answers": "English (EN) and German (DE) sections of the CoNLL 2009 corpus BIBREF13, EN-DE section of the Europarl corpus BIBREF14", "length": 7261}
{"pred": " No.", "answers": "No", "length": 7268}
{"pred": " No.", "answers": "Yes", "length": 7269}
{"pred": " A monolingual model consists of individual Bayesian models for each language and crosslingual latent variables to incorporate soft role agreement between aligned constituents.", "answers": "Bayesian model of garg2012unsupervised as our base monolingual model", "length": 7262}
{"pred": " No.", "answers": "Yes", "length": 7266}
{"pred": " sensitivity to the prior knowledge.", "answers": ["ability to accurately classify texts even when the amount of prior knowledge for different classes is unbalanced, and when the class distribution of the dataset is unbalanced", "Low sensitivity to bias in prior knowledge"], "length": 7087}
{"pred": " 15–3.", "answers": ["They won their first game with a score of 15-3."], "length": 6588}
{"pred": " The time required to update the robot's belief does not increase with the complexity of the environment.", "answers": ["The time required to update the belief does not increase with the complexity of the environment."], "length": 7006}
{"pred": " NLTK, Stanford CoreNLP, TwitterNLP, SentiStrength, TensiStrength, BIBREF17, BIBREF18, CogComp-NLP, Stanford NLP, spaCy.", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "length": 6906}
{"pred": " Four.", "answers": ["Four."], "length": 6361}
{"pred": " Nonlinear system vibration problems.", "answers": ["The paper aims to solve nonlinear system vibration problems efficiently."], "length": 7036}
{"pred": " Unif and Stopword.", "answers": ["varied from Maximum Entropy Classifiers (BIBREF4) to Support Vector Machines (BIBREF5,BIBREF6,BIBREF7,BIBREF8), Recursive Neural Networks (BIBREF9,BIBREF10), Convolutional Neural Networks (BIBREF11) and most recently transfer learning-based architectures like Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12)"], "length": 7111}
{"pred": " DTA18 and DTA19. \n\nQuestion: What is the gold standard data set used for evaluation?\nAnswer: Diachronic Usage Relatedness (DURel) data set. \n\nQuestion: What is the metric used to assess the performance of the models?\nAnswer: Spearman's $\\rho $. \n\nQuestion: What are the two baselines used for comparison?\nAnswer: log-transformed normalized frequency difference (FD) and count vectors with column intersection and cosine distance (CNT + CI + CD). \n\nQuestion: What is the distance measure used by most teams?\nAnswer: Cosine distance (CD). \n\nQuestion: What is", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "length": 7069}
{"pred": " Robert Paun, Director of Investor Relations, conducted the call and its purpose was to introduce the call and provide information about the conference call.", "answers": "The conference call was conducted by Robert Paun, Director of Investor Relations at FS KKR Capital Corp., and it was aimed at discussing the company's fourth quarter and full year 2018 earnings.", "length": 6839}
{"pred": " First, we received shareholder approval for the partnership between FS Investments and KKR. Second, we advanced our plan to optimize the company's capital structure closing a $2.1 billion revolver as part of a 3.4 billion five year omnibus credit facility that is also used by FSIC II and III. Third, we completed the merger between CCT and FSIC, which is an important milestone for the franchise as we seek to run our business more efficiently, reduce risk through greater portfolio diversification and drive sustained value for our shareholders. Finally, we began capitalizing on the full benefits of the combined FS Investments and KKR platforms,", "answers": "Key accomplishments included receiving shareholder approval for the partnership between FS Investments and KKR, optimizing the company's capital structure by closing a $2.1 billion revolver, completing a merger between CCT and FSIC, and starting to capitalize on the benefits of the combined FS Investments and KKR platforms.", "length": 6833}
{"pred": " The company believes that market volatility creates opportunities for them to be selective in their credit selection and to capture a projected annual interest expense savings of approximately $10 million by lowering their cost of financing. They are focused on being disciplined in their credit selection and are executing transactions where they believe there is an appropriate risk-reward. They are also taking steps to reduce their equity exposure and rotate out of non-income producing investments.", "answers": "The company acknowledged it is not immune to market volatility experienced at the end of the fourth quarter of 2018. To demonstrate conviction and alignment with shareholders, the Board authorized a $200 million share repurchase program, considering FSK's recent share price as a strong buying opportunity. We purchased about $40 million shares from this authorization so far.", "length": 6834}
{"pred": " The market volatility negatively impacted the leverage credit markets and investors sentiment deteriorated throughout the quarter. The sell-off occurred despite relatively stable corporate fundamentals and near historic low corporate default rates, and we believe it was mainly technical in nature. The pullback in January was quicker than we expected and hoped, and the overall market remains competitive.", "answers": "The global equity and fixed income markets experienced significant volatility in Q4 2018, which negatively impacted the leverage credit markets and investor sentiment. This shift in sentiment was reflected in bond and loan prices, which declined to a 2.5 year low. However, this also created some opportunities for the company to capitalize on market volatility.", "length": 6836}
{"pred": " The merger with CCT has increased portfolio diversification, which is a key risk mitigation tool, as the top 10 largest portfolio companies by fair value decreased to 19% of the portfolio from 36% of the portfolio at the end of Q3.", "answers": "The merger with CCT increased portfolio diversification, a key risk mitigation tool. At the end of the year, the top 10 largest portfolio companies by fair value decreased to 19% of the portfolio from 36% of the portfolio at the end of Q3. Furthermore, the portfolio is now comprised of 74% senior secured investments.", "length": 6829}
{"pred": " Net investment income was $0.19 per share, which was in line with our mid-January preliminary guidance and compares to $0.23 per share for the third quarter of 2018 and $0.22 per share in the fourth quarter of 2017. Net realized and unrealized losses on investments were $172 million in the fourth quarter or $0.62 per share. Approximately $68 million of the net realized and unrealized loss was attributable to the previously discussed restructuring of ThermaSys.", "answers": "For Q4 2018, net investment income was $0.19 per share, which compares to $0.23 per share for Q3 2018 and $0.22 per share in Q4 2017. The decline in net investment income is primarily attributed to certain assets being placed on nonaccrual and net sales and repayment activity during the year.", "length": 6839}
{"pred": " The merger between CCT and FSIC was an important milestone for the franchise, which allowed the company to run its business more efficiently, reduce risk through greater portfolio diversification, and drive sustained value for shareholders. The merger has increased portfolio diversification, with the top 10 largest portfolio companies by fair value decreasing to 19% of the portfolio from 36% of the portfolio at the end of Q3. The average hold position at fair value decreased from 1% of the portfolio at the end of Q3 to 0.5% at the end of Q4. The portfolio is now comprised of 74% senior secured investments", "answers": "The merger between CCT and FSIC, which closed on December 19, 2018, has increased portfolio diversification which serves as a key risk mitigation tool. By the end of 2018, the top 10 largest portfolio companies by fair value decreased to 19% of the portfolio from 36% at the end of Q3 2018. The merger also led to equity investments comprising 7% of the portfolio on a fair value basis, down from 13% at the beginning of the year.", "length": 6832}
{"pred": " We have a joint venture with KKR Credit, which is focused on investing in high-quality, senior-secured loans to middle-market companies. The JV's investment strategy is to invest in a diversified portfolio of loans, with a focus on origination activity and selectivity. In comparison, FSK's investment strategy is focused on a broader range of investments, including senior-secured loans, mezzanine loans, and equity investments, with a focus on generating consistent deal flow and driving near- and long-term value for shareholders.", "answers": "FSK had set up the JV probably at a bit of a different manner than others that have been in the market. FSK had set it up with a real strategic objective to allow them to use it opportunistically but also use it to expand that nonEPC bucket. In terms of marrying the 2 together now inside of FSK, the foundations of what FSIC and CCT did were fairly similar. FSK was evolving FSIC for the last 3 quarters of last year to more align with the KKR sort of credit platform, mainly from an origination perspective. So the goals of the JV remain the same.", "length": 6846}
{"pred": " Multiple papers have proposed hierarchical stacked classifiers that would for example first classify a piece of text by language group and then by exact language.", "answers": "'shallow' naive Bayes, SVM, hierarchical stacked classifiers, bidirectional recurrent neural networks", "length": 6407}
{"pred": " No.", "answers": "Yes", "length": 6409}
{"pred": " They build a lexicon over all the data and therefore includes the vocabulary from both the training and testing sets.", "answers": "built over all the data and therefore includes the vocabulary from both the training and testing sets", "length": 6407}
{"pred": " BLEU-1/4 and ROUGE-L. \n\nQuestion: What is the main task of the model?\nAnswer: Language Identification (LID). \n\nQuestion: What is the main contribution of the model?\nAnswer: The model proposes a hierarchical naive Bayesian and lexicon based classifier for LID of short pieces of text. \n\nQuestion: What is the main problem that the model is trying to solve?\nAnswer: LID of short texts, informal styles and similar languages. \n\nQuestion: What is the main evaluation metric used to measure the performance of the model?\nAnswer: Classification accuracy. \n\nQuestion: What is the main goal of", "answers": "average classification accuracy, execution performance", "length": 6405}
{"pred": " The Nguni languages. \n\nQuestion: What is the main task of the proposed algorithm in Passage 2?\nAnswer: Language identification (LID) of short texts.\n\nQuestion: What is the main task of the proposed algorithm in Passage 2?\nAnswer: Language identification (LID) of short texts.\n\nQuestion: What is the main task of the proposed algorithm in Passage 2?\nAnswer: Language identification (LID) of short texts.\n\nQuestion: What is the main task of the proposed algorithm in Passage 2?\nAnswer: Language identification (LID) of short texts.\n\nQuestion: What is the main task of the", "answers": "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "length": 6407}
{"pred": " DSL 2015 & DSL 2017 shared tasks, JW300 parallel corpus, WiLI-2018 benchmark dataset, NCHLT text corpora, Leipzig Corpora Collection, Universal Declaration of Human Rights, Tatoeba.", "answers": "DSL 2015, DSL 2017, JW300 parallel corpus , NCHLT text corpora", "length": 6410}
{"pred": " Yes.", "answers": "Yes", "length": 6416}
{"pred": " No.", "answers": "Yes", "length": 6411}
{"pred": " BIBREF0, BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6, BIBREF7, BIBREF8, BIBREF9.", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "length": 6805}
{"pred": " 85.61%", "answers": ["85.61%."], "length": 7289}
{"pred": " The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7131}
