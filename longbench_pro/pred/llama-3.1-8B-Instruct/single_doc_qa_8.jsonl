{"pred": " Multi30K dataset.  English-German dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30", "answers": ["the English-German dataset"], "length": 6772}
{"pred": " The bigger the receptive field size, the more successful the algorithm is in filling in the gaps. Models with bigger receptive field size can complete shapes with bigger gaps.  The bigger the filter size, the more successful the algorithm is in filling in the gaps.  The bigger the receptive field size, the more complete shapes we can reconstruct using DSP.  The bigger the receptive field size, the more successful the algorithm is in filling in the gaps.  The bigger the receptive field size, the more complete shapes we can reconstruct using DSP.  The bigger the receptive field size, the more successful the algorithm is in filling in the gaps. ", "answers": ["Bigger receptive field size leads to more successful shape completion."], "length": 6247}
{"pred": " Doc Brown.  Emmett `` Doc '' Brown ( portrayed by Christopher Lloyd in the films and Back to the Future : The Game, and voiced by Dan Castellaneta in the animated series ) is the inventor of the DeLorean time machine. At various points in time, Doc helps Marty restore the space - time continuum and reverse the changes that were caused by time travel. </P> <P> In 2008, the character was selected by film magazine Empire as one of The 100 Greatest Movie Characters of All Time, ranking at # 20. </P> <H3> Biff Tannen ( edit", "answers": "Doctor Emmett Lathrop `` Doc '' Brown", "length": 6477}
{"pred": " Claudia Wells.  She was not available to film the sequels for personal reasons, and the role was recast to Elisabeth Shue.  Wells reprised her role as Jennifer in Back to the Future: The Game as a punk rock version of her character.  Consequently, the opening scene of Back to the Future Part II was re-shot with Shue taking Wells' place, rather than using the ending of Back to the Future.  In the spin-off Back to the Future: the Animated Series, Jennifer was voiced by Cathy Cavadini.  In 1985, Jennifer attends Hill Valley High School, along with her", "answers": "Claudia Wells", "length": 6479}
{"pred": " Lea Thompson.  She also plays Maggie McFly.  In a DVD commentary track for Part III, Bob Gale states that the creative team considered it important to include Thompson in the film, and he imagines that McFly men are simply \"genetically predisposed\" to be attracted to women who look like her.  Lorraine is the eldest daughter of Sam (George DiCenzo) and Stella (Frances Lee McCain) Baines, and sister of Milton (Jason Hervey), Sally (Maia Brewton), Toby, and Joey.  In Back to the Future, Lorraine is initially portrayed in 198", "answers": "Lea Thompson", "length": 6477}
{"pred": " Linda McFly.  She was portrayed by Wendie Jo Sperber.  In 1985 before Marty went to 1955, Linda is having boy trouble and it is unknown if she is in college or has a job.  In 1985 after Marty went to 1955, Linda works in a boutique and has gained the attention of many boys.  She is the middle child and only daughter of George and Lorraine McFly.  She has a brother named Dave McFly.  She also has a brother named Marty (Jr.) and a sister named Marlene McFly.  Marty (Jr", "answers": "Wendie Jo Sperber", "length": 6478}
{"pred": " The dynamical behavior of the anisotropic order parameter m following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2). The alternative order parameter O, however, distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases. In the LG, the scaling form for O is not compatible with the prediction O ∼ t^(1/8) L_∥^(-1/2) of the Gaussian theory. However, following Ref. [AS200", "answers": ["It is well described by the Gaussian theory."], "length": 6401}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{equation}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document} ", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7619}
{"pred": " 22,880.  20,000.  40,000.  560,000.  20,000.  22,880.  20,000.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22,880.  22", "answers": ["22,880 users", "20,000"], "length": 7034}
{"pred": " 2013–2014.", "answers": ["In the 2013-2014 season."], "length": 6983}
{"pred": " FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney. Note that thankful was only available during specific time spans related to certain events, as Mother's Day in May 2016.  They also looked at the pages of the following individuals: Justin Bieber, and the following children's television shows: Cartoon Network, Nickelodeon, Spongebob, Disney.  They also looked at the pages of the following news organizations: FoxNews, CNN, ESPN, New York Times,", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "length": 7140}
{"pred": " Yes. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF3. BIBREF1, BIBREF2, and BIBREF", "answers": ["Yes", "Yes"], "length": 7156}
{"pred": " No.  They report results on both English and low-resource hate speech languages.  They also report results on datasets that are annotated for racism, sexism, or neither, and datasets that are annotated for hate, offensive, or neither.  They also report results on datasets that are annotated for different types of abusive language such as cyberbullying, hate, sarcasm, etc.  They also report results on datasets that are annotated for different types of biases in hate speech training datasets.  They also report results on datasets that are annotated for different types of hate speech and offensive language.  They also report results on datasets that are annotated for", "answers": "Yes", "length": 6949}
{"pred": " No.  They report results on both English and low-resource hate speech languages.  They also report results on datasets that are annotated for racism, sexism, or neither, and datasets that are annotated for hate, offensive, or neither.  They also report results on datasets that are annotated for different types of abusive language such as cyberbullying, hate, sarcasm, etc.  They also report results on datasets that are annotated for different types of biases in hate speech training datasets.  They also report results on datasets that are annotated for different types of hate speech and offensive language.  They also report results on datasets that are annotated for", "answers": "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate", "length": 6949}
{"pred": " The authors present the results of manual inspection on a subset of the data and record some of the mislabeled items by their model in Tables TABREF20 and TABREF21. They also mention that many errors are due to biases from data collection and rules of annotation, as recently studied in BIBREF2, BIBREF24, BIBREF19. They argue that the model can differentiate hate and offensive samples accurately by leveraging knowledge-aware language understanding that it has, despite the bias in the data. They also mention that the pre-trained BERT model is trained on general corpora, it has learned general knowledge from normal textual data", "answers": "Waseem-dataset, Davidson-dataset,", "length": 6959}
{"pred": " Waseem and Hovy, Davidson et al., Waseem et al.  and Waseem.  Waseem and Hovy dataset contains 16k of tweets, Waseem dataset contains 6.9k of tweets, Davidson et al. dataset contains 84.4 million tweets.  Waseem and Hovy dataset is merged with Waseem dataset.  The distribution of different classes in both datasets will be provided in Subsection SECREF15.  The distribution of different classes in both datasets are shown in Table TABREF16.  The distribution of different classes in both datasets are shown in", "answers": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "length": 6947}
{"pred": " Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10.  Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10.  Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10.  Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIB", "answers": "BERT based fine-tuning, Insert nonlinear layers, Insert Bi-LSTM layer, Insert CNN layer", "length": 6945}
{"pred": " 1. BERT based fine-tuning, 2. Insert nonlinear layers, 3. Insert Bi-LSTM layer, 4. Insert CNN layer. 5. BERT + nonlinear classifier on top of BERT. 6. BERT + CNN on top of BERT. 7. BERT + Bi-LSTM on top of BERT. 8. BERT + CNN on top of BERT + Bi-LSTM. 9. BERT + CNN on top of BERT + nonlinear classifier. 10. BERT + CNN on top of BERT + Bi-LSTM + nonlinear classifier.", "answers": "sampling tweets from specific keywords create systematic and substancial racial biases in datasets", "length": 6949}
{"pred": " The existing biases are from data collection and rules of annotation. The data collection biases include geographic restriction and language, and the annotation biases include annotators tended to annotate many samples containing disrespectful words as hate or offensive without any presumption about the social context of tweeters. The biases in data collection and annotation can lead to misclassifications. The misclassifications do not confirm the low performance of the classifier because annotators tended to annotate many samples containing disrespectful words as hate or offensive without any presumption about the social context of tweeters. Tweets IDs 6, 8, and 10 are some samples containing offensive words and slurs which are not", "answers": "Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters", "length": 6946}
{"pred": " Biases from data collection and rules of annotation.  Especially for Davidson-dataset, some tweets with specific language (written within the African American Vernacular English) and geographic restriction (United States of America) are oversampled such as tweets containing disparage words “nigga\", “faggot\", “coon\", or “queer\", result in high rates of misclassification. However, these misclassifications do not confirm the low performance of their classifier because annotators tended to annotate many samples containing disrespectful words as hate or offensive without any presumption about the social context of tweeters such as the speaker’s identity or dialect, whereas they", "answers": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "length": 6947}
{"pred": " McPherson.  McPherson was regularly organized as a county in the spring of 1870, a mass meeting being held at Sweadal. Sweadal, the county seat thus selected, was located about one mile and a half southwest of the present site of Lindsborg. In September, however, the County Commissioners resolved to meet at the latter place, McPherson which had already been located some two years. In April, 1873, a petition was filed for the county seat re-location. It was signed by 483 voters, and a special election was accordingly ordered for June 10. Upon that day,", "answers": ["McPherson."], "length": 6447}
{"pred": " Yes. Previous work examined the extent to which RNN-based models capture syntax-sensitive phenomena that are traditionally taken as evidence for the existence in hierarchical structure. In particular, in BIBREF1 we assess the ability of LSTMs to learn subject-verb agreement patterns in English, and evaluate on naturally occurring wikipedia sentences. BIBREF2 also consider subject-verb agreement, but in a “colorless green ideas” setting in which content words in naturally occurring sentences are replaced with random words with the same part-of-speech and inflection, thus ensuring a focus on syntax rather than on selectional-preferences based cues. BIBREF", "answers": ["Yes", "Yes"], "length": 7022}
{"pred": " Ternary Trans-CNN model.  Fully Connected dense networks.  Hybrid multi-channel CNN and LSTM model.  Transfer Learning on an architecture learnt on about 14,500 messages.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.  Fully Connected dense networks.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.  Fully Connected dense networks.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.", "answers": "Ternary Trans-CNN", "length": 6072}
{"pred": " HEOT.  The labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small. 3189 rows of text messages of average length of 116 words and with a range of 1, 1295. 14,500 messages with an accuracy of 83.90. 7934 messages. 700 tweets/messages were held out for testing. 2489 messages were sent to an offline pipeline for augmenting the data. 7934 messages. 70 tweets/messages were held out", "answers": "HEOT , A labelled dataset for a corresponding english tweets", "length": 6069}
{"pred": " 3189 rows of text messages. 14,500 messages with an accuracy of 83.90. 7934 messages. 2489 messages. 700 tweets/messages. 99,996 tweet IDs. 70,904 tweets. 100K tweets. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3189", "answers": "3189 rows of text messages", "length": 6070}
{"pred": " 3189 rows of text messages. 14,500 messages with an accuracy of 83.90. 7934 messages. 2489 messages. 700 tweets/messages. 99,996 tweet IDs. 70,904 tweets. 100K tweets. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3189", "answers": "Resulting dataset was 7934 messages for train and 700 messages for test.", "length": 6070}
{"pred": " The dataset is obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from twitter for the conversations happening in Indian subcontinent. A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small.  Basic summary and examples of the data from the dataset are below. The obtained data set had many challenges and thus a data preparation task was employed to clean the data and make it ready for the deep learning pipeline. The challenges and processes that were applied", "answers": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "length": 6070}
{"pred": " No.", "answers": "No", "length": 6072}
{"pred": " Ternary Trans-CNN model, Hybrid multi-channel CNN and LSTM model.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Bidirectional LSTM model architecture.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Conv", "answers": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "length": 6071}
{"pred": " No. The dataset is obtained from Twitter. The tweets are crawled from Twitter. The dataset is called HEOT. HEOT is a dataset of cleaned tweets obtained from Twitter for the conversations happening in Indian subcontinent. A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small. The dataset is used for the task of detecting hate speech in Hinglish. The dataset is used to train and test the model. The dataset is used to evaluate the performance of the model. The dataset is used to", "answers": "No", "length": 6075}
{"pred": " Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN, Pointer-Gen+ARL-SEN.  Test set is the headlines from the test set.  Note that we didn't compare to Pointer-Gen+ARL-ROUGE as it is actually Pointer-GEN.  Recall that $\\alpha _{\\text{sen}}(y^*)$ in Equation DISPLAY_FORM19 measures how good (based on reward function) is $y^*$.  Then the loss", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "length": 6253}
{"pred": " Neighbors-only.  In this experiment, we replaced the GRU combine function (see Eq. DISPLAY_FORM14) with the identity function. That is, we simply have $\\mathbf {H}^{t+1}$=$\\mathbf {M}^{t+1}$. Since $\\mathbf {A}$ has zero diagonal, by doing so, we completely ignore the previous feature of the node itself when updating its representation. That is, the update is based entirely on its neighbors. Except on Reuters (almost no change), performance always suffers, stressing the need to take into account the root node during updates, not only", "answers": ["Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets."], "length": 7506}
{"pred": " They translate each word in the source language into English using a bilingual dictionary. In an end-to-end solution, it would have been ideal to use bilingual embeddings or obtain word-by-word translations via bilingual embeddings. But, the quality of publicly available bilingual embeddings for English-Indian languages is very low for obtaining good-quality, bilingual representations. They also found that these embeddings were not useful for transfer learning. They use the CFILT-preorder system for reordering English sentences to match the Indian language word order. It contains two re-ordering systems: (1) generic rules that apply to all Indian languages and (2) hindi-tuned rules which", "answers": ["Unanswerable", "CFILT-preorder system"], "length": 6817}
{"pred": " We started with the best performing model according to validation performance. Then in each step we tried adding the best performing model that had not been previously tried. We kept it in the ensemble if it improved its validation performance and discarded it otherwise. This way we gradually tried each model once. We call the resulting model a greedy ensemble. We used the BookTest validation dataset for this procedure. The algorithm was offered 10 models and selected 5 of them for the final ensemble.  The single models were selected using the following algorithm. We started with the best performing model according to validation performance. Then in each step we tried adding the best performing model", "answers": ["simply averaging the predictions from the constituent single models"], "length": 6732}
{"pred": " A bi-directional language model to augment the sequence to sequence encoder and a uni-directional model to augment the decoder. Both use self-attention. The bi-directional model solves a cloze-style token prediction task at training time. The model consists of two towers, the forward tower operates left-to-right and the tower operating right-to-left as backward tower; each tower contains transformer blocks. The forward and backward representations are combined via a self-attention module and the output of this module is used to predict the token at position. The model has access to the entire input surrounding the current target token. Models use the standard settings for the Big", "answers": ["uni-directional model to augment the decoder", "bi-directional language model to augment the sequence to sequence encoder ,  uni-directional model to augment the decoder"], "length": 6433}
{"pred": " January 1929.  Upon the completion of the training in January 1929, he was designated Naval aviator.  He was subsequently attached to the Observation Squadron aboard the aircraft carrier  and participated in the Fleet exercises in the Caribbean.  He was transferred to the Bureau of Aeronautics in Washington, D.C. in August 1931 and served consecutively under the architect of naval aviation William A. Moffett and future Chief of Naval Operations Ernest J. King.  In June 1933, Goodwin was ordered to the Naval War College at Newport, Rhode Island, where he completed junior course in May", "answers": ["Goodwin became a Naval aviator in January 1929."], "length": 5893}
{"pred": " Yes.  The attention function is used to compute the similarity score between passages and questions.  A question-aware passage representation is computed as  $\\mathbf{p} = \\sum_{i=1}^{n} \\alpha_i \\mathbf{p}_i$, where $\\alpha_i$ is the attention weight.  After that, we use the method of BIBREF13 to apply self attention to the passage: $\\mathbf{p} = \\sum_{i=1}^{n} \\alpha_i \\mathbf{p}_i$, where $\\alpha_i$ is the attention weight.  At last", "answers": ["Yes", "Yes"], "length": 7335}
{"pred": " The dynamical behavior of the anisotropic order parameter following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2) and the Binder cumulant g of the lowest transverse mode is zero in this regime. The alternative order parameter O, however, distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases. In the LG, this scaling form is not compatible with the prediction O ∼ t^(1/8) L_∥^(-1/", "answers": ["It is well described by the Gaussian theory."], "length": 7200}
{"pred": " Yes. They use 300 dimensional Glove embeddings.  They initialized the embeddings of these words with 300 dimensional Glove embeddings.  They retained only the top 20K words in their vocabulary.  Of these, they initialized the embeddings of these words with 300 dimensional Glove embeddings.  They used Adam with a learning rate of 0.0001, 0.0005 and 0.001.  They trained the model for a maximum of 20 epochs and used early stopping with the patience set to 5 epochs.  They used Adam with a learning rate of INLINEFORM1, INLINEFORM2 and", "answers": ["Yes", "Yes"], "length": 7305}
{"pred": " 120.  (Note: The answer is not explicitly stated in the passage, but it can be inferred from the list of her novels.) 120.  (Note: The answer is not explicitly stated in the passage, but it can be inferred from the list of her novels.) 120.  (Note: The answer is not explicitly stated in the passage, but it can be inferred from the list of her novels.) 120.  (Note: The answer is not explicitly stated in the passage, but it can be inferred from the list of her novels.) 120.  (Note: The answer is not explicitly", "answers": ["Margaret Way wrote more than 120 novels."], "length": 6070}
{"pred": " Kannada, Hindi, Telugu, Malayalam, Bengali, and English.  (They also mention that they collected data for 7 Indian languages, but they only explicitly mention 6 languages. However, the table in the dataset section mentions 7 languages, including \"Others\".)  Kannada, Hindi, Telugu, Malayalam, Bengali, and English.  (They also mention that they collected data for 7 Indian languages, but they only explicitly mention 6 languages. However, the table in the dataset section mentions 7 languages, including \"Others\".)  Kannada, Hindi, Telugu,", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "length": 6247}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 5998}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6691}
{"pred": " Romance novels and women's fiction.  (Note: She also wrote other genres, but the question asks for the genre she wrote in, which is romance novels and women's fiction.)  (Note: She also wrote other genres, but the question asks for the genre she wrote in, which is romance novels and women's fiction.)  (Note: She also wrote other genres, but the question asks for the genre she wrote in, which is romance novels and women's fiction.)  (Note: She also wrote other genres, but the question asks for the genre she wrote in, which is romance novels and women's fiction.) ", "answers": ["Romance novels and women's fiction."], "length": 6393}
{"pred": " Environmental fluctuation and uncertainty.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity. Interestingly, the form of the emerging plasticity rule is additionally determined by the details of the task the artificial organisms are aiming to solve.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM, SCM, TKM.  FCM", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6580}
{"pred": " No.", "answers": "Unanswerable", "length": 6580}
{"pred": " 150,000. 112,845 not hate tweets and 36,978 hate tweets. 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets. 5,000 for validation and 10,000 for test. 112,845 not hate tweets and 36,978 hate tweets. 5,000 for validation and 10,000 for test. 112,845 not hate tweets and 36,978 hate tweets. 5,000 for validation and 10,000 for test. 112,845", "answers": " $150,000$ tweets", "length": 6580}
{"pred": " The proposed multimodal models do not outperform the textual models.  Besides the different architectures, we have tried different training strategies, such as initializing the CNN weights with a model already trained solely with MMHS150K images or using dropout to force the multimodal models to use the visual information. Eventually, though, these models end up using almost only the text input for the prediction and producing very similar results to those of the textual models. The proposed multimodal models, such as TKM, have shown good performance in other tasks, such as VQA. Next, we analyze why they do not perform well in this task and with this", "answers": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "length": 6588}
{"pred": " Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples.  The proposed multimodal models, such as TKM, have shown good performance in other tasks, such as VQA. Next, we analyze why they do not perform well in this task and with this data.  Noisy data. A major challenge of this task is the discrepancy between annotations due to subjective judgement. Although this affects also detection using only text, its repercussion is bigger in more complex tasks, such as detection using images or multimodal detection. Complexity and diversity of multimodal relations. Hate speech multimodal publications employ a lot", "answers": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "length": 6593}
{"pred": " F-score, the Area Under the ROC Curve (AUC) and the mean accuracy (ACC).  The F-score, the Area Under the ROC Curve (AUC) and the mean accuracy (ACC) of the proposed models when different inputs are available.  $TT$ refers to the tweet text, $IT$ to the image text and $I$ to the image. It also shows results for the LSTM, for the Davison method proposed in BIBREF7 trained with MMHS150K, and for random scores. Fig. FIGREF32 shows the Precision vs Recall plot and the ROC curve (which plots the True", "answers": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "length": 6583}
{"pred": " Twitter API.  The MMHS150K dataset ::: Tweets Gathering We used the Twitter API to gather real-time tweets from September 2018 until February 2019, selecting the ones containing any of the 51 Hatebase terms that are more common in hate speech tweets, as studied in BIBREF9.  We filtered out retweets, tweets containing less than three words and tweets containing porn related terms. From that selection, we kept the ones that included images and downloaded them. Twitter applies hate speech filters and other kinds of content control based on its policy, although the supervision is based on users' reports. Therefore, as we", "answers": "Twitter API", "length": 6585}
{"pred": " 150,000. 112,845 not hate tweets and 36,978 hate tweets. 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets. 5,000 for validation and 10,000 for test.  The remaining tweets are used for training.  The dataset is the biggest hate speech dataset to date, and the first multimodal hate speech dataset.  One of its challenges is to distinguish between tweets using the same key offensive words that constitute or not an attack to a community (hate speech).  The", "answers": "$150,000$ tweets", "length": 6589}
{"pred": " LSTM, Inception v3.  The LSTM was used for textual data and the Inception v3 was used for image data.  The Inception v3 was used as the image features extractor.  The LSTM was used to classify the tweet text.  The Inception v3 was used to classify the image.  The Inception v3 was fine-tuned to extract the features that, combined with the textual information, are optimal for hate speech detection.  The Inception v3 was used to extract the features from the image.  The LSTM was used to extract the features from the tweet text.  The Inception", "answers": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "length": 6583}
{"pred": " FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM.  FCM, SCM, and TKM", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6584}
{"pred": " 6 categories: No attacks to any community, racist, sexist, homophobic, religion based attacks or attacks to other communities. 112,845 not hate tweets and 36,978 hate tweets. The latest are divided in 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets. 112,845 not hate tweets and 36,978 hate tweets. 112,845 not hate tweets and 36,978 hate tweets. 112,845 not hate tweets and 36,978 hate tweets. 112,845 not hate", "answers": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "length": 6591}
{"pred": " No. The answered questions measure for the answerability of the question. The answerability of a question is the likelihood that the question will eventually get an answer. The usefulness of the answer is not measured. The usefulness of the answer is related to the quality of the answer. The quality of the answer is not measured in the passage. The passage only measures the answerability of the question. The answerability of the question is related to the characteristics of the question. The characteristics of the question are measured in the passage. The characteristics of the question are the linguistic structure, the psycholinguistic aspects, and the content of the question.", "answers": ["No"], "length": 7152}
{"pred": " SVM, BiLSTM, CNN.  The CNN system achieved higher performance in the experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT).  The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT).  All three models achieved similar results far surpassing the random baselines, with a slight performance edge", "answers": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "length": 6901}
{"pred": " The dataset proposed in this paper is the first to contain annotation of type and target of offenses in social media. It is different from pre-existing ones in that it includes a hierarchical three-level annotation model that distinguishes between whether language is offensive or not, the type of offense, and the target of the offense. This is in contrast to pre-existing datasets that focus on a different aspect of offensive language, such as abusive language, cyber-aggression, or hate speech. Additionally, this dataset includes a larger number of tweets and a more diverse set of keywords and constructions that are often included in offensive messages. The dataset also includes a more detailed annotation", "answers": "no prior work has explored the target of the offensive language", "length": 6905}
{"pred": " English.  English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English", "answers": "English", "length": 6900}
{"pred": " 14,100. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-pol", "answers": "14,100 tweets", "length": 6902}
{"pred": " 14,100. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-political keywords. 50% of the tweets come from political keywords and 50% come from non-pol", "answers": "Dataset contains total of 14100 annotations.", "length": 6902}
{"pred": " Aggression identification, bullying detection, hate speech identification, and offensive language.  Toxic comments are also explored.  Additionally, cyber-aggression, cyber-bullying, and hate speech are also explored.  Furthermore, abusive language, toxic comments, and hate speech are also explored.  Moreover, offensive language is also explored.  Finally, profanity, insult, and abuse are also explored.  Also, cyber-aggression, cyber-bullying, and hate speech are also explored.  Furthermore, abusive language, toxic comments, and hate speech are also explored.  Moreover, offensive language is also explored.  Finally, prof", "answers": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "length": 6901}
{"pred": " CNN.  The CNN outperforms the RNN model, achieving a macro-F1 score of 0.80. The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT). All three models achieved similar results far surpassing the random baselines, with a slight performance edge for the neural models. The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. The CNN", "answers": "CNN ", "length": 6900}
{"pred": " 6.  In case of 100% agreement, we considered these as acceptable annotations, and in case of disagreement, we requested more annotations until the agreement was above 66%. After the crowdsourcing annotation, we used expert adjudication to guarantee the quality of the annotation. The breakdown of the data into training and testing for the labels from each level is shown in Table TABREF15. We first acquired two annotations for each instance.  In case of 100% agreement, we considered these as acceptable annotations, and in case of disagreement, we requested more annotations until the agreement was above 66%.  We acquired two annotations for", "answers": "five annotators", "length": 6899}
{"pred": " We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.  Not Offensive (NOT): Posts that do not contain offense or profanity. Offensive (OFF): We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.  Not Offensive (NOT): Posts that", "answers": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "length": 6901}
{"pred": " Level A: Offensive language Detection, Level B: Categorization of Offensive Language, Level C: Offensive Language Target Identification.  Level A discriminates between offensive (OFF) and non-offensive (NOT) tweets. Level B categorizes the type of offense and two labels are used: targeted (TIN) and untargeted (INT) insults and threats. Level C categorizes the targets of insults and threats as individual (IND), group (GRP), and other (OTH).  Level A discriminates between offensive (OFF) and non-offensive (NOT) tweets. Level B categorizes the type of offense and two labels", "answers": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "length": 6903}
{"pred": " 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. 300. 14,100. 8,500. ", "answers": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "length": 6904}
{"pred": " Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN, Pointer-Gen+ARL-SEN.  Test set is the headlines from the test set.  Note that we didn't compare to Pointer-Gen+ARL-ROUGE as it is actually Pointer-GEN.  Recall that $\\alpha _{\\text{sen}}(y^*)$ in Equation DISPLAY_FORM19 measures how good (based on reward function) is $y^*$.  Then the loss", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "length": 6253}
{"pred": " 1) For German-English, French-English and Russian-English translations, we computed sentence-level BLEU with the NLTK implementation between the human translations and the automatic translations produced by a state-of-the-art system. We applied this method to these three language pairs only as we are confident about the quality of the corresponding systems. Translations with a score that was too low were manually inspected and sent back to the translators when needed. 2) We manually inspected examples where the source transcript was identical to the translation. 3) We measured the perplexity of the translations using a language model trained on a large amount of clean mon", "answers": ["Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "computed sentence-level BLEU, We manually inspected examples where the source transcript was identical to the translation, measured the perplexity of the translations, computed the ratio of English characters in the translations, calculate similarity scores between transcripts and translations"], "length": 6684}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7215}
{"pred": " Yes. 18 participants were recorded. 19 were initially recorded but one was discarded due to technical difficulties. The participants read 739 sentences. 349 sentences were read in a normal reading paradigm, and 390 sentences in a task-specific reading paradigm. The participants were instructed to read the sentences naturally, without any specific task other than comprehension in the normal reading paradigm. In the task-specific reading paradigm, the participants had to determine whether a certain relation type occurred in the sentence or not. The participants were also asked to decide for each sentence whether it contains the relation or not, i.e. they were actively annotating each sentence. The", "answers": ["No"], "length": 6501}
{"pred": " 65% of the speakers are men, speaking more than 75% of the time. 33.16% of the speakers are women. 22.57% of the total speech time is spoken by women. 35.71% of the total speech time is spoken by Anchor speakers. 29.47% of the speakers within the Anchor category are women. 15.9 min is the average speech time uttered by a female Anchor. 25.2 min is the average speech time uttered by a male Anchor. 49.04% is the average WER for the women Punctual speakers. 38", "answers": ["Women represent 33.16% of the speakers"], "length": 6759}
{"pred": " Yes.  Often the outputs of BioIE systems are used to assist in the creation of databases, or to suggest new paths for research. For example, a ranked list of interacting proteins that are extracted from biomedical literature, but are not present in existing databases, can allow researchers to make informed decisions about which protein/gene to study further. Interactions between drugs are necessary for clinicians who simultaneously administer multiple drugs to their patients. A database of diseases, treatments and tests is beneficial for doctors consulting in complicated medical cases.  A database of diseases, treatments and tests is beneficial for doctors consulting in complicated medical cases.  A database of diseases,", "answers": ["Yes"], "length": 6907}
{"pred": " Nuclear power.  Nuclear power plants.  Anti-nuclear power.  Anti-reconstruction.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power. ", "answers": "anti-nuclear-power", "length": 7167}
{"pred": " 3.  The three layers are a fully connected network, a maximum pooling layer, and a softmax layer.  The fully connected network is the last layer.  The maximum pooling layer is used to select the most important feature for comments.  The softmax layer is used to yield the final stance label prediction for the post.  The three convolutional layers are used to capture the user- and topic-dependent word vectors.  The three convolutional layers are followed by a maximum pooling layer and an average pooling layer.  The maximum pooling layer is used to obtain the unigram, bigram, and trigram n-gram representations.", "answers": "eight layers", "length": 7166}
{"pred": " ABO, GAY, OBA, MAR.  (ABO: abortion, GAY: gay rights, OBA: Obama, MAR: marijuana)  (ABO and MAR are discussed in the passage)  (GAY and OBA are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the", "answers": "abortion, gay rights, Obama, marijuana", "length": 7165}
{"pred": " ABO, GAY, OBA, MAR.  (ABO: abortion, GAY: gay rights, OBA: Obama, MAR: marijuana)  (ABO and MAR are discussed in the passage)  (GAY and OBA are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the", "answers": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "length": 7165}
{"pred": " 505,412.  2,496.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505", "answers": "32,595", "length": 7165}
{"pred": " Yes. They tested the proposed UTCNN on two different datasets: FBFans and CreateDebate. FBFans is a privately-owned, single-topic, Chinese, unbalanced, social media dataset, and CreateDebate is a public, multiple-topic, English, balanced, forum dataset. Results using these two datasets show the applicability and superiority for different topics, languages, data distributions, and platforms. The FBFans dataset contains data from anti-nuclear-power Chinese Facebook fan groups from September 2013 to August 2014, including posts and their author and liker IDs. There are a total of 2,496", "answers": "No", "length": 7163}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, representing a pure-text CNN model, 7) UTCNN without the LDA model, representing how UTCNN works with a single-topic dataset, 8) UTCNN without comments, in which the model predicts the stance label", "answers": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "length": 7162}
{"pred": " CRF, UWAV, BIBREF22, BIBREF24, BIBREF28, BIBREF10, BIBREF23, BIBREF25.  BIBREF4.  BIBREF13, BIBREF14, BIBREF15, BIBREF29, BIBREF30.  BIBREF1.  BIBREF3.  BIBREF6, BIBREF7, BIBREF8.  BIBREF9.  BIBREF11, BIBREF12.  BIBREF16, BIBREF17, BIBREF18", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "length": 6867}
{"pred": " modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "length": 6118}
{"pred": " Wikipedia data and Reddit CMV data.  The Wikipedia data is an expanded version of the annotated Wikipedia conversations dataset from BIBREF9. The Reddit CMV data is constructed from conversations collected via the Reddit API.  The prediction task is to forecast whether the conversation will be subject to moderator action in the future.  The dataset is constructed from the subreddit ChangeMyView (CMV).  The aim is to forecast whether a discussion will later be subject to moderator action due to “rude or hostile” behavior.  The dataset is constructed from the subreddit ChangeMyView (CMV).  The aim is to forecast whether a discussion", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "length": 6538}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\quad \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7055}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 7147}
{"pred": " Multi30K.  English-German dataset.  The English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The Multi30K English-German dataset.  The Multi30K dataset.  The", "answers": ["the English-German dataset"], "length": 7037}
{"pred": " Naive Bayes classifier.  They used a multinomial Naive Bayes classifier.  They also used a multinomial Naive Bayes classifier for their meta-classification approaches.  They used the same algorithm (multinomial NB) on heterogeneous data (i.e., different types of data such as content, occupation, introduction, interests, gender, city and state) in order to exploit all available sources of information.  They used a multinomial Naive Bayes classifier for their stacked generalization (or late fusion) approach.  They used a multinomial Naive Bayes classifier for their ensemble learning results on the development", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "length": 6743}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7168}
{"pred": " They conducted a survey among engineers and analyzed the NLP jobs submitted to a commercial centralized GPU cluster. Table TABREF11 showed that about 87.5% NLP related jobs belong to a few common tasks, including sentence classification, text matching, sequence labeling, MRC, etc. It further suggested that more than 90% of the networks were composed of several common components, such as embedding, CNN/RNN, Transformer and so on.  The authors also mentioned that general-purpose deep learning frameworks, such as TensorFlow, PyTorch and Keras, offer huge flexibility in DNN model design and support various NLP tasks,", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 6687}
{"pred": " A browser-based annotation tool, tagging all descriptions with part-of-speech information, leveraging the structure of Flickr30K Entities, and applying Louvain clustering to the coreference graph.  Additionally, manually categorizing images and counting the proportion of descriptions that contain markers for a particular social class.  Furthermore, looking at the distribution of terms used to describe entities in a particular category.  And, inspecting a subset of the Flickr30K data.  Also, manually detecting stereotypes, biases, and odd phrases.  Finally, using a coreference graph by linking all phrases that refer to the same entity.  And, looking at", "answers": ["spot patterns by just looking at a collection of images, tag all descriptions with part-of-speech information, I applied Louvain clustering", "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging"], "length": 6836}
{"pred": " LSTMs.  PRUs outperform LSTMs by about 4 points on the PTB dataset and by about 3 points on the WT-2 dataset.  PRUs achieve either the same or better performance than LSTMs.  PRUs learn rich representations at very high dimensional space while learning fewer parameters.  On the other hand, LSTMs overfit to the training data at such high dimensions and learn more parameters than PRUs.  PRUs are a drop-in replacement for LSTM, therefore, it can improve language models with modern inference techniques such as dynamic evaluation.  When we evaluate PRU-based language", "answers": ["Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM"], "length": 7140}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 6786}
{"pred": " The law requires an adjustment to your monthly Medicare Part B medical insurance and Medicare prescription drug coverage premiums. This affects less than five percent of people with Medicare. Most people don t pay higher premiums. If you have higher income, you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage. We call the additional amount the income - related monthly adjustment amount. Here s how it works : Part B helps pay for your doctors services and outpatient care. It also covers other medical services, such as physical and occupational therapy, and some home health care. For most beneficiaries, the government pays a substantial portion about 75 percent of", "answers": "The law requires an adjustment to your monthly Medicare Part B medical insurance and Medicare prescription drug coverage premiums . This affects less than five percent of people with Medicare . Most people don t pay higher premiums", "length": 6606}
{"pred": " Social Security uses the most recent federal tax return the IRS provides to us. If you must pay higher premiums, we use a sliding scale to calculate the adjustments, based on your modified adjusted gross income MAGI. Your MAGI is your total adjusted gross income and tax - exempt interest income. If you file your taxes as married, filing jointly and your MAGI is greater than $170,000, you ll pay higher premiums for your Part B and Medicare prescription drug coverage. If you file your taxes using a different status, and your MAGI is greater than $85,000, you ll pay higher premiums. See the chart below,", "answers": "Social Security uses the most recent federal tax return the IRS provides to us . you must pay higher premiums", "length": 6597}
{"pred": " If you have higher income, you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage. We call the additional amount the income - related monthly adjustment amount. Here s how it works : Part B helps pay for your doctors services and outpatient care. It also covers other medical services, such as physical and occupational therapy, and some home health care. For most beneficiaries, the government pays a substantial portion about 75 percent of the Part B premium, and the beneficiary pays the remaining 25 percent. If we determine you re a higher - income beneficiary, you ll pay a larger percentage of the total cost of Part B", "answers": "we use a sliding scale to calculate the adjustments , based on your modified adjusted gross income MAGI . Your MAGI is your total adjusted gross income and tax - exempt interest income .", "length": 6589}
{"pred": " You can find your local SHIP contact information in the back of your Medicare & You 2020 Handbook online, or you can request it when you call.", "answers": "You can find your local SHIP contact information in the back of your Medicare & You 2020 Handbook online", "length": 6611}
{"pred": " You'll pay monthly premiums plus an additional amount, which is based on what you report to the IRS. Because individual plan premiums vary, the law specifies that the amount is determined using a base premium. We tie the additional amount you pay to the base beneficiary premium, not your own premium amount. If you're a higher-income beneficiary, we deduct this amount from your monthly Social Security payments regardless of how you usually pay your monthly prescription plan premiums. If the amount is greater than your monthly payment from Social Security, or you don't get monthly payments, you'll get a separate bill from another federal agency, such as the Centers for Medicare &", "answers": "you ll pay monthly premiums plus an additional amount , which is based on what you report to the IRS . Because individual plan premiums vary , the law specifies that the amount is determined using a base premium .", "length": 6614}
{"pred": " this law does not apply to you.", "answers": " this law does not apply to you ", "length": 6599}
{"pred": "  If you have higher income, you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage. We call the additional amount the income - related monthly adjustment amount. Here s how it works : Part B helps pay for your doctors services and outpatient care. It also covers other medical services, such as physical and occupational therapy, and some home health care. For most beneficiaries, the government pays a substantial portion about 75 percent of the Part B premium, and the beneficiary pays the remaining 25 percent. If we determine you re a higher - income beneficiary, you ll pay a larger percentage of the total cost of Part", "answers": "you ll pay an additional premium amount for Medicare Part B and Medicare prescription drug coverage . We call the additional amount the income - related monthly adjustment amount ", "length": 6594}
{"pred": " Yes.  Both the audio and the transcript are de-identified (by removing the identifying information) with digital zeros and [de-identified] tags, respectively. The sentences in the transcript are grounded to the audio with the timestamps of its first and last word. The transcript of the conversations are annotated with summaries and Medication Regimen tags (MR tags), both grounded using the timestamps of the sentences from the transcript deemed relevant by the expert annotators.  The transcript for a typical conversation can be quite long, and not easy for many of the high performing deep learning models to act on. Moreover, the medical information about a concept/", "answers": ["Yes", "Yes"], "length": 6388}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6771}
{"pred": " Yes, the driving school must be at least 50 square feet, which is accessible by your customers. It must be in a suitable building and at least 1,500 feet from a DMV office or road test area. The driving school must have an experienced instructor who holds a valid instructor's card, and has at least 1,000 hours of experience as a behind-the-wheel instructor. The driving school must keep appropriate records. The driving school must have a vehicle used for training and testing students that meets DMV's requirements. All vehicles except motorcycles must have Student Driver signs and be equipped with dual-control brakes and mirrors for the", "answers": "Sure. If you're interested into opening a driving school, you must know that is necessary to get a DMV's approval for the use of its name in your school.", "length": 6254}
{"pred": " Yes, if your school will teach the Pre-licensing course, you must also have a classroom that meets DMV's requirements. You must also have a qualified, experienced instructor. You must also have a vehicle used for training and testing students that meets DMV's requirements. You must also have a vehicle used for training and testing students that meets DMV's requirements. You must also have a vehicle used for training and testing students that meets DMV's requirements. You must also have a vehicle used for training and testing students that meets DMV's requirements. You must also have a vehicle used for training and testing students that meets DM", "answers": "Good. If you're planning to do that, then you must have adequate facilities and an experienced instructor that holds a valid instructor's card, with at least 1,000 hours of experience. In any case, you must request a premises check.", "length": 6256}
{"pred": " You must receive approval from DMV for the use of the name for your driving school before you submit an application. be at least 50 square feet, which is accessible by your customers be in a suitable building see Part 76.2 for details be at least 1,500 feet from a DMV office or road test area Applicant must be given a receipt for all payments hours of operation schedule of fees NOTE: If your school will teach the Pre - licensing course, you must also have a classroom that meets DMV s requirements see also Request for Premises Check [3]. you must have an experienced instructor who holds a valid instructor", "answers": "LLCs have to submit a copy of their Filing Receipt from the Department of State.", "length": 6260}
{"pred": " You must submit a hard copy of your application, associated documents and fee to this address NYS DMV Bureau of Consumer & Facility Services Application Unit P.O. Box 2700 Albany, NY 12220 - 0700. You will be contacted by a clerk from Vehicle Safety s Application Processing Unit. Once your application is reviewed for completeness at our Albany office, it will be sent to a regional office for review. They will contact you to schedule an on - site investigation. When the automotive facilities inspector AFI arrives to inspect your facility, they will be checking that you have the following items dealer starter kit permanently mounted signs visible from", "answers": "Instructions to file can be found on the NY State Department of State website.", "length": 6234}
{"pred": " If you do not have your Certificate of Authority, do not submit an application with DMV yet! The Certificate of Authority and Sales Tax ID number are issued by the New York State Department of Taxation and Finance DTF. You may apply by visiting the NY State DTF website. Be sure to record your Sales Tax ID on the Original Facility Application.", "answers": "The Certificate of Authority and Sales Tax ID number are issued by the New York State Department of Taxation and Finance.  You can apply by visiting the NY State DTF website.", "length": 6238}
{"pred": " No. DMV does not provide Surety Bonds. You must contact a surety insurance company and have them fill out the Dealer Bond Under NY State Vehicle and Traffic Law Section 415 6-B. Be sure that the business name and mailing address on your bond exactly matches those that show on your application. The amount of the bond depends on the number of vehicles you anticipate selling used motor vehicle dealers. DMV does not provide Surety Bonds; you must contact a surety insurance company and have them fill out the Dealer Bond Under NY State Vehicle and Traffic Law Section 415 6-B pdf [5] VS-3. Be", "answers": "The DMV does not provide Surety Bonds. You will have to contact a surety insurance company and have them fill out the Dealer Bond Under NY State Vehicle and Traffic Law Section 415.", "length": 6238}
{"pred": " 3 feet wide by 2 feet tall.  The sign needs red background and white lettering.  The sign must display \"REGISTERED Facility Number STATE OF NEW YORK MOTOR VEHICLE DEALER\" in two inch block lettering.  The sign must be permanently mounted and visible at all times from the nearest street or highway.  The sign must be at least 3 feet wide by 2 feet tall.  The sign must display \"REGISTERED Facility Number STATE OF NEW YORK MOTOR VEHICLE DEALER\" in two inch block lettering.  The sign must be permanently mounted and visible at all times from the nearest street or", "answers": "The sign must measure at least 3 feet wide by 2 feet tall, and it needs to be a red background with white lettering.", "length": 6244}
{"pred": " modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest, and itineraries.  modelling urban regions, identifying points-of-interest", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "length": 6118}
{"pred": " Benefits Planner: Retirement.", "answers": "Is this for benefits for your family?", "length": 6408}
{"pred": " Yes, if any of your qualified family members apply for benefits with you, we will ask you for their Social Security numbers and their birth certificates.", "answers": "If any of your qualified family members apply for benefits with you ,we will ask you for their Social Security numbers and their birth certificates .", "length": 6410}
{"pred": " Yes. If your pension plan was terminated, you may be able to use the PBGC's Find an Unclaimed Pension tool to find out if you have unclaimed benefits.", "answers": "Use the PBGC's Find an Unclaimed Pension tool to find out if you have unclaimed benefits", "length": 6416}
{"pred": " Yes. only the qualified ones. only those requirements do I need. If you are deaf or hard of hearing, you can call us at TTY. If you are already age 62, you may be able to start your benefits in the month you apply. You should apply for benefits no more than four months before the date you want your benefits to start. Benefits are paid the month after they are due. If your benefits start in April, you will receive your first benefit payment in May. If you are not getting Social Security and you are not ready to retire, you should still use our online retirement benefit application to sign up for", "answers": "Yes, If any of the qualified family members apply for benefits with you ,we will ask you for their Social Security numbers and their birth certificates .", "length": 6425}
{"pred": " The amount needed for a work credit changes from year to year. In 2019, for example, you earn one credit for each $1,360 in wages or self-employment income. When you've earned $5,440, you've earned your four credits for the year.  No, the labor credit is not set in stone, it fluctuates.  The amount needed for a work credit changes from year to year.  In 2019, for example, you earn one credit for each $1,360 in wages or self-employment income.  When you've earned $5,440, you've earned", "answers": "The amount needed for a work credit changes from year to year. In 2019, for example, you earn one credit for every $ 1,360 in wages or self-employment income.", "length": 6431}
{"pred": " The ancient Chinese data we used come from ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era. They used plain and accurate words to express what happened at that time, and thus ensure the generality of the translated materials.  A large part of the data we used come from ancient Chinese history records in several dynasties (about 1000BC-200BC).  A large part of the ancient Chinese data we used come from ancient Chinese history records in several dynasties (about 1000BC-200BC).  A large part of", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "length": 6916}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\quad \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6952}
{"pred": " They conducted a survey among engineers and analyzed the NLP jobs submitted to a commercial centralized GPU cluster. Table TABREF11 showed that about 87.5% NLP related jobs belong to a few common tasks, including sentence classification, text matching, sequence labeling, MRC, etc. It further suggested that more than 90% of the networks were composed of several common components, such as embedding, CNN/RNN, Transformer and so on.  The authors also mentioned that general-purpose deep learning frameworks, such as TensorFlow, PyTorch and Keras, offer huge flexibility in DNN model design and support various NLP tasks,", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 6420}
{"pred": " The John F. Kennedy Profiles in Courage Award.  Brooksley Born, along with Sheila Bair of the FDIC, was awarded the John F. Kennedy Profiles in Courage Award in recognition of the \"political courage she demonstrated in sounding early warnings about conditions that contributed\" to the 2007-08 financial crisis.  According to Caroline Kennedy, \"Brooksley Born recognized that the financial security of all Americans was being put at risk by the greed, negligence and opposition of  powerful and well connected interests.... The catastrophic financial events of recent months have  proved them [Born and Sheila Bair] right.\"  One member of the President's", "answers": ["In 2009, Brooksley Born received the John F. Kennedy Profiles in Courage Award."], "length": 6612}
{"pred": " Fuller's Ranch.  It was established by Charles O. Fuller in 1855.  It provided accommodations for travelers on the Santa Fe Trail.  It was located about two miles south and one mile east of Galva.  It was probably the first white settlement in McPherson County.  Fuller's Ranch was established adjacent to the Running Turkey Creek Crossing.  It was a ranch.  It was established in 1855.  It was located in what is now McPherson County.  It was established by Charles O. Fuller.  It was a ranch.  It was established in 1855. ", "answers": ["The first white settlement in McPherson County was Fuller's Ranch, established by Charles O. Fuller."], "length": 6148}
{"pred": " The dynamical behavior of the anisotropic order parameter following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, $m \\sim t^{1/2}$ and the Binder cumulant $g$ of the lowest transverse mode is zero in this regime. The alternative order parameter $O$, however, distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases. In the LG, the scaling form for $O$ is not compatible with the prediction $O \\sim t^{1/8", "answers": ["It is well described by the Gaussian theory."], "length": 7784}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7168}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6841}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 7477}
{"pred": " English.  The tweets are in English.  The dataset contains 14,100 tweets and is released freely to the research community.  The dataset is in English.  The tweets are in English.  The dataset contains 14,100 English tweets.  The dataset is in English.  The tweets are in English.  The dataset contains 14,100 English tweets.  The dataset is in English.  The tweets are in English.  The dataset contains 14,100 English tweets.  The dataset is in English.  The tweets are in English.  The dataset contains 14,100 English tweets. ", "answers": ["English", "English ", "English"], "length": 6538}
{"pred": " It is a band geometric quantity that measures the k-space curl of the interlayer Berry connection over the occupied states, and hence is also a characteristic of layer-hybridized electronic states. Via an integration by parts, it becomes clear that χ int is a Fermi surface property. Since χ int is a time-reversal even pseudoscalar, it is invariant under rotation, but flips sign under space inversion, mirror reflection and rotoreflection symmetries. As such, χ int is allowed if and only if the system possesses a chiral crystal structure, which is the very case of twisted bilayers. Moreover, since twisted structures", "answers": ["The momentum space curl of the interlayer Berry connection polarizability generates the crossed nonlinear dynamical Hall effect."], "length": 6860}
{"pred": " You can only get health care through CHAMPVA if you don t qualify for TRICARE and at least one of the descriptions below is true for you. At least one of these must be true. You re: The spouse or child of a Veteran who s been rated permanently and totally disabled for a service - connected disability by a VA regional benefit office, or The surviving spouse or child of a Veteran who died from a VA - rated service - connected disability, or The surviving spouse or child of a Veteran who was at the time of death rated permanently and totally disabled from a service - connected disability, or The surviving spouse or child of", "answers": "Are you the spouse or surviving spouse of or a child of a Veteran with disabilities or a Veteran who has died ?", "length": 7235}
{"pred": " no, you may be able to get health insurance through the Civilian Health and Medical Program of the Department of Veterans Affairs CHAMPVA. Through this program, we cover the cost of some of your health care services and supplies. This is called cost sharing. Find out if you qualify for CHAMPVA and how to apply.  Can I get health care through CHAMPVA? You can only get health care through CHAMPVA if you don t qualify for TRICARE and at least one of the descriptions below is true for you. At least one of these must be true. You re: The spouse or child of a Veteran", "answers": "If you don t qualify for TRICARE the Department of Defense s health care program for active - duty and retired service members and their families", "length": 7232}
{"pred": " You can only get health care through CHAMPVA if you don t qualify for TRICARE and at least one of the descriptions below is true for you. At least one of these must be true. You re: The spouse or child of a Veteran who s been rated permanently and totally disabled for a service - connected disability by a VA regional benefit office, or The surviving spouse or child of a Veteran who died from a VA - rated service - connected disability, or The surviving spouse or child of a Veteran who was at the time of death rated permanently and totally disabled from a service - connected disability, or The surviving spouse or child of", "answers": "you may be able to get health insurance through the Civilian Health and Medical Program of the Department of Veterans Affairs CHAMPVA .", "length": 7240}
{"pred": " 855-260-3274.", "answers": "Yes, you can contact the caregiver support line at 855-260-3274", "length": 7255}
{"pred": " You can only get health care through CHAMPVA if you don t qualify for TRICARE and at least one of the descriptions below is true for you. At least one of these must be true. You re: The spouse or child of a Veteran who s been rated permanently and totally disabled for a service - connected disability by a VA regional benefit office, or The surviving spouse or child of a Veteran who died from a VA - rated service - connected disability, or The surviving spouse or child of a Veteran who was at the time of death rated permanently and totally disabled from a service - connected disability, or The surviving spouse or child of", "answers": "You will qualify for this program based on your Veteran’s qualifications. You may be eligible if the Veteran you’re caring for meets both of the requirements  ", "length": 7242}
{"pred": " Yes. To apply for CHAMPVA benefits, you'll need to submit the following required documents: Application for CHAMPVA Benefits VA Form 10-10d, Other Health Insurance Certification VA Form 10-7959c, and documents related to your Medicare status. You may also want to send copies of optional documents, such as the page from the VBA rating decision showing your Veteran is permanently and totally disabled or the death rating if you're a survivor, your Veteran's DD214 Certificate of Release or Discharge from Active Duty, and documents related to any dependent children you're including in your application. You'll need to sign", "answers": "Okay. Does the veteran you are caring for have a serious injury including traumatic brain injury, psychological trauma, or other mental disorder that was caused or made worse by their active-duty service on or after September 11, 2001?", "length": 7237}
{"pred": " no it happened later. If you re the surviving spouse of a qualifying CHAMPVA sponsor and you remarry before age 55, you no longer qualify for CHAMPVA as of midnight on the date of your remarriage. If you remarry on or after your 55th birthday, you can keep your CHAMPVA benefits. If you re the surviving spouse of a qualifying CHAMPVA sponsor and you remarry, but the remarriage ends by death, divorce, or annulment, you may qualify again for CHAMPVA. The first date that you qualify again is the first day of the month after your remarriage", "answers": "If that is true then you are not eligible for this benefit.", "length": 7237}
{"pred": " Multi30K.  English-German dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K dataset.  Multi30K", "answers": ["the English-German dataset"], "length": 7094}
{"pred": " The best performing model among author's submissions is the ensemble+ of (r4, r7 r12) for SLC task, which achieved a score of 0.673 in F1. For FLC task, the best performing model among author's submissions is the ensemble+ of (II and IV), which achieved a score of 0.673 in F1.  The best performing model among author's submissions is the ensemble+ of (II and IV) from each of the folds 1-3, i.e., $|{\\mathcal {M}}|=6$ models to obtain predictions on test. Table TAB", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "length": 6568}
{"pred": " It is a multi-label task.  The first author of this paper annotated the samples using the proposed schema.  The second annotator (second author) validated the findings by annotating 20% of the samples.  The inter-annotator agreement was computed by computing the (micro-averaged) F1 score, where the first annotator's labels were treated as gold.  The overall (micro) average F1 score of the annotations was 0.82.  This means that on average, more than two thirds of the overall annotated labels were agreed on by both annotators.  The full catalogue of features,", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "length": 6516}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7113}
{"pred": " No. The passage does not mention anything about the usefulness of the answer. It only talks about the characteristics of the questions that are answered. The passage focuses on the characteristics of the questions that are answered, such as the number of words used, the diversity of POS tags, and the psycholinguistic aspects of the question askers. It does not discuss the usefulness of the answers. Therefore, the answer to the question is no. The passage does not measure for the usefulness of the answer. It only provides information about the characteristics of the questions that are answered. The usefulness of the answer is not mentioned in the passage. The passage", "answers": ["No"], "length": 6661}
{"pred": " The baseline model, the model used for back-translation, and the DocRepair model are all Transformer base models. More precisely, the number of layers is $N=6$ with $h = 8$ parallel attention layers, or heads. The dimensionality of input and output is $d_{model} = 512$, and the inner-layer of a feed-forward networks has dimensionality $d_{ff}=2048$. We use regularization as described in BIBREF15. As a second baseline, we use the two-pass CADec model BIBREF11. The first pass produces sentence-level translations. The second pass takes", "answers": [" MT system on the data released by BIBREF11", "Transformer base, two-pass CADec model"], "length": 6924}
{"pred": " Nuclear power.  Nuclear power plants.  Anti-nuclear power.  Anti-reconstruction.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power.  Nuclear power plants.  Nuclear power. ", "answers": "anti-nuclear-power", "length": 7167}
{"pred": " 3.  The three layers are a fully connected network, a maximum pooling layer, and a softmax layer.  The fully connected network is the last layer.  The maximum pooling layer is used to select the most important feature for comments.  The softmax layer is used to yield the final stance label prediction for the post.  The three convolutional layers are used to capture the user- and topic-dependent word vectors.  The three convolutional layers are followed by a maximum pooling layer and an average pooling layer.  The maximum pooling layer is used to obtain the unigram, bigram, and trigram n-gram representations.", "answers": "eight layers", "length": 7166}
{"pred": " ABO, GAY, OBA, MAR.  (ABO: abortion, GAY: gay rights, OBA: Obama, MAR: marijuana)  (ABO and MAR are discussed in the passage)  (GAY and OBA are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the", "answers": "abortion, gay rights, Obama, marijuana", "length": 7165}
{"pred": " ABO, GAY, OBA, MAR.  (ABO: abortion, GAY: gay rights, OBA: Obama, MAR: marijuana)  (ABO and MAR are discussed in the passage)  (GAY and OBA are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the passage)  (ABO, GAY, OBA, MAR are discussed in the", "answers": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "length": 7165}
{"pred": " 505,412.  2,496.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505,412.  33,686.  505,137.  2,496.  505", "answers": "32,595", "length": 7165}
{"pred": " Yes. They tested the proposed UTCNN on two different datasets: FBFans and CreateDebate. FBFans is a privately-owned, single-topic, Chinese, unbalanced, social media dataset, and CreateDebate is a public, multiple-topic, English, balanced, forum dataset. Results using these two datasets show the applicability and superiority for different topics, languages, data distributions, and platforms. The FBFans dataset contains data from anti-nuclear-power Chinese Facebook fan groups from September 2013 to August 2014, including posts and their author and liker IDs. There are a total of 2,496", "answers": "No", "length": 7163}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, representing a pure-text CNN model, 7) UTCNN without the LDA model, representing how UTCNN works with a single-topic dataset, 8) UTCNN without comments, in which the model predicts the stance label", "answers": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "length": 7162}
{"pred": " Yes. The No-Answer Baseline (NA), Word Count Baseline, and Human Performance Baseline were tested.  The BERT Baseline was also tested in two different ways: Bert and Bert + Unanswerable.  The BERT Baseline was tested in two different ways: Bert and Bert + Unanswerable.  The BERT Baseline was tested in two different ways: Bert and Bert + Unanswerable.  The BERT Baseline was tested in two different ways: Bert and Bert + Unanswerable.  The BERT Baseline was tested in two different ways: Bert and Bert + Unanswer", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "length": 7250}
{"pred": " No.  The Penn Treebank is a dataset of English texts. However, the authors also mention that they train the skip-gram word embeddings on the one billion word language modeling benchmark dataset, which is a multilingual dataset. They also mention that they use fastText embeddings, which are trained on a multilingual dataset. Therefore, it is likely that they evaluate their model on datasets other than English. However, the specific datasets they use are not mentioned in the passage.  The Penn Treebank is a dataset of English texts. However, the authors also mention that they train the skip-gram word embeddings on the one billion word language", "answers": ["Yes", "Unanswerable"], "length": 7109}
{"pred": " 3.  The three layers are a fully connected network, a maximum pooling layer, and a softmax layer.  The fully connected network is the last layer.  The maximum pooling layer is used to select the most important feature for comments.  The softmax layer is used to yield the final stance label prediction for the post.  The three convolutional layers are used to capture the user- and topic-dependent word vectors.  The three convolutional layers are followed by a maximum pooling layer and an average pooling layer.  The maximum pooling layer is used to obtain the unigram, bigram, and trigram n-gram representations.", "answers": ["eight layers"], "length": 7166}
{"pred": " BIBREF0, SQuAD, Harry Potter and the Sorcerer’s Stone, and Covid-QA.  The Covid-QA dataset contains 1380 questions and gold answer spans. Every question is associated with one of 98 research papers (contexts). The dataset is treated as a test set. The contexts are full documents rather than single paragraphs. The correct answer may appear several times, often with slightly different wordings. Only a single one of the occurrences is annotated as correct. The dataset is challenging because of the differences between the dataset and SQuAD. The authors in BIBREF0 relate the surprisal of", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "length": 7331}
{"pred": " S.  The Sentence corpus (S) consists of domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining. This corpus is used by the IR solver and also used to create the tuple KB T and on-the-fly tuples $T^{\\prime }_{qa}$. Additionally, TableILP uses $\\sim $ 70 Curated tables (C) designed for 4th grade NY Regents exams.  We use the text corpora (S) from BIBREF6 aristo2016:combining to", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 6751}
{"pred": " 58.2% (TupleInf achieves a score of 58.2% as compared to TableILP's ensemble score of 56.7% on the 4th grade set) and 61.4% (TupleInf(C + T) also achieves scores comparable to TableILP on the latter's target Regents questions (61.4% vs TableILP's reported 61.5%)) and 61.5% (TableILP's reported 61.5% on the latter's target Regents questions). 61.4% and 61.5% are the same. So the answer", "answers": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "length": 6748}
{"pred": " No. (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention entity linking.)  (The passage does not mention", "answers": "No", "length": 6746}
{"pred": " No.", "answers": "No", "length": 6748}
{"pred": " ElasticSearch query.  The query was run against a text corpus (S) to retrieve domain-relevant sentences.  The top 200 hits were then run through Open IE v4, and the resulting tuples were aggregated over all answer choices and questions to create the tuple KB (T).  On-the-fly tuples were also generated using the same ElasticSearch query, but ignoring sentences that covered none or all answer choices, as well as long sentences and sentences with negation.  The resulting tuples were then re-scored using the Jaccard score due to the lossy nature of Open IE.  The top 50 scoring tuples were", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 6751}
{"pred": " No. However, it can be extended to do so with the addition of inter-tuple connections to the support graph search, controlled by a small number of rules over the OpenIE predicates. Learning such rules for the Science domain is an open problem and potential avenue of future work.", "answers": "Yes", "length": 6747}
{"pred": " S (a text corpus of approximately 80K sentences and 280 GB of plain text extracted from web pages).  The Sentence corpus (S) consists of domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining. This corpus is used by the IR solver and also used to create the tuple KB T and on-the-fly tuples $T^{\\prime }_{qa}$. Additionally, TableILP uses $\\sim $ 70 Curated tables (C) designed for 4th grade NY Regents exams.  We", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 6751}
{"pred": " Open IE v4.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was used to generate the extractions.  Open IE v4 was", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 6751}
{"pred": " No. However, they suggest that it is possible to add inter-tuple connections to the support graph search, controlled by a small number of rules over the OpenIE predicates. Learning such rules for the Science domain is an open problem and potential avenue of future work.", "answers": "Yes", "length": 6748}
{"pred": " 14 million words. 4,600,465 blog posts. 335,698 blogs. 197,527 bloggers. 153,209 users. 6946 sentences. 16225 unique words. 72782 unique words. 1,217 users. 9,136 users. 9,252 users. 11,701 users. 100,484 women. 52,725 men. 4,600,465 blog posts. 335,698 blogs. 197,527 bloggers. 153,209 users. 6946 sentences. 16225 unique words. 72782 unique words", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "length": 6078}
{"pred": " They use LIWC to group words into categories that reflect certain psycholinguistic or semantic properties. They also measure the usage of words related to people's core values as reported by Boyd et al. using the Meaning Extraction Method (MEM).  They use the distribution of the individual words in a category to compile distributions for the entire category, and therefore generate maps for these word categories.  They also measure the usage of words related to people's core values as reported by Boyd et al. using the Meaning Extraction Method (MEM).  They excavated the sets of words, or themes, using the Meaning Extraction Method (MEM) BIB", "answers": ["using the Meaning Extraction Method", "Unanswerable"], "length": 6502}
{"pred": " 32, 64, 128.  The dataset is divided into three parts with 64%, 16% and 20% of the total dataset into training set, development set and test set respectively.  The dataset volume is almost ten times bigger compared to ILPRL dataset in terms of entities.  The dataset contains the sentences collected from daily newspaper of the year 2015-2016.  The dataset has three major classes Person (PER), Location (LOC) and Organization (ORG).  The dataset is in standard CoNLL-2003 IO format.  The dataset is not lemmatized originally", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "length": 7004}
{"pred": " QuecPython 社区或者联系我们的在线支持：QQ 群 445121768获取 QuecPython 开发固件及加入官方交流群官网主页：https://python.quectel.com官网文件下载（各类资料、工具）：https://python.quectel.com/download官网 wiki（常用于视频教程、手把手教程下载、API 库）：https://python.quectel.com/wiki/#/官网文档中心(拥有从入门到精通的各种文档介绍、必看)：https://python.quectel.com/doc/工单系统", "answers": ["Online documentation, QuecPython community, online support: QQ group 445121768."], "length": 4701}
{"pred": " Greg Dougherty has highlighted several major actions being undertaken by the company for its restructuring plan, including reducing the company's headcount from approximately 3,000 to around 2,200 by January 1, 2014, and likely down to less than 1,500 people by July 1, 2014, reducing executive pay by approximately 15%, simplifying the company's global footprint and organization, and aggressively reducing cost and manufacturing overhead and operating expenses. He also mentioned that the company will focus on creating a post-restructuring strategy and business model, leveraging its core competencies and strong customer relationships to effectively and profitably", "answers": "Oclaro has been implementing a significant restructuring plan, which includes closing our second major asset sale and initiating a company-wide reorganization to strengthen our market focus. We've also refined our manufacturing strategy and started the process of resizing the company by implementing global headcount reductions. The company is downsizing from approximately 3,000 employees to about 1,500 by July 1, 2014, and the executive team and Board of Directors will reduce our pay by 15%. Oclaro has also taken steps to simplify its global footprint by reducing the number of global sites from about 20 to 10 by the end of June 2014. This restructuring is expected to result in a $10 million to $12 million reduction in quarterly spending.", "length": 6776}
{"pred": " We plan to leverage our technology leadership in indium phosphide and lithium niobate materials, devices and photonic integration to offer highly differentiated products at both the component and module level for high-speed transmission in both client and line side applications. We will focus our R&amp;D on the transition to 100G and beyond in the core optical network, enterprise and datacenter interconnects. In the core optical network, 100G coherent technology is taking over traditional direct detection solutions. High-speed optical interconnects are also required to transport massive amounts of data locally and over the few kilometers between enterprise networks, servers, datacenters and", "answers": "Oclaro plans to compete in high growth markets by leveraging its core competencies and strong customer relationships. Our strategy includes the utilization of technology leadership in indium phosphide and lithium niobate materials, devices and photonic integration to offer differentiated products at both the component and module level for high-speed transmission in client and line side applications. The company has been reorganized into two business divisions, one for the client side (optical connectivity) and one for the line side (integrated photonics), with each division responsible for its own operations and contributing about half of the company's revenues.", "length": 6765}
{"pred": " Oclaro has seen robust demand in both the telecom and datacom market segments despite some uncertainty about the exact timing of large scale 100G deployments in China. They have enjoyed strong demand for 100 gigabit CFP product lines, their 10 gigabit tunable products as well as transceivers used in wireless backhaul applications. They have also seen a very large spike in demand for their 40 gigabit line side product lines, which are used in deployments in North America. They have completed their qualification of their dual rate CFP2 product line and it is now released for mass production. On the future product front,", "answers": "Oclaro has seen robust demand in both the telecom and datacom market segments, with strong demand for our 100 gigabit CFP product lines, 10 gigabit tunable products, and transceivers used in wireless backhaul applications. We have also experienced a significant spike in demand for our 40 gigabit line side product lines. Despite these promising developments, the company has faced challenges due to delays in transferring products from Shenzhen to our contract manufacturers, which have impacted customer deliveries and constrained revenue output. However, with changes in our manufacturing strategy, Oclaro expects to improve our customer deliveries and mitigate risks in manufacturing transitions.", "length": 6765}
{"pred": " Repaying debt and restructuring the company. Oclaro can now apply the remainder of these resources to restructure the company, complete its manufacturing transfers, and fund its operating losses to breakeven.", "answers": "Some of the proceeds from the $185 million generated by product line sales were used to repay Oclaro's debt. The remaining resources are being applied to restructure the company, complete its manufacturing transfers, and fund its operating losses to breakeven.", "length": 6770}
{"pred": " $110 million per quarter, non-GAAP gross margins of 20% and operating expenses of 25% of sales. The restructuring costs are expected to be between $20 million and $25 million, spread fairly evenly over the next three quarters.  Oclaro expects to achieve adjusted EBITDA breakeven in one year.  To achieve breakeven on a non-GAAP operating base, further improvement in gross margin percentage is required.  Oclaro expects to achieve adjusted EBITDA breakeven in one year.  The restructuring costs are expected to be between $20 million and $25 million, spread fairly", "answers": "Oclaro expects to spend between $20 million and $25 million to restructure the company and lower its burn rate. With the completion of the restructuring, we estimate debt on revenues of approximately $110 million per quarter, non-GAAP gross margins of 20%, and operating expenses of 25% of sales would help them achieve adjusted EBITDA breakeven. The company aims to achieve this breakeven objective in one year.", "length": 6769}
{"pred": " We did see a strong bookings in the September quarter, and we are pleased with the progress we are making. Our bookings were up 20% from the prior quarter, and we are seeing a good level of demand for our products, particularly in the 40G and 100G transmission markets. In terms of linearity, we did see a good level of order intake throughout the quarter, with a slight pickup in the last month. We are pleased with the way the orders are coming in, and we are seeing a good level of visibility into the future. However, we do expect some variability in the bookings going forward, particularly as", "answers": "Well, I can’t really speak to the linearity and the order patterns, but I would say that, right now, we are not specifically reporting on bookings. But I would say that on a qualitative basis, we had a good month for bookings. It was actually a strong month for bookings.", "length": 6794}
{"pred": " Yes, that's correct. We expect to have the majority of our restructuring actions completed by the end of June 2014, and we expect to achieve adjusted EBITDA breakeven in one year. That's the first milestone, and then we'll work towards achieving breakeven on a non-GAAP operating base. So, yes, that's the correct way to read it.", "answers": "Yes, I think you should use the guidance we gave for the December quarter in combination with the EBITDA model and fill in the next year around those parameters.", "length": 6809}
{"pred": " We have enjoyed strong demand for 100 gigabit CFP product lines, our 10 gigabit tunable products as well as transceivers used in wireless backhaul applications. We have also seen very large spike in demand for our 40 gigabit line side product lines, which are used in deployments in North America. We have completed our qualification of our dual rate CFP2 product line and it is now released for mass production. On the future product front, we had a very successful showing at the ETA Trade Show this year, where we demonstrated our 100G coherent integrated laser and Mach-Zehnder modulator on a single", "answers": "I think that we broke out the percent revenue. The delay in the 100G China Telecom that has been moving target I think since the summer. But it looks good and we feel we are pretty well positioned there. We noted that Huawei was no longer a 10% customer. And I just wanted to ratchet up the reason for that. In the past, our largest 980 pump customer was Huawei and of course that business traveled with them. But we are continuing to view Huawei as a very good, very important customer and we are very well positioned there going forward. Probably the biggest notable trend Rob is in North America with the 40G business, it’s really on the line side, it has really picked up for us last quarter, this quarter. And we are expecting to see residual next quarter well beyond with I think we would have been expecting six months, nine months ago.", "length": 6805}
{"pred": " No. We ll ask you to have a claim exam only if we need more information to decide your claim. If you have enough medical evidence in your file to support your claim, we won t ask you to have a claim exam. Medical evidence may include doctor and hospital reports, test results, and other documents.  If you have any new non - VA medical records like records from a recent surgery or illness, please be sure to submit them before your appointment. The health care provider can t review new information during the exam.  If you have children, you ll need to plan ahead for childcare during your exam. Because you and the", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 7275}
{"pred": " Yes. To get a copy of the final report from your exam, you can : Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 7266}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing. If you were a part of chemical and biological warfare testing through Project 112 or Project Shipboard Hazard and Defense (SHAD), you may be at risk for certain illnesses. The Department of Defense's Deseret Test Center in Fort Douglas, Utah, conducted this testing, which took place aboard ships and on land in various locations from 1962", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 7292}
{"pred": " We ll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating. Each claim is different, but it usually takes us about 3 to 4 months to process a claim from start to finish. The processing time for your claim depends on how complex your claim is and how many conditions you ve claimed. See our most recent estimate for the average number of days to complete a claim Sign in to track your claim Yes. To get a copy of the final report from your exam, you can : Contact your nearest VA regional benefit office, or Call us at ", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 7289}
{"pred": " Yes. To get a copy of the final report from your exam, you can: Contact your nearest VA regional benefit office, or Call us at 800-827-1000 and request an appointment to view your file.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 7286}
{"pred": " Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 7288}
{"pred": " You can also watch our VA claim exams video series. This series offers videos on how to prepare for your VA claim exam, how to use disability benefits questionnaires DBQs, and what to expect at claim exams for the most common disability claims. View the VA claim exams video series. More information and resources are available on the VA website. You can also get help filing a claim by connecting with a Veterans Service Organization VSO or accredited Veterans representative for help applying for benefits. Disability housing grants for Veterans are also available, as well as fiduciary services, VA nursing homes, assisted living, and home health care. Vocational Rehabilitation", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 7266}
{"pred": " The staff at your local VA medical center or a local doctor's office that we partner with will contact you. They'll either send you a letter by mail with the date and time of your exam, or call you to find a time that works for you. Make sure both the VA regional office and the VA medical center nearest you have your up-to-date address, phone number, and email address so you get your exam notice in time. Call the number provided right away to confirm the time and location of your exam. It's important not to miss your scheduled exam, so you'll want to double check that you have the right place and", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 7270}
{"pred": " SVM, BiLSTM, CNN.  The CNN outperforms the RNN model, achieving a macro-F1 score of 0.80. The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT). All three models achieved similar results far surpassing the random baselines, with a slight performance edge for the neural models. The performance of all systems for the OTH class is 0. This poor performances can be explained by two main factors", "answers": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "length": 6910}
{"pred": " The dataset proposed in this paper is the first to contain annotation of type and target of offenses in social media. It is different from pre-existing ones in that it includes a hierarchical three-level annotation model that distinguishes between whether language is offensive or not, the type of offense, and the target of the offense. This model is not present in pre-existing datasets. Additionally, the dataset is designed to capture the nuances of offensive language, including the target of the offense, which is not typically included in pre-existing datasets. The dataset is also larger than some pre-existing ones, with 14,100 tweets. Overall, the dataset proposed in this", "answers": "no prior work has explored the target of the offensive language", "length": 6914}
{"pred": " English.  English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English. English", "answers": "English", "length": 6909}
{"pred": " 14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000", "answers": "14,100 tweets", "length": 6911}
{"pred": " 14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000.  15,000.  300.  14,100.  8,500.  24,000", "answers": "Dataset contains total of 14100 annotations.", "length": 6911}
{"pred": " Aggression identification, bullying detection, hate speech, toxic comments, and offensive language.  Aggression identification: The TRAC shared task on Aggression Identification provided participants with a dataset containing 15,000 annotated Facebook posts and comments in English and Hindi for training and validation. For testing, two different sets, one from Facebook and one from Twitter were provided. Systems were trained to discriminate between three classes: non-aggressive, covertly aggressive, and overtly aggressive. Bullying detection: Several studies have been published on bullying detection. One of them is the one by xu2012learning which apply sentiment analysis to detect bullying in tweets.", "answers": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "length": 6910}
{"pred": " CNN.  The CNN outperforms the RNN model, achieving a macro-F1 score of 0.80. The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT). All three models achieved similar results far surpassing the random baselines, with a slight performance edge for the neural models. The CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. The CNN", "answers": "CNN ", "length": 6909}
{"pred": " 6. 21. 5. 100. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6. 5. 6", "answers": "five annotators", "length": 6908}
{"pred": " We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.  Posts that do not contain offense or profanity are labeled as non-offensive.  This category includes insults, threats, and posts containing profane language or swear words.  Posts that do not contain offense or profanity are labeled as non-offensive.  This category includes insults, threats, and posts containing profane language or swear words.  Posts that do not contain offense or", "answers": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "length": 6910}
{"pred": " Level A: Offensive language Detection, Level B: Categorization of Offensive Language, Level C: Offensive Language Target Identification.  Level A discriminates between offensive (OFF) and non-offensive (NOT) tweets. Level B categorizes the type of offense and two labels are used: targeted (TIN) and untargeted (INT) insults and threats. Level C categorizes the targets of insults and threats as individual (IND), group (GRP), and other (OTH).  Level C categorizes the targets of insults and threats as individual (IND), group (GRP), and other (OTH).  Level C categorizes", "answers": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "length": 6912}
{"pred": " 14,100. 8,500. 8,000. 395. 1,075. 2,407. 8,500. 8,000. 395. 1,075. 2,407. 8,500. 8,000. 395. 1,075. 2,407. 8,500. 8,000. 395. 1,075. 2,407. 8,500. 8,000. 395. 1,075. 2,407. 8,500. 8,", "answers": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "length": 6913}
{"pred": " Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7167}
{"pred": " The accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence. The efficiency of a communication scheme is measured as the fraction of tokens that are kept in the keywords. The retention rate of tokens is measured as the fraction of tokens that are kept in the keywords. The completion times and accuracies for typing randomly sampled sentences from the Yelp corpus are measured. The ROUGE unigram score is used to compare the performance of the ILP-based summarization algorithm with the corresponding manual summaries. The ROUGE unigram score is used to compare the performance of the ILP-based summarization", "answers": ["by training an autocomplete system on 500K randomly sampled sentences from Yelp reviews", "efficiency of a communication scheme $(q_{\\alpha },p_{\\beta })$ by the retention rate of tokens, which is measured as the fraction of tokens that are kept in the keywords, accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence"], "length": 6681}
{"pred": " February 15, 2010.  As the station had to wait for ESPN's contract with rival KFAN and its sister station KFXN to expire, it did not become an ESPN Radio affiliate until April 12, the same day that the Minnesota Twins were scheduled to play the first game in their new ball park, Target Field, against the Boston Red Sox.  As a result Coast to Coast AM and Live on Sunday Night, it's Bill Cunningham were retained during this period.  One ESPN Radio network program, The Herd with Colin Cowherd, was picked up by KSTP immediately following the format change", "answers": ["KSTP switched to a sports radio format on February 15, 2010."], "length": 6803}
{"pred": " Ternary Trans-CNN model.  Fully Connected dense networks.  Hybrid multi-channel CNN and LSTM model.  Transfer Learning on an architecture learnt on about 14,500 messages.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.  Fully Connected dense networks.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.  Fully Connected dense networks.  Convolution based architectures.  Sequence models.  SimpleRNN, LSTM, GRU, Bidirectional LSTM model architecture.", "answers": "Ternary Trans-CNN", "length": 6072}
{"pred": " HEOT.  The labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small. 3189 rows of text messages of average length of 116 words and with a range of 1, 1295. 14,500 messages with an accuracy of 83.90. 7934 messages. 700 tweets/messages were held out for testing. 2489 messages were sent to an offline pipeline for augmenting the data. 7934 messages. 70 tweets/messages were held out", "answers": "HEOT , A labelled dataset for a corresponding english tweets", "length": 6069}
{"pred": " 3189 rows of text messages. 14,500 messages with an accuracy of 83.90. 7934 messages. 2489 messages. 700 tweets/messages. 99,996 tweet IDs. 70,904 tweets. 100K tweets. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3189", "answers": "3189 rows of text messages", "length": 6070}
{"pred": " 3189 rows of text messages. 14,500 messages with an accuracy of 83.90. 7934 messages. 2489 messages. 700 tweets/messages. 99,996 tweet IDs. 70,904 tweets. 100K tweets. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3,189. 14,500. 7934. 2489. 700. 70,904. 99,996. 100K. 3189", "answers": "Resulting dataset was 7934 messages for train and 700 messages for test.", "length": 6070}
{"pred": " The dataset is obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from twitter for the conversations happening in Indian subcontinent. A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small.  Basic summary and examples of the data from the dataset are below. The obtained data set had many challenges and thus a data preparation task was employed to clean the data and make it ready for the deep learning pipeline. The challenges and processes that were applied", "answers": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "length": 6070}
{"pred": " No.", "answers": "No", "length": 6072}
{"pred": " Ternary Trans-CNN model, Hybrid multi-channel CNN and LSTM model.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Bidirectional LSTM model architecture.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Convolution based architectures, Sequence models.  Fully Connected dense networks, Conv", "answers": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "length": 6071}
{"pred": " No. The dataset is obtained from Twitter. The tweets are crawled from Twitter. The dataset is called HEOT. HEOT is a dataset of cleaned tweets obtained from Twitter for the conversations happening in Indian subcontinent. A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al. This dataset was important to employ Transfer Learning to our task since the number of labeled dataset was very small. The dataset is used for the task of detecting hate speech in Hinglish. The dataset is used to train and test the model. The dataset is used to evaluate the performance of the model. The dataset is used to", "answers": "No", "length": 6075}
{"pred": " 110 hours.  110 hours of German-English ST corpus from LibriVox audiobooks.  110-hour German-English ST corpus. 110 hours of German speeches. 110 hours of German-English ST corpus. 110 hours of German. 110 hours of German-English. 110 hours of German. 110 hours of German-English ST corpus. 110 hours of German. 110 hours of German-English. 110 hours of German. 110 hours of German-English. 110 hours of German. 110 hours of German-English. 110 hours of German.", "answers": ["Unanswerable", "Unanswerable"], "length": 6191}
{"pred": " BIBREF0.  BIBREF1, BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6, BIBREF7, BIBREF8, BIBREF9.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from BIBREF0.  The dataset from B", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "length": 7038}
{"pred": " 2013–2014.  The club won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  The club won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 201", "answers": ["In the 2013-2014 season."], "length": 7059}
{"pred": " No. The diversity metric of POS tags is used to measure the answerability of questions. The diversity metric of POS tags is lower for answered questions. The diversity metric of POS tags is used to measure the answerability of questions. The diversity metric of POS tags is lower for answered questions. The diversity metric of POS tags is used to measure the answerability of questions. The diversity metric of POS tags is lower for answered questions. The diversity metric of POS tags is used to measure the answerability of questions. The diversity metric of POS tags is lower for answered questions. The diversity metric of POS tags is used to measure the answerability of", "answers": ["No"], "length": 7139}
{"pred": " 23 September. 2017.  However, the Prime Minister later confirmed that his party would approach ACT, United Future and the Māori Party if confidence and supply agreements were required to form a government following the election.  In his second cabinet reshuffle on 24 April, English appointed Gerry Brownlee as his new Foreign Affairs Minister; he also promoted Nikki Kaye to the portfolio of Education Minister, and moved Mark Mitchell into the cabinet to become Defence Minister. The reshuffle was perceived as an election preparation.  On 13 February 2017, English welcomed Australian Prime Minister Malcolm Turnbull to Wellington. The two leaders reaff", "answers": ["23 September."], "length": 6566}
{"pred": " Personal attack, racism, and sexism.  Three types of social networks (Formspring: a Q&A forum, Twitter: microblogging, and Wikipedia: collaborative knowledge repository) for three topics of cyberbullying.  However, Formspring dataset is not specifically about any single topic. Twitter dataset contains examples of racism and sexism. Wikipedia dataset contains examples of personal attack.  However, Formspring dataset is not specifically about any single topic.  All three datasets have the problem of class imbalance where posts labeled as cyberbullying are in the minority as compared to neutral posts.  Variation in the number of posts across datasets also affects vocabulary", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "length": 6789}
{"pred": " The bigger the receptive field size, the more successful the algorithm is in filling in the gaps. Models with bigger receptive field size can complete shapes with bigger gaps.  The bigger the filter size, the more successful the algorithm is in filling in the gaps.  The bigger the receptive field size, the more complete shapes we can reconstruct using DSP.  The bigger the receptive field size, the more successful the algorithm is in filling in the gaps.  The bigger the receptive field size, the more complete shapes we can reconstruct using DSP.  The bigger the receptive field size, the more successful the algorithm is in filling in the gaps. ", "answers": ["Bigger receptive field size leads to more successful shape completion."], "length": 6247}
{"pred": " No. We’ll ask you to have a claim exam only if we need more information to decide your claim. If you have enough medical evidence in your file to support your claim, we won’t ask you to have a claim exam. Medical evidence may include doctor and hospital reports, test results, and other documents.  If you have enough medical evidence in your file to support your claim, we won’t ask you to have a claim exam. Medical evidence may include doctor and hospital reports, test results, and other documents.  If you have enough medical evidence in your file to support your claim, we won’t ask you to have a", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 7141}
{"pred": " Yes. To get a copy of the final report from your exam, you can: Contact your nearest VA regional benefit office, or Call us at 800-827-1000 and request an appointment to view your file.", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 7132}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing. If you were a part of chemical and biological warfare testing through Project 112 or Project Shipboard Hazard and Defense SHAD, you may be at risk for certain illnesses. The Department of Defense's Deseret Test Center in Fort Douglas, Utah, conducted this testing, which took place aboard ships and on land in various locations from 1962 to", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 7158}
{"pred": " We ll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating. Each claim is different, but it usually takes us about 3 to 4 months to process a claim from start to finish. The processing time for your claim depends on how complex your claim is and how many conditions you ve claimed. See our most recent estimate for the average number of days to complete a claim Sign in to track your claim Yes. To get a copy of the final report from your exam, you can : Contact your nearest VA regional benefit office, or Call us at ", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 7155}
{"pred": " Yes.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 7152}
{"pred": " Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 7154}
{"pred": " You can also watch our VA claim exams video series. This series offers videos on how to prepare for your VA claim exam, how to use disability benefits questionnaires DBQs, and what to expect at claim exams for the most common disability claims. View the VA claim exams video series. More information about what happens after you file your claim How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments. Check claim and appeal statusTrack the status of your disability claims and appeals. Appeals processFind out what to do if you disagree with your disability rating decision. VA disability compensation VA disability compensation pay offers a monthly", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 7132}
{"pred": " The staff at your local VA medical center or a local doctor's office that we partner with will contact you. They'll either send you a letter by mail with the date and time of your exam, or call you to find a time that works for you. Make sure both the VA regional office and the VA medical center nearest you have your up-to-date address, phone number, and email address so you get your exam notice in time. Call the number provided right away to confirm the time and location of your exam. It's important not to miss your scheduled exam, so you'll want to double check that you have the right place and", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 7136}
{"pred": " Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7103}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\quad \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6942}
{"pred": " 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) two mature deep learning models on text classification, CNN and Recurrent Convolutional Neural Networks (RCNN), 5) the above SVM and deep learning models with comment information, 6) UTCNN without user information, representing a pure-text CNN model, 7) UTCNN without the LDA model, representing how UTCNN works with a single-topic dataset, 8) UTCNN without comments, in which the model predicts the stance label", "answers": ["SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, ecurrent Convolutional Neural Networks, SVM and deep learning models with comment information", "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information"], "length": 7162}
{"pred": " 9 folds of the training data.  The 10th fold is used to predict labels for the 10th fold.  The model is retrained on the 9 folds.  The model is retrained 10 times.  The 10th fold is used to predict labels for the 10th fold.  The model is retrained on the 9 folds.  The model is retrained 10 times.  The 10th fold is used to predict labels for the 10th fold.  The model is retrained on the 9 folds.  The model is retrained 10 times.", "answers": ["57,505 sentences", "57,505 sentences"], "length": 7167}
{"pred": " No.  The text does not mention any baseline.  The system outperformed other participants' systems and previous works in this domain.  The text does not mention any baseline.  The system outperformed other participants' systems and previous works in this domain.  The text does not mention any baseline.  The system outperformed other participants' systems and previous works in this domain.  The text does not mention any baseline.  The system outperformed other participants' systems and previous works in this domain.  The text does not mention any baseline.  The system outperformed other participants' systems and previous works", "answers": ["No", "No"], "length": 6964}
{"pred": " Environmental fluctuation and uncertainty.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity. Interestingly, the form of the emerging plasticity rule is additionally determined by the details of the task the artificial organisms are aiming to solve.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " He loses his job and Njoroge's family is forced to move. Ngotho is left barely alive after being brutally beaten by Mr. Howlands. He soon dies from his injuries.  Ngotho's position as the central power of the family weakened, to the point where his self-realization that he has spent his whole life waiting for the prophecy (that proclaims the blacks will be returned their land) to come true rather than fighting for Kenyan independence, leads to his depression.  Ngotho's death is a result of his injuries.  Ngotho's death is a result", "answers": ["After attacking Jacobo at a workers' strike, Ngotho loses his job and Njoroge's family is forced to move."], "length": 6268}
{"pred": " The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South West Ultras fan club.  The South", "answers": ["South West Ultras fan club."], "length": 6847}
{"pred": " Flickr. 70 million Flickr photos with coordinates in Europe. Natura 2000 dataset. SoilGrids. CORINE land cover classes. ScenicOrNot website. European network of nature protected sites. Flickr tags. Structured scientific data. European network of nature protected sites. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr. Flickr", "answers": [" the same datasets as BIBREF7", "same datasets as BIBREF7"], "length": 6120}
{"pred": " General Forbearance, Mandatory Forbearance.  There are two main types of forbearance.  General Forbearance is a discretionary forbearance that your loan servicer decides whether to grant a request for.  Mandatory Forbearance is a forbearance that your loan servicer is required to grant if you meet the eligibility requirements.  The eligibility requirements for Mandatory Forbearance include serving in an AmeriCorps position, qualifying for partial repayment of your loans under the U.S. Department of Defense Student Loan Repayment Program, serving in a medical or dental internship or residency program, being a member of the National", "answers": "The two main types are general forbearance and mandatory forbearance.", "length": 6984}
{"pred": " Teacher Loan Forgiveness Forbearance Request.", "answers": "It would be teacher loan forgiveness if you are performing a teaching service that would qualify you", "length": 6987}
{"pred": " If you re having trouble repaying your loans due to circumstances that may continue for an extended period, or if you re unsure when you ll be able to afford to make your monthly loan payments again, a better option might be to change to an income - driven repayment plan. Income - driven repayment plans base your monthly payments on your income and family size. In some cases, your payment could be as low as $0 per month. They can also provide loan forgiveness if your loan is not paid in full after 20 or 25 years. Always contact your student loan servicer immediately if you re having trouble making your student loan payments.", "answers": "Income-driven repayment plans base your monthly payments on your income and family size, meaning that in some cases, you payment under this plan could become as low as $0 per month. ", "length": 6989}
{"pred": " Yes, you are eligible for this deferment if you re enrolled at least half-time at an eligible college or career school. If you re a graduate or professional student who received a Direct PLUS Loan, you qualify for an additional six months of deferment after you cease to be enrolled at least half-time. In most cases, your loan will be placed into a deferment automatically based on enrollment information reported by your school, and your loan servicer will notify you that the deferment has been granted. If you enroll at least half-time but do not automatically receive a deferment, you should contact the school where you are enrolled. Your school", "answers": "With that option, in most cases your loan will be placed into a deferment automatically based on enrollment information reported by your school, and your loan servicer will notify you that the deferment has been granted. ", "length": 6991}
{"pred": " Yes. You may be eligible for a military service and post-active duty student deferment. This deferment ends when you resume enrollment in an eligible college or career school on at least a half-time basis or 13 months following the completion date of active duty service and any applicable grace period, whichever is earlier. Complete the Military Service and Post-Active Duty Student Deferment Request.  You are also eligible for an in-school deferment if you are enrolled at least half-time at an eligible college or career school. If you are a graduate or professional student who received a Direct PLUS Loan, you qualify for an additional six months of defer", "answers": "You may be eligible for this deferment if you are on active duty military service in connection with a war, military operation, or national emergency. ", "length": 6990}
{"pred": " Yes.  You may be eligible for a mandatory forbearance.  You may be eligible for a mandatory forbearance in the following circumstances. Note: The mandatory forbearances discussed below apply only to Direct Loans and FFEL Program loans unless otherwise noted.  AmeriCorps  You are serving in an AmeriCorps position for which you received a national service award.  Request an AmeriCorps forbearance.  Department of Defense Student Loan Repayment Program  You qualify for partial repayment of your loans under the U.S. Department of Defense Student Loan Repayment Program.  Complete the Mandatory Forbearance", "answers": "You may be eligible for this deferment. ", "length": 6987}
{"pred": " You may qualify for this deferment if you are enrolled in an approved graduate fellowship program. A graduate fellowship program is generally a program that provides financial support to graduate students to pursue graduate studies and research. Most graduate fellowship programs are for doctoral students, but some are available to master's degree students. Complete the Graduate Fellowship Deferment Request.  If you re a graduate or professional student who received a Direct PLUS Loan, you qualify for an additional six months of deferment after you cease to be enrolled at least half-time. Important! If you are enrolled in an eligible college or career school at least half-time, in most cases your loan", "answers": "You could complete the Graduate Fellowship Deferment Request if you are enrolled in an approved graduate fellowship program, which is generally a program that provides financial support to graduate students to pursue graduate studies and research. ", "length": 6979}
{"pred": " They built a dataset of Twitter accounts based on two lists annotated in previous works. For the non-factual accounts, they relied on a list of 180 Twitter accounts from BIBREF1. This list was created based on public resources where suspicious Twitter accounts were annotated with the main fake news types (clickbait, propaganda, satire, and hoax). They discarded the satire labeled accounts since their intention is not to mislead or deceive. On the other hand, for the factual accounts, they used a list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy by independent third parties. They discarded some accounts that publish", "answers": "public resources where suspicious Twitter accounts were annotated, list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy", "length": 6554}
{"pred": " relu, selu, tanh.  They also tested other activation functions.  They used the following activation functions: relu, selu, tanh.  They also tested other activation functions.  They used the following activation functions: relu, selu, tanh.  They also tested other activation functions.  They used the following activation functions: relu, selu, tanh.  They also tested other activation functions.  They used the following activation functions: relu, selu, tanh.  They also tested other activation functions.  They used the following activation functions: relu, selu, tanh.", "answers": "relu, selu, tanh", "length": 6557}
{"pred": " LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets.  The results show that our approach produces superior results at detecting non-factual accounts.  The sequence of these tweets is better captured by our proposed model sequence-agnostic or non-neural classifiers.  Moreover, the results demonstrate that the features at tweet-level do not perform well to detect the Twitter accounts factuality, since they obtain a result near to the majority class ($0.18$).  Another finding", "answers": "Top-$k$ replies, likes, or re-tweets, FacTweet (tweet-level), LR + All Features (chunk-level), LR + All Features (tweet-level), Tweet2vec, LR + Bag-of-words", "length": 6555}
{"pred": " Each chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. They are split from the account's timeline. Each chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. They are split from the account's timeline. Each chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. They are split from the account's timeline. Each chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. They are split from the account's timeline. Each chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. They are", "answers": "Chunks is group of tweets from single account that  is consecutive in time - idea is that this group can show secret intention of malicious accounts.", "length": 6552}
{"pred": " Emotion, Sentiment, Morality, Style, Words embeddings.  Emotion: We build an emotions vector using word occurrences of 15 emotion types from two available emotional lexicons. We use the NRC lexicon BIBREF10, which contains $\\sim $14K words labeled using the eight Plutchik's emotions BIBREF11. The other lexicon is SentiSense BIBREF12 which is a concept-based affective lexicon that attaches emotional meanings to concepts from the WordNet lexical database. It has $\\sim $5.5 words labeled with emotions from a set of 14 emotional categories We use", "answers": "Sentiment, Morality, Style, Words embeddings", "length": 6552}
{"pred": " No.  The approach used in this work to detect fake news was not fully supervised. It was a semi-supervised approach. The authors used a list of propaganda, hoax and clickbait accounts and compared different versions of sequential chunk-based approaches using a variety of feature sets against several baselines. The authors also used a list of trustworthy accounts to compare the results. The authors did not use a fully supervised approach where the model is trained on a large dataset of labeled tweets. The authors used a semi-supervised approach where the model is trained on a small dataset of labeled tweets and a large dataset of unlabeled tweets. The authors also", "answers": "Yes", "length": 6561}
{"pred": " Words embeddings, style, and morality features.  Other features (emotion and sentiment) show lower importance: nevertheless, they still improve the overall system performance (on average 0.35% Macro-F$_1$ improvement).  These performance figures suggest that non-factual accounts use semantic and stylistic hidden signatures mostly while tweeting news, so as to be able to mislead the readers and behave as reputable (i.e., factual) sources.  We leave a more fine-grained, diachronic analysis of semantic and stylistic features – how semantic and stylistic signature evolve across time and change across the accounts' timelines – for future", "answers": "words embeddings, style, and morality features", "length": 6565}
{"pred": " 180 non-factual accounts and 32 factual accounts.  The dataset is unbalanced.  The dataset contains 180 non-factual accounts and 32 factual accounts.  The dataset is unbalanced.  The dataset contains 180 non-factual accounts and 32 factual accounts.  The dataset is unbalanced.  The dataset contains 180 non-factual accounts and 32 factual accounts.  The dataset is unbalanced.  The dataset contains 180 non-factual accounts and 32 factual accounts.  The dataset is unbalanced.  The dataset contains 180 non-factual accounts and 32 factual accounts. ", "answers": "Total dataset size: 171 account (522967 tweets)", "length": 6557}
{"pred": " A chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account. Each chunk consists of s tweets. Each tweet in ck_i contains s tweets. Each tweet in ck_i is represented by a vector v ∈ R^d, where v is the concatenation of a set of features' vectors, that is v = ⟨f1, …, fn⟩. Each feature vector fi is built by counting the presence of tweet's words in a set of lexical lists. The final representation of the tweet is built by averaging the single word vectors. The tweets are sorted by the posting date in ascending way and we split them", "answers": "chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account", "length": 6560}
{"pred": " LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets.  The results show that our approach produces superior results at detecting non-factual accounts.  The sequence of these tweets is better captured by our proposed model sequence-agnostic or non-neural classifiers.  Moreover, the results demonstrate that the features at tweet-level do not perform well to detect the Twitter accounts factuality, since they obtain a result near to the majority class ($0.18$).  Another finding", "answers": "LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets", "length": 6556}
{"pred": " 3.  The three layers are a fully connected network, a maximum pooling layer, and a softmax layer.  The fully connected network is the last layer.  The maximum pooling layer is used to select the most important feature for comments.  The softmax layer is used to yield the final stance label prediction for the post.  The three convolutional layers are used to capture the user- and topic-dependent word vectors.  The three convolutional layers are followed by a maximum pooling layer and an average pooling layer.  The maximum pooling layer is used to obtain the unigram, bigram, and trigram n-gram representations.", "answers": ["eight layers"], "length": 7166}
{"pred": " Iraq.  The text is about the situation in Iraq.  It discusses the political situation, the violence, and the impact on the people of Iraq.  It also mentions the US military presence in Iraq and the efforts of some people to bring attention to the issue of the wars in Iraq and Afghanistan.  The text also discusses the situation of Iraqi Christians and the impact of the violence on them.  It also mentions the situation of Iraqi women and their lack of representation in the new government.  The text also discusses the situation of Iraqi refugees and the challenges they face.  The text also mentions the US military presence in Iraq and the", "answers": ["The main topic of the text is Iraq's politics and current situation."], "length": 7052}
{"pred": " 635Hrs of audio data for 7 Indian languages. \nNote: This answer is incorrect. The correct answer is 635Hrs of audio data for 7 Indian languages, namely Kannada, Hindi, Telugu, Malayalam, Bengali, and English. They collected the data from the All India Radio news channel. \n\nHowever, the question is related with Passage 1. \nAnswer: They use a dataset of tweets. \nNote: This answer is correct. They use a dataset of tweets. \n\nHowever, the question is related with Passage 1. \nAnswer: They use a dataset of tweets. \n", "answers": ["Unanswerable", " Paraphrase Database (PPDB) ,  book corpus", "Unanswerable"], "length": 7009}
{"pred": " Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.  The club headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan.", "answers": ["The club's headquarters are located on Jivani Street 2 of the Malatia-Sebastia District, Yerevan."], "length": 7103}
{"pred": " English.  English Wikipedia and Simple English Wikipedia are used in this paper.  The paper aims to simplify English texts.  The NMT model is trained on English data.  The paper evaluates the performance of text simplification on English datasets.  The paper uses English metrics to evaluate the performance of text simplification.  The paper discusses the use of English simplified corpora to improve the performance of NMT models for text simplification.  The paper proposes a method to use simplified English corpora during training of NMT systems.  The paper evaluates the performance of the proposed method on English datasets.  The paper compares the performance of", "answers": ["English", "Simple English"], "length": 6181}
{"pred": " Their model's performance is compared to the following systems, for which results are reported in the referred literature. Please note that no other existing model was re-implemented, and results are those reported in the respective papers. Our B-M model relies on subsets of Facebook pages for training, which were chosen according to their performance on the development set as well as on the observation of emotions distribution on different pages and in the different datasets, as described in Section SECREF4. The feature set we use is our best on the development set, namely all the features plus Google-based embeddings, but excluding the lexicon. This makes our approach completely independent of", "answers": ["Answer with content missing: (Table 3) Best author's model B-M average micro f-score is 0.409, 0.459, 0.411 on Affective, Fairy Tales and ISEAR datasets respectively. "], "length": 7274}
{"pred": " 5.  The five experiments are: 1) picking and placing a bottle using a tripod grasp, 2) picking, rotating and placing a chips can on a box using a tripod grasp, 3) picking, rotating and handing over the chips can to a person using a tripod grasp, 4) picking, rotating and handing over a brown foam brick to a person using a pinch grasp, 5) a person handed over a plastic cup to the robot, filled it with coins to increase its weight, and the robot then handed it back to the person using a tripod grasp.  The experiments are shown in the figures", "answers": ["5."], "length": 6999}
{"pred": " The Carnegie Mellon Pronouncing Dictionary and the multilingual pronunciation corpus collected by deri2016grapheme.  The corpus consists of spelling–pronunciation pairs extracted from Wiktionary. It is already partitioned into training and test sets. Corpus statistics are presented in Table TABREF10. In addition to the raw IPA transcriptions extracted from Wiktionary, the corpus provides an automatically cleaned version of transcriptions. Cleaning is a necessary step because web-scraped data is often noisy and may be transcribed at an inconsistent level of detail. The data cleaning used here attempts to make the transcriptions consistent with the phonemic inventories used", "answers": ["the Carnegie Mellon Pronouncing Dictionary BIBREF12, the multilingual pronunciation corpus collected by deri2016grapheme , ranscriptions extracted from Wiktionary", "multilingual pronunciation corpus collected by deri2016grapheme"], "length": 6428}
{"pred": " Relation detection.  The core component for KBQA is relation detection.  The relation detection subtask is a key task in KBQA systems, and it is responsible for identifying the relations between entities in the question and the knowledge base.  The relation detection subtask is challenging due to the large number of relation types in the knowledge base and the need to handle unseen relations during testing.  The relation detection subtask is typically performed using a combination of natural language processing and machine learning techniques.  The output of the relation detection subtask is a set of relations that are likely to be relevant to the question, which are then used to generate", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "length": 6735}
{"pred": " Gene transfer to hemophilia A mice via oral delivery of FVIII-chitosan nanoparticles. Sustained viral gene delivery through core-shell fibers.  Transport of chitosan-DNA nanoparticles in human intestinal M-cell model versus normal intestinal enterocytes.  Low Oxygen Tension and Synthetic Nanogratings Improve the Uniformity and Stemness of Human Mesenchymal Stem Cell Layer.  Efficacy of engineered FVIII-producing skeletal muscle enhanced by growth factor-releasing co-axial electrospun fibers.  Nucleic acid scavengers inhibit thrombosis without increasing bleeding.  Tuning Physical Properties of Nanocom", "answers": ["Sustained viral gene delivery through core-shell fibers and Gene transfer to hemophilia A mice via oral delivery of FVIII-chitosan nanoparticles."], "length": 6709}
{"pred": " January 1929.  Upon the completion of the training in January 1929, he was designated Naval aviator.  Goodwin was subsequently attached to the Observation Squadron aboard the aircraft carrier  and participated in the Fleet exercises in the Caribbean.  He was transferred to the Bureau of Aeronautics in Washington, D.C. in August 1931 and served consecutively under the architect of naval aviation William A. Moffett and future Chief of Naval Operations Ernest J. King.  In June 1933, Goodwin was ordered to the Naval War College at Newport, Rhode Island, where he completed junior course in", "answers": ["Goodwin became a Naval aviator in January 1929."], "length": 7114}
{"pred": " Permanent yellow spot damage on the screen. Screen damage caused by sunlight exposure or other strong sources of light is not covered by the warranty.", "answers": ["Exposure to sunlight or strong light may cause permanent yellow spot damage on the screen."], "length": 5324}
{"pred": " NUBes-PHI and MEDDOCAN.  NUBes-PHI is a corpus of around 7,000 real medical reports written in Spanish and annotated with negation and uncertainty information. MEDDOCAN is a synthetic corpus of clinical cases enriched with sensitive information by health documentalists.  The MEDDOCAN corpus contains more sensitive information annotations, both in absolute and relative terms.  The sensitive annotation categories considered in MEDDOCAN differ in part from those in NUBes-PHI. Most notably, it contains finer-grained labels for location-related mentions –namely, `Address', `Territory', and `Country", "answers": ["MEDDOCAN, NUBes-PHI", "MEDDOCAN, NUBes "], "length": 6104}
{"pred": " The ancient Chinese data we used come from ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era. They used plain and accurate words to express what happened at that time, and thus ensure the generality of the translated materials.  They were collected from the internet.  A large part of the ancient Chinese data we used come from ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era. They used plain and accurate words to express what happened at that time, and thus ensure the", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "length": 6843}
{"pred": " The nuclear liquid-gas transition in the strong coupling regime of lattice QCD.  The nuclear liquid-gas transition from a gas of hadrons to a nuclear phase cannot be determined numerically from conventional lattice QCD due to the severe sign problem at large values of the baryon chemical potential. In the strong coupling regime of lattice QCD with staggered quarks, the dual formulation is suitable to address the nuclear liquid gas transition.  We determine this first order transition at low temperatures and as a function of the quark mass and the inverse gauge coupling β. We also determine the baryon mass and discuss the nuclear interactions as", "answers": ["Nuclear liquid-gas transition in lattice QCD."], "length": 7196}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\end{document} \\", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7774}
{"pred": " No. The passage does not mention anything about the usefulness of the answer. It only talks about the characteristics of the questions that are answered. The passage focuses on the characteristics of the questions that are answered, such as the number of words used, the type of words used, the part-of-speech tags, and the psycholinguistic aspects of the question asker. It does not mention anything about the usefulness of the answer. Therefore, the answer to the question is no. The passage does not provide any information about the usefulness of the answer. It only provides information about the characteristics of the questions that are answered. 0.5", "answers": ["No"], "length": 7027}
{"pred": " No.  The dataset of 1,000 randomly selected tweets contains more than twice as many tweets about Trump than about the other candidates.  In the sentiment analysis experiments, we found that a tweet may contain multiple sentiments. The groundtruth labels contain 210 positive sentiments, 521 neutral sentiments, and 305 negative sentiments to the candidates.  We measured the CCR, across all tweets, to be 31.7% for Rosette Text Analytics, 43.2% for Google Cloud, 44.2% for TensiStrength, and 74.7% for the crowdworkers. This means the difference between", "answers": ["No"], "length": 6856}
{"pred": " The dynamical behavior of the anisotropic order parameter following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2) and the Binder cumulant g of the lowest transverse mode is zero in this regime. The alternative order parameter O, however, distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases. In the LG, the scaling form for O is not compatible with the prediction O ∼ t^(1/8) L_∥^(-", "answers": ["It is well described by the Gaussian theory."], "length": 6858}
{"pred": " It is a multi-label task.  The first author of this paper annotated the samples using the proposed schema.  The second annotator (second author) validated the findings by annotating 20% of the samples.  The inter-annotator agreement was computed by computing the (micro-averaged) F1 score, where the first annotator's labels were treated as gold.  The overall (micro) average F1 score of the annotations was 0.82.  This means that on average, more than two thirds of the overall annotated labels were agreed on by both annotators.  The full catalogue of features,", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "length": 6516}
{"pred": " CRF, Pipeline.  UWAV.  BIBREF4.  BIBREF25.  BIBREF23.  BIBREF10.  BIBREF28.  BIBREF22.  BIBREF24.  BIBREF7.  BIBREF8.  BIBREF9.  BIBREF5.  BIBREF6.  BIBREF1.  BIBREF2.  BIBREF3.  BIBREF0.  BIBREF4.  BIBREF5.  BIBREF6.  BIBREF1", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "length": 7426}
{"pred": " A group of 50 native people who were well-versed in both English and Tamil languages acted as annotators for the evaluation. A collection of samples of about 100 sentences were taken from the test set results for comparison. This set included a randomized selection of the translation results to ensure the objectivity of evaluation. Fluency and adequacy results for the RNNMorph results are tabulated. Adequacy rating was calculated on a 5-point scale of how much of the meaning is conveyed by the translation (All, Most, Much, Little, None). The fluency rating was calculated based on grammatical correctness on a ", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "length": 6890}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 7166}
{"pred": " English, Spanish, Finnish.  English-Spanish, English-Finnish.  Spanish, Finnish, English.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish.  English, Spanish, Finnish", "answers": ["English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish", "English, Spanish, Finnish"], "length": 6791}
{"pred": " 30. INLINEFORM0. INLINEFORM1. INLINEFORM2. INLINEFORM3. INLINEFORM4. INLINEFORM5. INLINEFORM6. INLINEFORM7. INLINEFORM8. INLINEFORM9. INLINEFORM10. INLINEFORM11. INLINEFORM12. INLINEFORM13. INLINEFORM14. INLINEFORM15. INLINEFORM16. INLINEFORM17. INLINEFORM18. INLINEFORM19. INLINEFORM20. INLINEFORM21. INLINEFORM22. INLINEFORM23. INLINEFORM24. INLINEFORM25. INLINEFORM26. INLINEFORM27. INLINEFORM28. INLINEFORM29. INLINEFORM30. INLINE", "answers": "48,705", "length": 6931}
{"pred": " The hybrid approach that combines the best performing popularity-based and the best similarity-based approach.  The best performing popularity-based approach was the one that used popular tags from e-books of a specific author, and the best performing similarity-based approach was the one that used the description text to find similar e-books.  This hybrid approach achieved the highest accuracy of 0.73.  The combination of the two vocabularies can provide a good trade-off between recommendation accuracy and diversity.  The hybrid approach also outperformed all of the initially evaluated popularity algorithms.  The combination of the two best performing similarity-based approaches did not yield better accuracy.", "answers": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "length": 6930}
{"pred": " The dissimilarity of all pairs of tags in the list of recommended tags is calculated as the average dissimilarity of all pairs of tags. The dissimilarity function is defined as the cosine similarity measure using the latent vector representations of respective tags. The number of evaluated e-books is used as the number of pairs of tags. The average dissimilarity of all pairs of tags is given as the recommendation diversity. The cosine similarity measure is used to calculate the similarity of two tags. The latent vector representations of respective tags are extracted from the previously trained Doc2Vec model. The similarity of two tags is then calculated with the Cosine similarity", "answers": " the average dissimilarity of all pairs of tags in the list of recommended tags", "length": 6928}
{"pred": " 30% of the Amazon search terms contain parts of the e-book titles. 497 e-books have both editor tags and Amazon search terms. 33,663 distinct review keywords and on average 30 keyword assignments per e-book. 48,705 e-books from 13 publishers. 21,243 e-books for 12 months. 2,896 e-books for evaluation. 19 different algorithms to recommend tags for e-books. 11 official languages of South Africa. 300+ character sentences per language. 3500 training samples and 600 testing samples per language. 18000 training samples and 1000 testing", "answers": "33,663", "length": 6929}
{"pred": " The dataset contains two sources of data, one to generate tag recommendations and another one to evaluate tag recommendations. HGV GmbH has collected all data sources and we provide the dataset statistics in Table TABREF3. Data used to generate recommendations. We employ two sources of e-book annotation data: (i) editor tags, and (ii) Amazon search terms. For editor tags, we collect data of 48,705 e-books from 13 publishers, namely Kunstmann, Delius-Klasnig, VUR, HJR, Diogenes, Campus, Kiwi, Beltz, Chbeck, Rowohlt, Droemer", "answers": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "length": 6928}
{"pred": " 19 different algorithms to recommend tags for e-books. They are grouped into (i) popularity-based, (ii) similarity-based (i.e., using content information), and (iii) hybrid approaches. Popularity-based approaches include the most popular tag approach for editor tags and Amazon search terms, and a round-robin combination strategy. Similarity-based approaches include a content-based filtering approach based on TF-IDF to find top-similar e-books, and a cross-source algorithm to combine the tags of the top-similar e-books. Hybrid approaches include a cross-source algorithm to construct four hybrid recommendation approaches. The algorithms are: (i)", "answers": "popularity-based, similarity-based, hybrid", "length": 6929}
{"pred": " You don’t need to do anything while you wait unless VA sends you a letter asking for more information. If VA schedules exams for you, be sure not to miss them. Track the status of your appeal.  You can also use the tool to check the status of a VA claim or appeal online.  You can use this tool to check the status of a VA claim or appeal for compensation. Track your: Disability compensation including claims based on special needs like an automobile or clothing allowance Veterans or Survivors Pension benefits Special monthly compensation such as Aid and Attendance Dependency and Indemnity Compensation DIC to help pay for a Veteran’s burial and", "answers": "We can help you find out what happens after you request a decision review Did the VA schedule an exam for you?", "length": 6787}
{"pred": " yes they did and you'll see where your claim or appeal is in our review process, and when we think we'll complete our review. You can also view these details: you've filed online Any evidence to support your initial claim we've requested from you Any additional evidence Your claim type What you've claimed Your representative for VA claims. Note: You can only upload documents online to support your initial claim. You can't upload documents online to support an appeal.  You won't see documents that: You sent to us by mail or fax, or You brought to us in person, or We've restricted to protect your or someone else's", "answers": "You can view the details that you filed online, including any evidence that supports your initial claim.", "length": 6789}
{"pred": " Yes, you can get answers to frequently asked questions about decision reviews at the following website: https://www.va.gov/decisionreviews/. You can also call us at 800-827-1000. We're here Monday through Friday, 8:00 a.m. to 9:00 p.m. ET.", "answers": "We have a page for frequently asked questions about decision reviews. I can give you the link", "length": 6803}
{"pred": " Yes. A Veterans Service Organization or VA-accredited attorney or agent can help you request a decision review. Get help requesting a decision review. Your representative, if you have one, may help you at the hearing. Your representative, if you have one, may help you at the hearing. The hearing will be transcribed and added to your appeal file. You can add new and relevant evidence within 90 days after the hearing, but it isn't required. Your representative, if you have one, may help you at the hearing. Your representative, if you have one, may help you at the hearing. The hearing will be transcribed", "answers": "Your representative ,  if you have one ,  may help you at the hearing .", "length": 6781}
{"pred": " No. You can't get assistance with the actual decision-making process. You can only get assistance with the process of requesting a decision review. If you have questions about the decision-making process, you should contact a Veterans Service Organization or a VA-accredited attorney or agent. They can provide you with guidance on how to navigate the process. However, they cannot assist you with the actual decision-making process. If you disagree with a Board decision, you can appeal to the U.S. Court of Appeals for Veterans Claims. You can hire an attorney to represent you, or you can represent yourself. Learn more about filing a Court Appeal. If you", "answers": "A Veterans Service Organization, or VA-accredited attorney or agent can help you request a decision review. I can send you to the page where you can get more information on this", "length": 6801}
{"pred": " Download VA Form 10182 PDF. By mail Send the completed form and any supporting documents to this address : Board of Veterans AppealsPO Box 27063Washington, D.C. 20038 In person Bring your completed form to a regional benefit office. Find a regional benefit office near you By fax Fax your completed form to 844 - 678 - 8979. You can also ask a regional benefit office for a copy of this form to fill out. Or you can call the VA toll - free hotline at 800 - 827 - 1000, Monday through Friday, 8:00 a.m. - 9", "answers": "You can ask a regional office for a copy of this form or you can call the VA toll-free hotline at 800-827-1000, Monday through Friday, 8:00 a.m. - 9:00 p.m. ET, to request a form. ", "length": 6791}
{"pred": " Direct Review.  If you want a Veterans Law Judge to review your case as quickly as possible, choose a Direct Review.  Evidence SubmissionIf you have additional evidence for a Veterans Law Judge to review, choose Evidence Submission. Hearing RequestIf you want a video conference hearing with a Veterans Law Judge at a nearby VA location, choose a Hearing Request. At your hearing, you and a Veterans Law Judge will have a conversation, and they ll ask you questions about your appeal. Your hearing will be transcribed and added to your appeal file. Learn more about hearings and how to request one  Direct Review is the fastest option.  Direct Review", "answers": "If you want a Veterans Law Judge to review your case as quickly as possible, choose a Direct Review.", "length": 6797}
{"pred": " Military sexual trauma (MST) refers to sexual assault or repeated, threatening sexual harassment that happened while a Veteran was in the military. This can happen to both women and men. If you were involved in any sexual act against your will during your time in the military, you may have experienced MST. Find out how to access our free services that can help you recover.  If you're a Veteran in crisis or concerned about one, connect with our caring, qualified Veterans Crisis Line responders for confidential help. Many of them are Veterans themselves. This service is private, free, and available 24/7. To connect with a Veterans Crisis", "answers": "Are you a veteran?", "length": 6978}
{"pred": " Yes. You can download our military sexual trauma brochure for Veterans: In English PDF En espa ol PDF. Download our educational brochure for men who've experienced MST: In English PDF En espa ol PDF. Watch a video about MST, its effects on survivors, and VA services available to Veterans who've experienced MST. Watch the video. Access more fact sheets, articles, and resources, and learn more about our programs and services. Get VA information about mental health. Go to our Make the Connection website to hear stories from Veterans about their own experiences with the effects of MST, and find more resources and support. Visit Make the Connection. Go to", "answers": "You can download our military sexual trauma brochure for Veterans : In English PDF ,or En espanol PDF", "length": 6983}
{"pred": " You can download our military sexual trauma brochure for Veterans: In English PDF En espa ol PDF. Download our educational brochure for men who ve experienced MST: In English PDF En espa ol PDF. Watch a video about MST, its effects on survivors, and VA services available to Veterans who ve experienced MST. Watch the video. Access more fact sheets, articles, and resources, and learn more about our programs and services. Get VA information about mental health. Go to our Make the Connection website to hear stories from Veterans about their own experiences with the effects of MST, and find more resources and support. Visit Make the Connection. Go to the Department", "answers": "You can download our military sexual trauma brochure for Veterans : In English PDF ,or En espanol PDF", "length": 6979}
{"pred": " We provide free, confidential private counseling and treatment to male and female Veterans for both mental and physical health problems linked to MST. Our services include: MST-related treatment and support at every VA medical center, and providers knowledgeable about treating the aftereffects of MST at each facility Specialized outpatient mental health services focused on sexual trauma at many VA locations Counseling with professionals who are specially trained to treat conditions related to sexual trauma at Vet Centers across the country Specialized MST treatment in a residential live-in or inpatient setting including gender-specific programs for Veterans who need more intensive care Treatment and support for health conditions linked to MST, like: Posttraumatic stress disorder", "answers": "you can remain anonymous. You can get 1-on-1 advice , support , and information 24/7 by phone , text , or online chat .You can also connect with a sexual assault response coordinator near your base or installation .", "length": 6990}
{"pred": " Call 1800 - 662-HELP 800 - 662 - 4357. Learn more about the helpline.  The Substance Abuse and Mental Health Services Administration SAMHSA offers free, confidential help with treatment referral and information services for individuals and families facing mental health and/or substance use disorders. Support is available 24/7, 365-days - a - year, in both English and Spanish. To reach SAMHSA s National Helpline : Call 1800 - 662-HELP 800 - 662 - 4357. Learn more about the helpline.  The Substance Abuse and Mental Health Services", "answers": "Yes, simply call 1800-662-HELP 800-662-4357.", "length": 6994}
{"pred": " Yes. If you don't qualify for VA health care, you may still be able to get certain health care services, like care for needs linked to military sexual trauma. Call our general VA hotline at 800 - 827 - 1000 to find out what your care options may be. We're here Monday through Friday, 8:00 a.m. to 9:00 p.m. ET. Depending on your needs and situation, you can also: Get free private counseling, alcohol and drug assessment, and other support for combat Veterans and families at one of our 300 community Vet Centers. Find a Vet Center near you", "answers": "you may be able to get MST - related care even if you don't qualify for other VA services . You also don't need to have reported the MST or have other proof that it happened .", "length": 6984}
{"pred": " Yes. You may be able to get disability compensation for conditions resulting from MST like PTSD the most common mental health condition linked to MST. Find out if you can get disability benefits for PTSD. Or get help applying for disability compensation by: Reading our fact sheet on disability compensation for conditions related to MST. Read the fact sheet PDF Talking to the MST coordinator at your nearest VA regional office. Find an MST coordinator near you. You can’t get compensation for the traumatic event itself. But you may be able to get disability compensation for conditions resulting from MST like PTSD the most common mental health condition linked to MST. Find out if you can get disability", "answers": "Not the traumatic event itself, but you may be able to get disability compensation for conditions resulting from MST like PTSD the most common mental health condition linked to MST.  We can help you find out if you can get disability benefits for PTSD", "length": 6975}
{"pred": " You can get help through VA. You don’t need to have a service-connected disability rating, and you may be able to get MST-related care even if you don’t qualify for other VA services. You also don’t need to have reported the MST or have other proof that it happened. Here’s how to access VA services for MST: If you have a VA primary care provider, talk to that professional about what you’ve been through. All our primary care providers are trained in MST and can help you figure out if you have related issues, like PTSD or depression. Your provider will offer treatment and support as needed. If you don’t", "answers": "If you have a VA primary care provider talk to that professional about what you have been through . Your provider will offer treatment and support as needed .", "length": 6976}
{"pred": " They achieved average recipe-level coherence scores of 1.78-1.82, surpassing the baseline at 1.77. They also achieved step entailment scores of 0.83-0.85, surpassing the baseline at 0.82. They also performed better in human evaluation, with 63% of users preferring personalized model outputs to baseline. They also performed better in human coherence survey, with 60% of users finding recipes generated by personalized models to be more coherent and preferable to those generated by baseline models. They also achieved better results on perplexity, with Prior Name performing the best. They also achieved", "answers": ["average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time"], "length": 6851}
{"pred": " A tweet went viral if it was retweeted more than 1000 times.  They consider that a straightforward way of sharing information on Twitter is by using the retweet functionality, which enables a user to share a exact copy of a tweet with his followers. Among the reasons for retweeting, Body et al. reported the will to: 1) spread tweets to a new audience, 2) to show one’s role as a listener, and 3) to agree with someone or validate the thoughts of others.  For our study, we consider that a tweet went viral if it was retweeted more than 1000", "answers": ["Viral tweets are the ones that are retweeted more than 1000 times", "those that contain a high number of retweets"], "length": 7165}
{"pred": " June 1, 1999.  Brooksley Born resigned as chairperson on June 1, 1999, shortly after Congress passed legislation prohibiting her agency from regulating derivatives.  In 1998, a trillion-dollar hedge fund called Long Term Capital Management (LTCM) was near collapse.  Using mathematical models to calculate debt risk, LTCM used derivatives to leverage $5 billion into more than $1 trillion, doing business with fifteen of Wall Street's largest financial institutions.  The derivative transactions were not regulated, nor were investors able to evaluate LTCM's exposures.  Born stated, \"I thought that LTCM", "answers": ["June 1, 1999."], "length": 7128}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 6950}
{"pred": " 65% of the speakers are men, speaking more than 75% of the time. 33.16% of the speakers are women, accounting for only 22.57% of the total speech time. 65% - 33.16% = 31.84% imbalance. 75% - 22.57% = 52.43% imbalance. 31.84% + 52.43% = 84.27% imbalance. 84.27% is 84.27/100 * 100% = 84.27%. 84.27% is 84.", "answers": ["Women represent 33.16% of the speakers"], "length": 6564}
{"pred": " The South West Ultras fan club.", "answers": ["South West Ultras fan club."], "length": 6174}
{"pred": " Statistical machine learning models.  They require a labeled dataset for model training.  Data labeling is a long, laborious, and usually costly process.  For the case of micropost classification, though positive labels can be collected, there is no straightforward way to generate negative labels useful for model training.  To tackle this lack of negative labels and the significant manual efforts in data labeling, a weak supervision based learning approach is introduced, which uses only positively labeled data, accompanied by unlabeled examples by filtering microposts that contain a certain keyword indicative of the event type under consideration.  Another key technique in this context is expectation regularization", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "length": 6631}
{"pred": " Romance novels and women's fiction.  She also wrote many novels through Mills & Boon, a romance imprint of British publisher Harlequin UK Ltd.  Many of her novels were set in Australia.  She also wrote many novels through Mills & Boon, a romance imprint of British publisher Harlequin UK Ltd.  Many of her novels were set in Australia.  She also wrote many novels through Mills & Boon, a romance imprint of British publisher Harlequin UK Ltd.  Many of her novels were set in Australia.  She also wrote many novels through Mills & Boon, a romance imprint of British publisher Har", "answers": ["Romance novels and women's fiction."], "length": 6377}
{"pred": " 1964.  It was published under the name James Ngugi.  It was among the African Writers Series.  It was the first English language novel to be published by an East African.  It was published while Ngũgĩ was a student at Makerere University.  The book is divided into two parts and eighteen chapters.  Part one deals mostly with the education of Njoroge, while part two deals with the rising Mau Mau movement.  Njoroge, a little boy, is urged to attend school by his mother.  He is the first one of his family able to go to", "answers": ["Weep Not, Child was first published in 1964."], "length": 7240}
{"pred": " No. The dataset of 1,000 randomly selected tweets contains more than twice as many tweets about Trump than about the other candidates. In the sentiment analysis experiments, we found that a tweet may contain multiple sentiments. The groundtruth labels contain 210 positive sentiments, 521 neutral sentiments, and 305 negative sentiments to the candidates.  The dataset is not balanced among classes.  The crowdworkers correctly identified 62% of the neutral, 85% of the positive, and 92% of the negative sentiments. Google Cloud correctly identified 88% of the neutral sentiments, but only 3% of the positive, and ", "answers": ["No"], "length": 7124}
{"pred": " The Sentence corpus (S) from BIBREF6 aristo2016:combining. This corpus is used by the IR solver and also used to create the tuple KB T and on-the-fly tuples $T^{\\prime }_{qa}$. Additionally, TableILP uses $\\sim $ 70 Curated tables (C) designed for 4th grade NY Regents exams. 80K sentences and 280 GB of plain text extracted from web pages.  The Sentence corpus (S) consists of domain-targeted.  We use the text corpora (S) from BIBREF6 aristo2016:comb", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 7242}
{"pred": " 61.4% vs TableILP's reported 61.5% on the latter's target Regents questions. 58.2% as compared to TableILP's ensemble score of 56.7% on the 4th grade set. 54.1% by itself. 61.4% vs TableILP's reported 61.5% on the latter's target Regents questions. 58.2% as compared to TableILP's ensemble score of 56.7% on the 4th grade set. 54.1% by itself. 58.2% as compared to", "answers": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "length": 7239}
{"pred": " No. The passage does not mention an entity linking process. It focuses on question answering and tuple inference. The passage does mention named entity recognition (NER) in the context of Passage 2, but it is not related to Passage 1. Passage 1 discusses tuple inference and question answering, and it does not involve entity linking. The passage does mention named entity recognition (NER) in the context of Passage 2, but it is not related to Passage 1. Passage 1 discusses tuple inference and question answering, and it does not involve entity linking. The passage does mention named entity recognition (NER) in the context of Passage", "answers": "No", "length": 7237}
{"pred": " No. They can have zero or more objects. They are referred to as (subject; predicate; objects). The objects can be one or more. The subject, predicate, and objects are the fields of the tuple. The objects can be zero or more. The subject, predicate, and objects are the fields of the tuple. The objects can be one or more. The subject, predicate, and objects are the fields of the tuple. The objects can be one or more. The subject, predicate, and objects are the fields of the tuple. The objects can be one or more. The subject, predicate, and objects are the fields", "answers": "No", "length": 7239}
{"pred": " Open IE v4.  The Open IE v4 was run on the top 200 hits from the ElasticSearch query.  The resulting tuples were then aggregated over all answer choices and all questions in the training set to create the tuple KB.  On-the-fly tuples were also generated using the same ElasticSearch query and Open IE v4.  The resulting tuples were then re-scored using the Jaccard score.  The top 50 scoring tuples were then selected.  The Jaccard score was used to re-score the tuples because Open IE is a lossy process and the Jaccard score helps to mitigate this loss", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 7242}
{"pred": " No. The current version of the method can only combine parallel evidence. However, it is possible to add inter-tuple connections to the support graph search, controlled by a small number of rules over the OpenIE predicates. Learning such rules for the Science domain is an open problem and potential avenue of future work.  The current version of the method can only combine parallel evidence. However, it is possible to add inter-tuple connections to the support graph search, controlled by a small number of rules over the OpenIE predicates. Learning such rules for the Science domain is an open problem and potential avenue of future work.  The current version of", "answers": "Yes", "length": 7238}
{"pred": " The text corpora (S) from BIBREF6 aristo2016:combining. For each test set, we use the corresponding training questions $Q_\\mathit {tr}$ to retrieve domain-relevant sentences from S. Specifically, for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$, we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S. We take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$", "answers": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "length": 7242}
{"pred": " Open IE v4.  The Open IE v4 was run on the top 200 hits.  The resulting tuples were aggregated over all answer choices and all questions in the training set.  The aggregated tuples were used to create the tuple KB.  The tuple KB was used to select the most relevant tuples for the question.  The most relevant tuples were selected based on their overlap with the question tokens.  The selected tuples were then scored using a normalized TF-IDF score.  The top-scoring tuples were used to create the support graph.  The support graph was used to answer the question.  The support graph was scored", "answers": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "length": 7242}
{"pred": " No. They only combine parallel evidence. However, they mention that adding inter-tuple connections to the support graph search, controlled by a small number of rules over the OpenIE predicates, could enable reliable multi-hop reasoning. But this is not implemented in their current method. They leave this as an open problem for future work.  They also mention that learning such rules for the Science domain is an open problem and potential avenue of future work.  They say that their current method only combines parallel evidence i.e. each tuple must connect words in the question to the answer choice.  They say that for reliable multi-hop reasoning using OpenIE tuples", "answers": "Yes", "length": 7239}
{"pred": " NLTK, Stanford CoreNLP, TwitterNLP, SentiStrength, TensiStrength, BIBREF17, BIBREF18, CogComp-NLP, spaCy, Stanford NLP NER.  BIBREF23, BIBREF19, BIBREF24, BIBREF25, BIBREF26.  BIBREF14, BIBREF15, BIBREF16.  BIBREF2, BIBREF22, BIBREF27.  BIBREF1, BIBREF3, BIBREF4, BIBREF5, BIBREF6", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "length": 5889}
{"pred": " The dynamical behavior of the anisotropic order parameter following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2) and the Binder cumulant g of the lowest transverse mode is zero in this regime. However, the alternative order parameter O distinguishes between the driven (IDLG, RDLG) and the equilibrium (LG) lattice gases. In the LG, the scaling form for O is not compatible with the prediction O ∼ t^(1/8) L_∥^(-1", "answers": ["It is well described by the Gaussian theory."], "length": 7123}
{"pred": " English.  English Wikipedia and Simple English Wikipedia are used in this paper.  The paper also mentions that the ordinary and simple English Wikipedias are used as benchmark for evaluating text simplification.  The paper also mentions that the ordinary and simple English Wikipedias are used as benchmark for evaluating text simplification.  The paper also mentions that the ordinary and simple English Wikipedias are used as benchmark for evaluating text simplification.  The paper also mentions that the ordinary and simple English Wikipedias are used as benchmark for evaluating text simplification.  The paper also mentions that the ordinary and simple English Wikipedias are used as", "answers": ["English", "Simple English"], "length": 6318}
{"pred": " By employing a propagator in the latent space to capture the reduced-order dynamics of the system. In contrast to other time-extended variational autoencoder frameworks, our representation uses complex-valued latent variables. In addition, the latent variables are treated independently, enabling an interpretable latent dynamics as well as a model that is especially suitable for being trained in the Small Data regime due to the small number of required parameters. This is in contrast to temporal propagators such as LSTMs. For each dimension i of the latent variable z, we are using the following continuous ODE in the complex plane: dz/dt = λz. By", "answers": ["By using a propagator in the latent space."], "length": 6626}
{"pred": " RNN-based NMT model and Transformer-NMT model.  SMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model.  RNN-based NMT model and Transformer based NMT model", "answers": ["RNN-based NMT model, Transformer-NMT"], "length": 7017}
{"pred": " The dynamical behavior of the anisotropic order parameter m is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2) and the Binder cumulant g of the lowest transverse mode is zero in this regime. However, the alternative order parameter O distinguishes between the driven and the equilibrium lattice gases. The generic behavior of O can be assumed to be O ∼ t^α L_∥^(-1/2), where α is a phenomenological exponent to be determined. This implies that the prediction O ∼ t^(1/", "answers": ["It is well described by the Gaussian theory."], "length": 7123}
{"pred": " DTA18 and DTA19. They consist of subparts of DTA corpus BIBREF11 which is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century. DTA18 contains 26 million sentences published between 1750-1799 and DTA19 40 million between 1850-1899. The corpus version used in the task has the following format: \"year [tab] lemma1 lemma2 lemma3...\".  DTA18 and DTA19. They consist of subparts", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "length": 6915}
{"pred": " 4 years.  From 1946 to 1952.  There were few radios equipped to receive FM signals in that era, and management decided to discontinue FM broadcasts.  KSTP-FM 102.1 was only on the air four years.  There were few radios equipped to receive FM signals in that era, and management decided to discontinue FM broadcasts.  From 1946 to 1952.  There were few radios equipped to receive FM signals in that era, and management decided to discontinue FM broadcasts.  From 1946 to 1952.  There were few radios equipped to", "answers": ["Four years."], "length": 6810}
{"pred": " Sumy package.  ILP-based summarization.  ROUGE.  TextRank.  LexRank.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis.  Latent Dirichlet Allocation.  Latent Semantic Analysis. ", "answers": ["LSA, TextRank, LexRank and ILP-based summary.", "LSA, TextRank, LexRank"], "length": 6918}
{"pred": " O (t, L_{\\parallel} ; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O (t/L_{\\parallel}^{z/(1+\\Delta)} ; S_\\Delta).  \\quad \\label{eq:Oscalingass}  \\end{eqnarray}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{document}  \\end{", "answers": ["O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta)."], "length": 7511}
{"pred": " 1964.  (under the name James Ngugi)  (under the name James Ngugi) 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 1964. 196", "answers": ["Weep Not, Child was first published in 1964."], "length": 7087}
{"pred": " No. We ll ask you to have a claim exam only if we need more information to decide your claim. If you have enough medical evidence in your file to support your claim, we won t ask you to have a claim exam. Medical evidence may include doctor and hospital reports, test results, and other documents.  If you have enough medical evidence in your file to support your claim, we won t ask you to have a claim exam. Medical evidence may include doctor and hospital reports, test results, and other documents.  No. We ll ask you to have a claim exam only if we need more information to decide your claim.", "answers": "No. We ll ask you to have a claim exam only if we need more information to decide your claim . Do you have enough medical evidence to support your claim?", "length": 6600}
{"pred": " Yes. To get a copy of the final report from your exam, you can : Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "we won t ask you to have a claim exam . Medical evidence may include doctor and hospital reports , test results , and other documents .", "length": 6591}
{"pred": " You may be able to get disability benefits if you meet both of the requirements listed below. Both of these must be true: You were part of Projects 112 or SHAD testing from 1962 to 1974, and You have an illness believed to be caused by the testing. If you were a part of chemical and biological warfare testing through Project 112 or Project Shipboard Hazard and Defense SHAD, you may be at risk for certain illnesses. The Department of Defense's Deseret Test Center in Fort Douglas, Utah, conducted this testing, which took place aboard ships and on land in various locations from 1962 to", "answers": "If you were part of Projects 112 or SHAD from 1962 to 1974 and want to know more about a certain test site, ship, or unit, you can view the declassified Department of Defense fact sheets.  We can give you a link to the declassified Department of Defense fact sheets", "length": 6617}
{"pred": " We ll review all the evidence in your file, assign your disability rating, and send you a decision notice a letter letting you know your disability rating. Each claim is different, but it usually takes us about 3 to 4 months to process a claim from start to finish. The processing time for your claim depends on how complex your claim is and how many conditions you ve claimed. See our most recent estimate for the average number of days to complete a claim Sign in to track your claim Yes. To get a copy of the final report from your exam, you can : Contact your nearest VA regional benefit office, or Call us at ", "answers": "We ll review all the evidence in your file , assign your disability rating , and send you a decision notice a letter letting you know your disability rating .", "length": 6614}
{"pred": " Yes. Disability housing grants for Veterans, Fiduciary services, VA nursing homes, assisted living, and home health care, Vocational Rehabilitation and Employment, Aid and Attendance benefits and Housebound allowance, Exposure through Project 112 or Project SHAD.", "answers": "There is Aid and Attendance benefits and Housebound allowance. You can find out if you're eligible for extra monthly pension payments if you need more aid than you're currently receiving .", "length": 6611}
{"pred": " Contact your nearest VA regional benefit office, or Call us at 800 - 827 - 1000 and request an appointment to view your file.", "answers": "you can : Contact your nearest VA regional benefit office ,or\nCall us at 800 - 827 - 1000 and request an appointment to view your file", "length": 6613}
{"pred": " VA claim exam fact sheet, VA claim exam tips, VA claim exam FAQs, Step-by-step VA claim process, Mental health exam fact sheet, Review exams fact sheet, VA claim exams video series.  VA disability compensation, VA disability ratings, VA claim exam, VA nursing homes, assisted living, and home health care, Vocational Rehabilitation and Employment, Aid and Attendance benefits and Housebound allowance, Exposure through Project 112 or Project SHAD.  You can also watch our VA claim exams video series. This series offers videos on how to prepare for your VA claim exam, how to use disability benefits questionnaires DBQs, and", "answers": "How VA assigns disability ratingsLearn how we assign severity ratings and how they affect your disability payments ", "length": 6591}
{"pred": " The staff at your local VA medical center or a local doctor's office that we partner with will contact you. They'll either send you a letter by mail with the date and time of your exam, or call you to find a time that works for you. Make sure both the VA regional office and the VA medical center nearest you have your up-to-date address, phone number, and email address so you get your exam notice in time. Call the number provided right away to confirm the time and location of your exam. It's important not to miss your scheduled exam, so you'll want to double check that you have the right place and", "answers": " Call the number provided right away to confirm the time and location of your exam . It s important not to miss your scheduled exam , so you ll want to double check that you have the right place and time ", "length": 6595}
{"pred": " 1964.  under the name James Ngugi.  It was among the African Writers Series.  It was the first English language|English novel to be published by an East African.  Thiong'o's works deal with the relationship between Africans and white settlers in colonial Kenya, and are heavily critical of colonial rule.  Specifically, Weep Not, Child deals with the Mau Mau Uprising, and \"the bewildering dispossession of an entire people from their ancestral land.\" Ngũgĩ wrote the novel while he was a student at Makerere University.  The book is divided into two parts and eighteen", "answers": ["Weep Not, Child was first published in 1964."], "length": 7320}
{"pred": " Yes, most federal student loans are eligible for at least one income-driven repayment plan. If your income is low enough, your payment could be as low as $0 per month. An income-driven repayment plan sets your monthly student loan payment at an amount that is intended to be affordable based on your income and family size. We offer four income-driven repayment plans: Revised Pay As You Earn Repayment Plan (REPAYE) Plan, Pay As You Earn Repayment Plan (PAYE) Plan, Income-Based Repayment Plan (IBR) Plan, and Income-Contingent Repayment Plan (ICR) Plan. If you", "answers": "You might be able to repayment it under an income-driven repayment plan but it depends on what type of loan you have. Do you have a FFEL Program Loan or a Federal Perkins Loan?", "length": 6743}
{"pred": " You may only be eligible for the IBR Plan. However, if you consolidate your FFEL Program loans into a Direct Consolidation Loan, you'll then have access to the REPAYE, PAYE, and ICR plans. Find out more about loan consolidation.", "answers": "You might be able to get a Direct Consolidation Loan and then you could repay under the REPAYE plan.", "length": 6728}
{"pred": " No. The passage does not mention tribal government as a qualifying employer for the Public Service Loan Forgiveness Program. However, it does mention that employment with a U.S. federal, state, local, or tribal government qualifies for PSLF. Therefore, it is likely that tribal government employment would qualify, but it is not explicitly stated in the passage. However, it is worth noting that the passage does not provide a comprehensive list of qualifying employers, and it is possible that tribal government employment may be considered qualifying employment under certain circumstances. It is recommended to contact the loan servicer or the U.S. Department of Education for further clarification.", "answers": "You may be eligible for the Public Service Loan Forgiveness Program. Read on to see if you can qualify.", "length": 6747}
{"pred": " You must submit an application called the Income-Driven Repayment Plan Request. You can submit the application online or on a paper form, which you can get from your loan servicer. The application allows you to select an income-driven repayment plan by name, or to request that your loan servicer determine what income-driven plan or plans you qualify for, and to place you on the income-driven plan with the lowest monthly payment amount. Note: If you have more than one servicer for the loans that you want to repay under an income-driven plan, you must submit a separate request to each servicer. When you apply, you’ll be", "answers": "To apply for an Income-Driven Repayment Plan you will have to complete the paper application and provide a paper copy of your most recently filed federal income tax return or IRS tax return transcript.", "length": 6742}
{"pred": " Borrowers currently on an IDR Plan who need to re-certify or make changes to their repayment plan. Borrowers not currently on an IDR Plan who are seeking a lower monthly payment on their federal student loans.", "answers": "Borrowers currently on an IDR Plan who need to recertify or make changes to their repayment plan.", "length": 6747}
{"pred": " Your payment is always based on your income and family size, regardless of any changes in your income. This means that if your income increases over time, in some cases your payment may be higher than the amount you would have to pay under the 10-year Standard Repayment Plan. Under the REPAYE and ICR Plans, your payment is always based on your income and family size, regardless of any changes in your income. This means that if your income increases over time, in some cases your payment may be higher than the amount you would have to pay under the 10-year Standard Repayment Plan. Under the REPAYE and", "answers": "Your payment is always based on your income and family size, regardless of any changes in your income.", "length": 6757}
{"pred": " Yes. Browse our Income-Driven Plans Questions and Answers page.", "answers": "You can browse our Income-Driven Plans question and answers page for more information.", "length": 6735}
{"pred": " Browse our Income-Driven Plans Questions and Answers page.", "answers": "On our website.", "length": 6731}
{"pred": " Environmental fluctuation and uncertainty.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity. Interestingly, the form of the emerging plasticity rule is additionally determined by the details of the task the artificial organisms are aiming to solve.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.  Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity", "answers": ["Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity."], "length": 6408}
{"pred": " Kannada, Hindi, Telugu, Malayalam, Bengali, and English.  (Note: The passage actually says 7 Indian languages, but only 6 languages are listed. The 7th language is not explicitly mentioned, but it can be inferred that it is likely to be another Indian language, possibly Marathi or Tamil, given the context of the passage.)  However, based on the information given in the passage, the answer is 6 languages.  If you want to consider the 7th language, you would need to make an educated guess.  I will provide the answer based on the information given in", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "length": 6714}
{"pred": " They split the context into three disjoint regions based on the two relation arguments: the left context, the middle context and the right context. They then use two contexts: (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. Due to the repetition of the middle context, they force the network to pay special attention to it. The two contexts are processed by two independent convolutional and max-pooling layers. After pooling, the results are concatenated to form the sentence representation.  They call this new context representation as", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "length": 7121}
{"pred": " 2013–2014.  The club won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in", "answers": ["In the 2013-2014 season."], "length": 7011}
{"pred": " Romance novels and women's fiction.  She was a prolific author, writing more than 120 novels since 1970, many through Mills & Boon, a romance imprint of British publisher Harlequin UK Ltd.  She began writing when her son, Laurence Way, was born, a friend took a pile of Mills & Boon books to her, she read all and decided that she also could write these types of novels.  She began to write and promote her country with her stories set in Australia.  She sold her first novels in 1970.  Margaret Way lives with her family in her native Brisbane. ", "answers": ["Romance novels and women's fiction."], "length": 5603}
{"pred": " Yes.  They use Lucene to index the paragraphs of Wikipedia and then query the answer sentences to retrieve the top-5 ranked paragraphs.  They then measure the cosine similarity between each sentence in these paragraphs and the answer sentence.  They assign a weight to each n-gram score and measure the weighted sum.  If there exists a sentence whose n-gram score is greater than a certain threshold, the paragraph consisting of that sentence is considered the silver-standard answer passage.  They repeat this process for each question in the dataset to create a sample of a QA Wikipedia dataset.  They call this dataset the silver-standard dataset.  They", "answers": ["Yes", "No"], "length": 7133}
{"pred": " FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants.  FC Banants", "answers": ["FC Banants."], "length": 6520}
{"pred": " The dynamical behavior of the anisotropic order parameter following a quench to the critical point is well described by the Gaussian theory for all the three lattice gas models studied. In the short-time regime, m ∼ t^(1/2) and the Binder cumulant g of the lowest transverse mode is zero in this regime. However, the alternative order parameter O distinguishes between the driven and the equilibrium lattice gases. In the short times, the only dependence of O on the system size L_∥ is of the form O ∼ L_∥^(-1/2). The generic behavior of O can be", "answers": ["It is well described by the Gaussian theory."], "length": 7178}
{"pred": " They conducted a survey among engineers and analyzed the NLP jobs submitted to a commercial centralized GPU cluster. Table TABREF11 showed that about 87.5% NLP related jobs belong to a few common tasks, including sentence classification, text matching, sequence labeling, MRC, etc. It further suggested that more than 90% of the networks were composed of several common components, such as embedding, CNN/RNN, Transformer and so on.  The authors also mentioned that general-purpose deep learning frameworks, such as TensorFlow, PyTorch and Keras, offer huge flexibility in DNN model design and support various NLP tasks,", "answers": ["By conducting a survey among engineers", "Unanswerable"], "length": 7109}
{"pred": " 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2-5 times smaller. 2", "answers": ["Infall rate is 2-5 times smaller and gas density is 2-5 times smaller."], "length": 7287}
{"pred": " V +, V 0, V −.  (V +, V 0, V − )  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0, V −.  V +, V 0", "answers": ["The three subsets are V+, V0, and V-, determined by the Kullback-Leibler information distance."], "length": 6987}
{"pred": " Fuller's Ranch.  It was established by Charles O. Fuller in 1855.  It provided accommodations for travelers on the Santa Fe Trail.  It was located adjacent to the Running Turkey Creek Crossing about two miles south and one mile east of Galva.  It was probably the first white settlement in McPherson County.  Fuller's Ranch was established in 1855.  It was located in what is now McPherson County.  It was established by Charles O. Fuller.  It was a ranch.  It was located adjacent to the Running Turkey Creek Crossing.  It was located about two miles south and", "answers": ["The first white settlement in McPherson County was Fuller's Ranch, established by Charles O. Fuller."], "length": 6552}
{"pred": " The belief update time on Map 2 and Map 3, containing more obstacles, is reduced compared to the first map.  More obstacles result in fewer iterations when solving the constrained shortest path problem with A. Adding constraints due to the obstacles and polytopes reduces the size of the A search tree.  The complexity of the Bayesian update should not increase with the number of obstacles or polytopes.  The time required to update the robot's belief does not increase with the complexity of the environment.  The belief update time on Map 2 and Map 3, containing more obstacles, is reduced compared to the first map. ", "answers": ["The belief entropy decreases more steadily."], "length": 7007}
{"pred": " 1964.  It was published under the name James Ngugi.  It was published in the African Writers Series.  It was the first English language novel to be published by an East African.  It was published in 1964.  It was published under the name James Ngugi.  It was published in the African Writers Series.  It was the first English language novel to be published by an East African.  It was published in 1964.  It was published under the name James Ngugi.  It was published in the African Writers Series.  It was the first English language novel to be published", "answers": ["Weep Not, Child was first published in 1964."], "length": 7124}
{"pred": " Our model.  Our model achieves new state-of-the-art results on MSR and AS, and comparable results on PKU and CITYU.  Our model is compared to recent models in terms of closed test setting.  Our model is compared to recent models in terms of open test setting.  Our model is compared to recent LSTM models.  Our model is compared to recent neural models.  Our model is compared to recent models in terms of decoding time.  Our model is compared to recent models in terms of performance.  Our model is compared to recent models in terms of F-score.  Our model is compared to recent models in", "answers": ["Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019"], "length": 7141}
{"pred": " word2vec.  BIBREF10.  BIBREF11.  BIBREF12.  BIBREF14.  BIBREF15.  BIBREF16.  BIBREF17.  BIBREF18.  BIBREF1.  BIBREF2.  BIBREF3.  BIBREF4.  BIBREF5.  BIBREF6.  BIBREF7.  BIBREF8.  BIBREF9.  BIBREF10.  BIBREF11.  BIBREF12.  BIBREF", "answers": "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach", "length": 6920}
{"pred": " The Twitter dataset is formed of tweets about Turkish mobile network operators. Those tweets are mostly much noisier and shorter compared to the reviews in the movie corpus. In total, there are 1,716 tweets. 973 of them are negative and 743 of them are positive. These tweets are manually annotated by two humans, where the labels are either positive or negative. We measured the Cohen's Kappa inter-annotator agreement score to be 0.82. If there was a disagreement on the polarity of a tweet, we removed it.  We also utilised two other datasets in English to test the cross-linguality", "answers": "one of the Twitter datasets is about Turkish mobile network operators, there are positive, neutral and negative labels and provide the total amount plus the distribution of labels", "length": 6923}
{"pred": " The dataset contains 20,244 movie reviews, with an average of 39 words per review. The reviews have star-rating scores between 0.5 and 5, with 7,020 negative and 7,020 positive reviews selected for processing. The dataset is collected from a popular website. The reviews are mostly complete or nearly complete, making accuracy a suitable metric for evaluation. The dataset is used to evaluate the performance of the proposed approaches. The Cohen's Kappa inter-annotator agreement score is 0.82, indicating high agreement between the annotators. The dataset is used to test the cross-linguality of", "answers": "there are 20,244 reviews divided into positive and negative with an average 39 words per review, each one having a star-rating score", "length": 6924}
{"pred": " Minimum, mean, and maximum polarity scores. Three hand-crafted polarity scores. Three supervised scores. Three features. Three hand-crafted features. Three scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are minimum, mean, and maximum polarity scores. Three hand-crafted features are", "answers": "polarity scores, which are minimum, mean, and maximum polarity scores, from each review", "length": 6926}
{"pred": " 4-scores and supervised polarity score. 3-feats.  TDK dictionary.  SentiWordNet lexicon.  Positive pointwise mutual information (PPMI) scores.  Singular value decomposition (SVD).  Fuzzy c-means clustering algorithm.  Principal component analysis (PCA).  Corpus-based and dictionary-based vector components.  Positive and negative words.  Emoticons.  Idioms.  Morphological parser and disambiguator tools.  Negation handling.  Stop-word elimination.  Zemberek tool.  Word2vec embeddings.  Gensim library.  Lib", "answers": "generate word embeddings specific to a domain, TDK (Türk Dil Kurumu - “Turkish Language Institution”) dictionary to obtain word polarities", "length": 6924}
{"pred": " $w_{t}$ denotes the sentiment score of word $t$, $N_{t}$ is the number of documents (reviews or tweets) in which $t$ occurs in the dataset of positive polarity, $N$ is the number of all the words in the corpus of positive polarity. $N^{\\prime }$ denotes the corpus of negative polarity. $N^{\\prime }_{t}$ and $N^{\\prime }$ denote similar values for the negative polarity corpus. We perform normalisation to prevent the imbalance problem and add a small number to both numerator and denominator for smoothing.  $w_{t} =", "answers": "(+1 or -1), words of opposite polarities (e.g. “happy\" and “unhappy\") get far away from each other", "length": 6924}
{"pred": " 85.61%. 58.54% for Track-1. 85.61% for Track-2. 58.54% for Track-1. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85.61% for Track-2. 85", "answers": ["85.61%."], "length": 7048}
{"pred": " small BERT.  BERT$_\\mathrm {BASE}$ model.  BERT$_\\mathrm {BASE}$ model for fine-tuning, because we find that BERT$_\\mathrm {LARGE}$ model performs slightly worse than BERT$_\\mathrm {BASE}$ in this task.  BERT$_\\mathrm {BASE}$ model for fine-tuning, because we find that BERT$_\\mathrm {LARGE}$ model performs slightly worse than BERT$_\\mathrm {BASE}$ in this task.  BERT$_\\mathrm {BASE}$ model for fine-tuning, because we find that BERT$_\\", "answers": ["small BERT", "small BERT"], "length": 6169}
{"pred": " Personal attack, racism, and sexism.  Also, they experimented with Formspring dataset which is not specifically about any single topic.  They also experimented with Twitter dataset which contains examples of racism and sexism.  They also experimented with Wikipedia dataset which contains examples of personal attack.  They also experimented with Formspring dataset which is not specifically about any single topic.  They also experimented with Twitter dataset which contains examples of racism and sexism.  They also experimented with Wikipedia dataset which contains examples of personal attack.  They also experimented with Formspring dataset which is not specifically about any single topic.  They also experimented with Twitter dataset which contains examples", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "length": 6460}
{"pred": " Yes.  Often the outputs of BioIE systems are used to assist in the creation of databases, or to suggest new paths for research. For example, a ranked list of interacting proteins that are extracted from biomedical literature, but are not present in existing databases, can allow researchers to make informed decisions about which protein/gene to study further. Interactions between drugs are necessary for clinicians who simultaneously administer multiple drugs to their patients. A database of diseases, treatments and tests is beneficial for doctors consulting in complicated medical cases.  A database of diseases, treatments and tests is beneficial for doctors consulting in complicated medical cases.  A database of diseases,", "answers": ["Yes"], "length": 6631}
{"pred": " FCM, SCM, and TKM.  They are CNN+RNN models with three inputs: the tweet image, the tweet text and the text appearing in the image (if any).  FCM is a Feature Concatenation Model, SCM is a Spatial Concatenation Model, and TKM is a Textual Kernels Model.  The TKM design aims to capture interactions between the two modalities more expressively than concatenation models.  The FCM architecture is illustrated in Fig. FIGREF26.  The SCM architecture is illustrated in Fig. FIGREF28.  The TKM architecture is illustrated in Fig", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6872}
{"pred": " No.", "answers": "Unanswerable", "length": 6872}
{"pred": " 150,000. 112,845 not hate tweets and 36,978 hate tweets. 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets. 5,000 for validation and 10,000 for test.  The remaining tweets are used for training.  The dataset is the biggest hate speech dataset to date, and the first multimodal hate speech dataset.  The dataset is called MMHS150K.  The dataset is formed by $150,000$ tweets, each one of them containing text and an image", "answers": " $150,000$ tweets", "length": 6872}
{"pred": " The proposed multimodal models do not outperform the textual models.  The proposed multimodal models, such as TKM, have shown good performance in other tasks, such as VQA. Next, we analyze why they do not perform well in this task and with this data: Noisy data. A major challenge of this task is the discrepancy between annotations due to subjective judgement. Although this affects also detection using only text, its repercussion is bigger in more complex tasks, such as detection using images or multimodal detection. Complexity and diversity of multimodal relations. Hate speech multimodal publications employ a lot of background knowledge which makes the relations", "answers": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "length": 6880}
{"pred": " Noisy data, complexity and diversity of multimodal relations, and small set of multimodal examples.  The dataset is also too small to learn the complex multimodal relations needed to identify multimodal hate.  The model trained only with images proves that they are useful for hate speech detection, the proposed multimodal models are not able to improve the detection compared to the textual models.  Besides the different architectures, we have tried different training strategies, such as initializing the CNN weights with a model already trained solely with MMHS150K images or using dropout to force the multimodal models to use the visual information.  Eventually, though, these", "answers": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "length": 6885}
{"pred": " F-score, the Area Under the ROC Curve (AUC) and the mean accuracy (ACC).  The Precision vs Recall plot and the ROC curve are also used.  The metrics are used to evaluate the performance of the proposed models when different inputs are available.  The metrics are used to compare the performance of the proposed models with the LSTM, the Davison method, and random scores.  The metrics are used to evaluate the performance of the proposed models when different inputs are available.  The metrics are used to compare the performance of the proposed models with the LSTM, the Davison method, and random scores.  The metrics are", "answers": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "length": 6875}
{"pred": " Twitter API.  The Twitter API was used to gather real-time tweets from September 2018 until February 2019.  The tweets were selected based on the presence of certain hate speech terms.  The tweets were then filtered to remove retweets, tweets with less than three words, and tweets with porn-related terms.  The remaining tweets were then downloaded.  The dataset was created by gathering tweets from real-time posting, so the content had not yet passed any filter.  The tweets were then manually annotated using the crowdsourcing platform Amazon Mechanical Turk.  The annotators were given the definition of hate speech and examples to make the", "answers": "Twitter API", "length": 6877}
{"pred": " 150,000. 112,845 not hate tweets and 36,978 hate tweets.  The latest are divided in 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets.  The remaining tweets are used for training.  The dataset is divided into training, validation and test sets.  The validation set contains 5,000 tweets and the test set contains 10,000 tweets.  The remaining tweets are used for training.  The dataset is the biggest hate speech dataset to date, and the first multimodal hate", "answers": "$150,000$ tweets", "length": 6881}
{"pred": " LSTM.  The LSTM to detect hate speech when only text is available, gets similar results as the method presented in BIBREF7, which we trained with MMHS150K and the same splits. However, more than substantially advancing the state of the art on hate speech detection in textual publications, our key purpose in this work is to introduce and work on its detection on multimodal publications. We use LSTM because it provides a strong representation of the tweet texts.  The proposed LSTM to detect hate speech when only text is available, gets similar results as the method presented in BIBREF7, which we trained with MMHS150K", "answers": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "length": 6875}
{"pred": " FCM, SCM, and TKM.  The FCM is a Feature Concatenation Model, the SCM is a Spatial Concatenation Model, and the TKM is a Textual Kernels Model.  The TKM design aims to capture interactions between the two modalities more expressively than concatenation models.  The FCM architecture is illustrated in Fig. FIGREF26, the SCM architecture is illustrated in Fig. FIGREF27, and the TKM architecture is illustrated in Fig. FIGREF29.  The TKM uses the $8\\times 8\\times 2048$ feature map after the last", "answers": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "length": 6876}
{"pred": " 6 categories: No attacks to any community, racist, sexist, homophobic, religion based attacks or attacks to other communities. 112,845 not hate tweets and 36,978 hate tweets.  The hate tweets are divided in 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets.  The latest are divided in 11,925 racist, 3,495 sexist, 3,870 homophobic, 163 religion-based hate and 5,811 other hate tweets.  The hate / not hate split is used in this", "answers": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "length": 6883}
{"pred": " The Post-9/11 GI Bill Chapter 33 helps you pay for school or job training. If you ve served on active duty after September 10, 2001, you may qualify for the Post-9/11 GI Bill Chapter 33. Find out if you can get this education benefit.  You can receive up to 36 months of benefits, including : Tuition and fees. If you qualify for the maximum benefit, we ll cover the full cost of public, in - state tuition and fees. We cap the rates for private and foreign schools, and update those rates each year. View current rates Money for housing", "answers": "The GI Bill Post-9/11 helps you pay for school or job training. have you served the active army after September 10, 2001?", "length": 6132}
{"pred": " At least one of these must be true. You: Served at least 90 days on active duty either all at once or with breaks in service on or after September 11, 2001, or Received a Purple Heart on or after September 11, 2001, and were honorably discharged after any amount of service, or Served for at least 30 continuous days all at once, without a break in service on or after September 11, 2001, and were honorably discharged with a service-connected disability, or Are a dependent child using benefits transferred by a qualifying Veteran or service member.  Note:", "answers": "one of the primary requirements is to have served at least 90 days on active duty, all at once or with interruptions in service as of September 11, 2001,", "length": 6151}
{"pred": " Yes, you can get these education benefits if you meet at least one of the requirements listed below. At least one of these must be true. You: Served at least 90 days on active duty either all at once or with breaks in service on or after September 11, 2001, or Received a Purple Heart on or after September 11, 2001, and were honorably discharged after any amount of service, or Served for at least 30 continuous days all at once, without a break in service on or after September 11, 2001, and were honorably discharged with a service - connected", "answers": "Did you receive a Purple Heart on or after September 11, 2001?", "length": 6140}
{"pred": " No, I have not received a Purple Heart.  At least one of these must be true. You: Served at least 90 days on active duty either all at once or with breaks in service on or after September 11, 2001, or Received a Purple Heart on or after September 11, 2001, and were honorably discharged after any amount of service, or Served for at least 30 continuous days all at once, without a break in service on or after September 11, 2001, and were honorably discharged with a service-connected disability, or Are a dependent child using benefits transferred", "answers": "have you served for at least 30 continuous days at a time, without a break in service as of September 11, 2001?", "length": 6131}
{"pred": " True. You: Served for at least 30 continuous days all at once, without a break in service on or after September 11, 2001, and were honorably discharged with a service-connected disability, or Are a dependent child using benefits transferred by a qualifying Veteran or service member.  Note: If you re a member of the Reserves who lost education benefits when the Reserve Educational Assistance Program REAP ended in November 2015, you may qualify to receive restored benefits under the Post-9/11 GI Bill.  You ll have to pick which benefit you d like to use. This is an irrevoc", "answers": "Are you a dependent child using the benefits transferred by a veteran or qualified service member?", "length": 6137}
{"pred": " True. You: Served at least 90 days on active duty either all at once or with breaks in service on or after September 11, 2001, or Received a Purple Heart on or after September 11, 2001, and were honorably discharged after any amount of service, or Served for at least 30 continuous days all at once, without a break in service on or after September 11, 2001, and were honorably discharged with a service - connected disability, or Are a dependent child using benefits transferred by a qualifying Veteran or service member Note: If you re a member of the Res", "answers": "Based on the information provided by you, I inform you that you are not eligible for benefits.", "length": 6142}
{"pred": " You can check your GI Bill Statement of Benefits. View your GI Bill Statement of Benefits. If you already applied for and were awarded Post-9/11 GI Bill education benefits, your GI Bill Statement of Benefits will show you how much of your benefits you’ve used and how much you have left to use. View your GI Bill Statement of Benefits. If you already applied for and were awarded Post-9/11 GI Bill education benefits, your GI Bill Statement of Benefits will show you how much of your benefits you’ve used and how much you have left to use. View your GI Bill Statement of Benefits. View your GI Bill Statement of", "answers": "Before you enroll you need to contact the school or use the GI Bill Comparison Tool to find out if we have approved your program for VA educational benefits ", "length": 6143}
{"pred": " You usually have 10 years to use your MGIB-AD benefits. This may change depending on your situation. You may get up to 36 months of education benefits. We ll pay the benefits monthly. The amount you ll receive depends on these factors : Your length of service, and The type of educational or training program you choose, and Your category as defined above, and Whether you qualify for a college fund or kicker, and How much you ve paid into the $600 Buy - Up program Learn more about the $600 Buy - Up program. You may get help paying for : Remedial courses classes some students must take to build", "answers": "I can help you learn that too. You may be able to get financial help.", "length": 6139}
{"pred": " Second (EI-Reg, EI-Oc), fourth (V-Reg) and fifth (V-Oc) on the SemEval AIT-2018 leaderboard. However, it is evident that the results obtained on the test set are not always in line with those achieved on the development set. Especially on the anger subtask for both EI-Reg and EI-Oc, the scores are considerably lower on the test set in comparison with the results on the development set. Therefore, a small error analysis was performed on the instances where our final model made the largest errors.", "answers": ["column Ens Test in Table TABREF19"], "length": 7051}
{"pred": " 2013–2014.  The club won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in their history.  In 2013–2014, they won the Armenian Premier League for the first time in", "answers": ["In the 2013-2014 season."], "length": 6990}
{"pred": " The baseline assigns a semantic role to a constituent based on its syntactic function, i.e. the dependency relation to its head. If there is a total of INLINEFORM0 clusters, INLINEFORM1 most frequent syntactic functions get a cluster each, and the rest are assigned to the INLINEFORM2 th cluster.  This baseline is the same as used by lang2011unsupervised which has been shown to be difficult to outperform.  The baseline model is used for comparison with the proposed model.  The baseline model is used for comparison with the proposed model.  The baseline model is used for comparison with the proposed model.", "answers": "same baseline as used by lang2011unsupervised", "length": 7260}
{"pred": " Crosslingual latent variables.  CLVs.  Chinese Restaurant Process.  CLVs are a multi-valued variable where each value defines a distribution over role labels for each language.  CLVs are used to capture crosslingual semantic role patterns.  CLVs are used to capture correlations between roles in different languages.  CLVs are used to regularize the parameter estimates of the monolingual models.  CLVs are used to capture the improvement in the parameter estimates for the target language.  CLVs are used to capture the cross-lingual patterns at least as well as the external penalty term.  CLVs are", "answers": "CLV as a parent of the two corresponding role variables", "length": 7264}
{"pred": " Crosslingual latent variables.  CLVs.  Chinese Restaurant Process.  CLVs are a multi-valued variable where each value defines a distribution over role labels for each language.  CLVs are used to capture crosslingual semantic role patterns.  CLVs are used to capture correlations between roles in different languages.  CLVs are used to regularize the parameter estimates of the monolingual models.  CLVs are used to capture the improvement in the parameter estimates for the target language.  CLVs are used to capture the cross-lingual patterns at least as well as the external penalty term.  CLVs are", "answers": "crosslingual latent variables", "length": 7264}
{"pred": " Europarl and CoNLL 2009.  The EN-DE section of the Europarl corpus and the English (EN) and German (DE) sections of the CoNLL 2009 corpus.  The EN-DE section of the Europarl corpus and the English (EN) and German (DE) sections of the CoNLL 2009 corpus.  The EN-DE section of the Europarl corpus and the English (EN) and German (DE) sections of the CoNLL 2009 corpus.  The EN-DE section of the Europarl corpus and the English (EN) and German", "answers": "English (EN) and German (DE) sections of the CoNLL 2009 corpus BIBREF13, EN-DE section of the Europarl corpus BIBREF14", "length": 7261}
{"pred": " No.  Little information can be learned about semantic roles from this parallel data setup. One possible explanation for this result is that the setup itself is inadequate. Given the definition of aligned arguments, only 8% of English arguments and 17% of German arguments are aligned. This plus our experiments suggest that improving the alignment model is a necessary step to making effective use of parallel data in multilingual SRI, for example by joint modeling with SRI. We leave this exploration to future work.  Further analyses reveals that annotating small amounts of data can easily outperform the performance gains obtained by adding large unlabeled dataset as well as adding", "answers": "No", "length": 7268}
{"pred": " No. They add one latent variable for each aligned argument. If there are a total of L languages, and there is an aligned argument in A of them, the multilingual latent variable is connected to only those A aligned arguments. If there are a total of L languages, and there are A aligned arguments, the multilingual latent variable is connected to A aligned arguments. If there are a total of L languages, and there are A aligned arguments, the multilingual latent variable is connected to only those A aligned arguments. If there are a total of L languages, and there are A aligned arguments, the multilingual latent variable is connected to", "answers": "Yes", "length": 7269}
{"pred": " Individual Bayesian models for each language and crosslingual latent variables to incorporate soft role agreement between aligned constituents.  A multinomial distribution for the role labels and a binomial distribution for the role ordering.  A multinomial distribution for the role labels and a binomial distribution for the role ordering.  A multinomial distribution for the role labels and a binomial distribution for the role ordering.  A multinomial distribution for the role labels and a binomial distribution for the role ordering.  A multinomial distribution for the role labels and a binomial distribution for the role ordering.  A multinomial distribution for the role labels and a bin", "answers": "Bayesian model of garg2012unsupervised as our base monolingual model", "length": 7262}
{"pred": " No.  The results indicate that little information can be learned about semantic roles from this parallel data setup. One possible explanation for this result is that the setup itself is inadequate. Given the definition of aligned arguments, only 8% of English arguments and 17% of German arguments are aligned. This plus our experiments suggest that improving the alignment model is a necessary step to making effective use of parallel data in multilingual SRI, for example by joint modeling with SRI. We leave this exploration to future work.  Further analyses reveals that annotating small amounts of data can easily outperform the performance gains obtained by adding large unlabeled dataset", "answers": "Yes", "length": 7266}
{"pred": " The model is robust if it is insensitive to the prior knowledge.  The model is sensitive to the prior knowledge if it is misled by the prior knowledge with heavy bias.  The model is robust if it can handle the situation appropriately when the prior knowledge is biased.  The model is robust if it can make the performance desirable even when the prior knowledge is biased.  The model is robust if it can reduce the sensibility of the prior knowledge.  The model is robust if it can make the model more practical.  The model is robust if it can make the model more robust.  The model is robust if it can make the", "answers": ["ability to accurately classify texts even when the amount of prior knowledge for different classes is unbalanced, and when the class distribution of the dataset is unbalanced", "Low sensitivity to bias in prior knowledge"], "length": 7087}
{"pred": " 15–3. 1–0. 0–0. 1–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–0. 0–", "answers": ["They won their first game with a score of 15-3."], "length": 6588}
{"pred": " The time required to update the robot's belief does not increase with the complexity of the environment.  The belief update time on Map 2 and Map 3, containing more obstacles, is reduced compared to the first map.  More obstacles result in fewer iterations when solving the constrained shortest path problem with A.  Adding constraints due to the obstacles and polytopes reduces the size of the A search tree.  C. Limitations Simulation environments. In our simulations, we hardcoded the preference policy over the maps (e.g. in Map 1, go around the table counter-clockwise).  We randomly sampled problem instances (start and", "answers": ["The time required to update the belief does not increase with the complexity of the environment."], "length": 7006}
{"pred": " NLTK, Stanford CoreNLP, TwitterNLP, SentiStrength, TensiStrength, BIBREF17, BIBREF18, CogComp-NLP, spaCy, Stanford NLP NER.  Rosette Text Analytics, Google Cloud.  BIBREF23, BIBREF19, BIBREF24, BIBREF25, BIBREF26.  BIBREF14, BIBREF15, BIBREF16.  BIBREF22.  BIBREF27.  BIBREF1.  BIBREF2.  BIBREF3.  B", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "length": 6906}
{"pred": " 4.  Njoroge has four brothers: Boro, Kamau, Kori and Mwangi.  Mwangi is Njoroge's only full brother, who died in World War II.  Boro is the leader of the Mau Mau.  Kamau has been imprisoned for life.  Kori is not mentioned in the passage as being involved in the Mau Mau.  Kori is mentioned as being one of Njoroge's brothers.  Njoroge's brothers are all sons of Ngotho's first wife, Njeri.  N", "answers": ["Four."], "length": 6361}
{"pred": " Nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems.  The paper aims to solve nonlinear system vibration problems. ", "answers": ["The paper aims to solve nonlinear system vibration problems efficiently."], "length": 7036}
{"pred": " Unif and Stopword. The Unif encoder randomly keeps tokens to generate keywords with the probability δ. The Stopword encoder keeps all tokens but drops stop words (e.g. ‘the’, ‘a’, ‘or’) all the time (δ =0) or half of the time (δ =0.5). The corresponding decoders for these encoders are optimized using gradient descent to minimize the reconstruction error (i.e. loss(x, α, β)).  The Stopword encoder keeps all tokens but drops stop words (e.g. ‘the’, ‘a’, ‘or’) all the time (δ =0) or", "answers": ["varied from Maximum Entropy Classifiers (BIBREF4) to Support Vector Machines (BIBREF5,BIBREF6,BIBREF7,BIBREF8), Recursive Neural Networks (BIBREF9,BIBREF10), Convolutional Neural Networks (BIBREF11) and most recently transfer learning-based architectures like Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12)"], "length": 7111}
{"pred": " DTA18 and DTA19. They consist of subparts of DTA corpus BIBREF11 which is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century. DTA18 contains 26 million sentences published between 1750-1799 and DTA19 40 million between 1850-1899. The corpus version used in the task has the following format: \"year [tab] lemma1 lemma2 lemma3...\". The Diachronic Usage Relatedness (DURel) gold standard", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "length": 7069}
